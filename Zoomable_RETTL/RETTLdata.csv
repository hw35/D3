Actors,Expertise/Interests,Doctorate/ Highest degree,Organization,Department,College/ School,Award Number,Title,Abstract,Project Keywords (Survey),Project Categories,Corrected Tags,MappedExpertise,ExpertiseCategories,CleanedDepartment
Rogelio Cardona-Rivera,"Modeling human intelligence, Computational Psychology, Artificial Intelligence, Game Design, Interactive Narrative, Virtual Reality",,University of Utah,"School of Computing, Entertainment Arts and Engineering Program",,2119630,Transformative Computational Models of Narrative to Support Teaching Indigenous Perspectives in K-12 Classrooms,"This project will contribute to the national need for sharing Indigenous perspectives in US K-12 education. By providing accurate representations of Indigenous narratives within social studies curricula, this project will address misconceptions of Indigenous peoples and their communities. The project will mitigate potential impacts of misrepresentations such as cultural identity silencing, disconnection, and lower graduation rates for Indigenous students and lack of cultural competence for non-Indigenous students. Often, Tribal Knowledge Holders visit classrooms and share their histories and perspectives class by class, which has the potential to overburden Indigenous communities. Technology can support both teachers and Indigenous communities to develop sustainable processes and practices to appropriately preserve and share Indigenous knowledge, culture, and perspectives. To date, little work has examined the role of Indigenous representation in the creation of narrative technologies designed to mitigate the lack of Indigenous representation in the classroom. This project will develop emerging narrative technologies from an Indigenous perspective to support teachers and classroom learning. The broader impact of the work includes benefits for tribal communities, K-12 educators, and policymakers, and other community and education organizations that wish to expand representations of diverse knowledge, cultures, education, and computations.<br/><br/>The proposed work builds on existing efforts to address pressing issues of bias embedded in emerging technologies and expand current notions of how to design new forms of technology for more equitable futures. The proposed project will deconstruct and culturally reformulate the basis of emerging technologies: the underlying computational models, data, algorithms, and interfaces. The overarching research question is: What does a culturally sustaining/revitalizing computational model of Indigenous narrative(s) look like? Building on an existing partnership with the Northwestern Band of the Shoshone Nation and K-12 teachers, the project team will use the social studies classroom as a design context to address issues of representation of Indigenous knowledge and culture via computational models. The proposed work seeks to empower Tribal members to (re)engage technologies that have historically perpetuated disparities and caused significant harm to their community to develop prototypes that represent their ways of being and knowing. The prototypes will be Tribally-created design experiences that preserve Indigenous history and effectively share it with students in fourth grade classrooms. This project will offer empirical insights for effective strategies and processes of how to engage Indigenous communities through a community-driven design methodological approach. The project has the potential to reimagine not only how models and algorithms are designed, but also who designs them. This project will inform and advance diverse fields including computer science, learning sciences, psychology, Indigenous education, teacher education, and social studies education.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Identity, Motivation and engagement, Broadening participation of historically marginalized groups, Cultural competence/responsiveness, Bias and equity in AI","Learning analytics,Narrative and simulated environments,Modeling and simulation (including agent-based modeling),AI,Augmented/virtual/mixed reality,Games and game making","Analytics,AI Approaches and Technologies,Learning Environments and Platforms","Arts, Engineering,Computer Science"
Fatma Baytar,"Human centered design, Computational tools and methods, textile engineering, protective apparel, virtual fit, virtual avatars, AR applications for virtual dressing rooms, 3D virtual prototyping,  ",,Cornell University,College of Human Ecology,,2048022,CAREER: Developing Computational Tools to Revitalize the U.S. Textile Manufacturing Workforce,"The loss of U.S. apparel production jobs overseas and a subsequent decline in manufacturing infrastructure after the 1980s was highlighted during the COVID-19 pandemic, when demand for domestically produced personal protective equipment could not be met. In order to address this deficit, the U.S. textile industry requires the physical and human resources to update, upskill, and accelerate manufacturing. At the core of this transformation are 2D/3D digital technologies, which enable instant product iterations and quickly move garments from development into production. Currently, digital competence is low for many in the U.S. textile manufacturing workforce, which has traditionally preferred manual techniques and questioned the accuracy of digital technologies, thus limiting rates of adoption. In education, there is a lack of knowledge about how to integrate 3D digital technologies into the curriculum, which has made it challenging to develop a tech-savvy future workforce and provide training to the existing workforce.<br/><br/>To address these gaps, the overarching goal of this CAREER project is to accelerate digitalization in manufacturing by: (1) creating a novel computational tool to replace in-person fit sessions during new product development, and facilitate rapid decision-making when using 2D/3D digital technologies, and (2) designing effective training modules for the current and future workforce to strengthen their core knowledge and growth. Tools and research findings from this project will advance scholarly knowledge and make a contribution across the fields such as textiles, learning sciences, computer science, and human-computer interaction. In addition, the methods proposed in this research will pave the way to create new jobs in U.S. manufacturing industries at the intersection of design, ergonomics, and technology, which will significantly benefit from the computational tool and cyber learning approaches developed in this project. A major educational component of the research focuses on leveraging the digital skills of the technologically savvy cohort, and includes organizing workshops for educators, designing curricular materials, providing research involvement and mentoring of undergraduate and graduate students, and outreach to 4-H and K-12 students.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Smart & connected communities for learning, Workshop, Engineering education","Engineering education,HCI,Material science,Augmented/virtual/mixed reality,Computing technology","Research Methods,Disciplinary Areas,Other Disciplinary Areas,Learning Environments and Platforms",Psychology
Marcela Borge,"Computer-supported collaborative learning, cognition and development, sociocultural theory, human-computer interaction, design-based research methods, scenario based design, intelligent systems, technology supported self-regulated learning, socio-metacognition",,Pennsylvania State Univ University Park,College of Education,,2124855,"International Society of the Learning Sciences (ISLS) 2021 Conference: Reflecting the Past and Embracing the Future through Doctoral Consortium, Early, and Mid-career Workshops","This project supports a group of 25 US-based doctoral students and early career professionals to virtually attend the Doctoral Consortium, Early Career Workshop, and Mid-Career Workshop at the Annual Meeting of the International Society of the Learning Sciences to be held virtually in June 2021. This workshop will enhance the capacity of the learning sciences as a field to address important challenges associated with the transformation of education and broadening of participation in the digital age. Additionally, the workshop will target diverse participants within the field and mentor scholars who are underrepresented. The overall goal is to support new scholars in the interdisciplinary learning science research community and contribute to impactful research on learning that will benefit society as a whole.<br/><br/>Given the virtual setting due to the Covid-19 pandemic, the project will employ new technologies to create virtual-based opportunities for community building and networking for the participants.  The workshop organization builds on a successful model documented as effective in similar past workshops, providing opportunities for the participants to interact with international researchers and practitioners. The activities provide participants with a deeper understanding of the field combined with hands-on mentorship. This will support early career scholars to succeed in the field and go on to make valuable intellectual contributions. Ultimately, the workshop will enhance the capacity of the learning sciences as an interdisciplinary field to address important challenges associated with the transformation of education and broadening of participation in the digital age.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Workshop, Broadening participation of historically marginalized groups","Self-regulation reflection and metacognition,HCI,Cultural competence/responsiveness,Collaborative and/or participatory learning,Design-based research (DBR),Scenario-based design","Research Methods,Equity and Social Justice,Learning Processes and Theories",Education
Mubbasir Kapadia,"Intelligent systems, Artificial Intelligence, Computer Animation, Crowd Simulation, Digital Storytelling, Autonomous Agents",,Rutgers University New Brunswick,Computer Science Department,,2119265,The Role of Agency and Interactivity in Embodied Conversational Agents to Support Teacher Training in High Poverty Schools,"Challenges with classroom behavior management predicts teacher stress and attrition and support for behavior management is a top professional priority identified by teachers. Traditional training for teachers in behavior management (e.g., workshops, whole group in-service training) has failed to produce substantial improvements in teachers‚Äô work-related knowledge and skills. Virtual Reality-based training provides an opportunity for teachers to practice responding positively to disruptive behaviors with the freedom to explore and fail in a low-stakes setting. However, existing  platforms suffer from low usability and limited realism, particularly when simulating conversational interactions. This project offers a synergistic exploration of the educational impact of immersive, conversational learning environments, and the fundamental technical capabilities for building intelligent virtual agents. Specifically, the aim of the project is to systematically study the impact of embodied conversational agents on learning outcomes of teachers in high poverty schools, where discipline disparities and exclusionary discipline practices are prominent and positive discipline approaches are needed to promote engagement and learning.<br/><br/>This project supports the development and release of a new platform for specifying embodied conversational interaction, combining recent advances in intelligent virtual agents, generative modeling of communicative behavior, and human-in-the-loop design. The project outcomes will push the boundaries of agency and interactivity in virtual reality training platforms, where teachers can fully immerse themselves in virtual classrooms and engage with autonomous virtual students capable of expressing themselves using facial expressions, hand and body gestures, and spoken language. These free-form interactions are theorized to support transfer of learning from one setting (e.g., virtual classroom) to a new setting (e.g., live classroom), where teachers may carry forward applicable knowledge and skills. The research plan includes a series of studies over a 3-year time period, to systematically study the impact of agency and interactivity in virtual training platforms on the training outcomes of teachers, and their ability to transfer knowledge and skills to real classrooms. This type of training in behavior management provides an unique opportunity to augment existing support to teachers and foster the dissemination and implementation of effective training that can ultimately enhance student achievement and student/teacher well-being.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality,,"Augmented/virtual/mixed reality, Workshop, Modeling and simulation (including agent-based modeling)","Modeling and simulation (including agent-based modeling),AI,Pedagogical agents,Games and game making,Adaptive/Personalized learning and intelligent tutors","AI Approaches and Technologies,Learning Environments and Platforms",Computer Science
Melissa Tehee,"Bias/prejudice/racism, health disparities domestic violence and other trauma experienced by ethnic and racial minorities",University of Arizona,Utah State University,Psychology,,2119573,Transformative Computational Models of Narrative to Support Teaching Indigenous Perspectives in K-12 Classrooms,"This project will contribute to the national need for sharing Indigenous perspectives in US K-12 education. By providing accurate representations of Indigenous narratives within social studies curricula, this project will address misconceptions of Indigenous peoples and their communities. The project will mitigate potential impacts of misrepresentations such as cultural identity silencing, disconnection, and lower graduation rates for Indigenous students and lack of cultural competence for non-Indigenous students. Often, Tribal Knowledge Holders visit classrooms and share their histories and perspectives class by class, which has the potential to overburden Indigenous communities. Technology can support both teachers and Indigenous communities to develop sustainable processes and practices to appropriately preserve and share Indigenous knowledge, culture, and perspectives. To date, little work has examined the role of Indigenous representation in the creation of narrative technologies designed to mitigate the lack of Indigenous representation in the classroom. This project will develop emerging narrative technologies from an Indigenous perspective to support teachers and classroom learning. The broader impact of the work includes benefits for tribal communities, K-12 educators, and policymakers, and other community and education organizations that wish to expand representations of diverse knowledge, cultures, education, and computations.<br/><br/>The proposed work builds on existing efforts to address pressing issues of bias embedded in emerging technologies and expand current notions of how to design new forms of technology for more equitable futures. The proposed project will deconstruct and culturally reformulate the basis of emerging technologies: the underlying computational models, data, algorithms, and interfaces. The overarching research question is: What does a culturally sustaining/revitalizing computational model of Indigenous narrative(s) look like? Building on an existing partnership with the Northwestern Band of the Shoshone Nation and K-12 teachers, the project team will use the social studies classroom as a design context to address issues of representation of Indigenous knowledge and culture via computational models. The proposed work seeks to empower Tribal members to (re)engage technologies that have historically perpetuated disparities and caused significant harm to their community to develop prototypes that represent their ways of being and knowing. The prototypes will be Tribally-created design experiences that preserve Indigenous history and effectively share it with students in fourth grade classrooms. This project will offer empirical insights for effective strategies and processes of how to engage Indigenous communities through a community-driven design methodological approach. The project has the potential to reimagine not only how models and algorithms are designed, but also who designs them. This project will inform and advance diverse fields including computer science, learning sciences, psychology, Indigenous education, teacher education, and social studies education.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Identity, Motivation and engagement, Broadening participation of historically marginalized groups, Cultural competence/responsiveness, Bias and equity in AI","Critical theory and identity,Critical theory and identity,Community partnerships",Equity and Social Justice,Psychology
Eleanor O'Rourke,"Human-Computer Interaction, educational technology, Computer Science Education, Game Science","University of Washington, Seattle",Northwestern University,"Computer Science, Learning Sciences",,2045809,CAREER: Towards Intelligent Learning Environments that Support the Practice of Programming,"Technology plays an important role in modern society, shaping how people socialize, learn, and work. As a result, programming skills are in high demand across all sectors of the economy. While enrollments in university computer science (CS) courses are growing rapidly, many students struggle to learn programming and retention in the major is low. Learning to program requires mastering practices like problem-solving, systematic debugging, and adaptive planning. However, rising enrollments in CS classes make it difficult for instructors to monitor student practices and provide feedback. Given that a student‚Äôs programming process cannot be determined from the final solution, instructors rarely have visibility into students‚Äô programming practices. This project leverages a unique opportunity to observe and support the programming process automatically and aims to advance scientific understanding of the programming process by building intelligent programming environments that assess and adapt to students‚Äô motivations and practices. As a CAREER project, it employs integrated education and outreach efforts, to develop the theoretical and technical foundations needed to develop and disseminate intelligent learning environments that effectively support the practice of programming.<br/><br/>This CAREER project explores and addresses core challenges in promoting effective programming practices in introductory CS courses. The PI‚Äôs prior work reveals that students often use programming practices as signals of whether they are performing well. For example, many students believe that planning and looking up syntax are signs of low ability, even though experts consider these practices a natural part of programming. Furthermore, these self-assessments have been shown to impact self-efficacy, or a student‚Äôs belief in their ability to succeed. These findings introduce two core challenges. First, students‚Äô inaccurate expectations about programming may lead them to avoid effective expert practices. Second, students may develop low self-efficacy when they engage in these practices, a factor that can impact course performance and the decision to major in CS. This project proposes a general approach and set of techniques to address these challenges by (1) developing behavioral models that automatically detect programming practices to enable a large-scale study of student motivations and practices, and (2) designing and evaluating interventions that provide personalized guidance to help students develop motivation and effective practices. The proposed education plan will expand the impact of the research through (1) online workshops for CS instructors that focus on student motivation and practices, (2) new courses for graduate students who plan to become CS instructors, and (3) research opportunities for students who are underrepresented in CS.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Cyber-enhanced/Computer-assisted assessments, Formative assessment, Motivation and engagement, Workshop","HCI,Computer science education,Games and game making","Research Methods,Disciplinary Areas,Learning Environments and Platforms","Learning Sciences,Computer Science"
Stephen Looney,"Biostatistics, statistics, Linguistics",University of Georgia,Pennsylvania State Univ University Park,Applied Linguistics,,2140414,EAGER: Collaborative Research:  Second Language Speech Production: Formulation  of Objective Speech Intelligibility Measures and Learner-Specific Feedback,"This Early-concept Grants for Exploratory Research (EAGER) project focuses on exploring and developing a novel operational collection of speech, language and perception-based measures to objectively assess speech intelligibility for second language (L2) speech production, as well as providing effective learner-specific feedback. With the rise of English as an international language, intelligibility-based successful communication has been emphasized over native-like accents. However, L2 teachers often raise concerns about learners‚Äô slow or stagnant pronunciation progress. Several primary reasons for this problem may include difficulties in perceptually discerning changes in learners‚Äô speech and interpreting learners‚Äô speech patterns without any learner-specific intelligibility assessment profile. Today, teachers have no systematic way to assess each student‚Äôs speech changes, nor can students monitor and track feedback related to their pronunciation learning progression. Therefore, an exploratory and transformative method is introduced for measuring speech intelligibility that provides both teachers and learners with objective and individualized feedback. This  exploratory project is proposed for EAGER funding  in order to establish a baseline working framework for operational objective measure creation, and proof-of-concept assessment feedback for teachers and learners. This approach will help teachers gauge learners‚Äô intelligibility levels and allow learners to self-regulate their learning progress incrementally over time. The long-term innovation is expected to benefit skilled US professionals from non-English speaking countries, who work in various STEM (science, technology, engineering, and mathematics) fields. Additionally, this interdisciplinary project provides various opportunities for hands-on training and experience for both graduate and undergraduate students in the fields of language education, applied linguistics, computer engineering, and speech technology.<br/><br/>This project explores an idea to assess intelligibility in speech communications based on multiple individual speech measures for non-native speakers. The ideas are currently in their very early stages of development, and a large portion of the research ideas are untested. In order to establish the ground truth of potential individual speech production intelligibility measures, the implementation and feasibility of this intelligibility feedback approach must be validated with evidence. By employing advanced Automatic Speech Recognition-based accent classification technology based on machine learning, the team of researchers plan to provide learners with measured speech property information through operational and a discriminating set of objective speech intelligibility measures. The current innovation builds on language skill acquisition theory with a functional analytic-linguistic approach, arguing that explicit and metalinguistic feedback plays a pivotal role in moving learners forward in their L2 development. The vision is enabled by on-going research on auditory-based neurogram and spectrogram orthogonal polynomial measures that predict speech intelligibility, employing the learners‚Äô unconstrained speech utterances. The project will contribute to the scientific knowledge of what constitutes L2 intelligible speech, understanding how individualized objective speech intelligibility feedback affects L2 speech development, and creating a foundational collection of speech/auditory/signal processing measures as well as ASR/DNN driven measures that assess a speaker‚Äôs intelligibility and identify efficient ways of implementing this technology in L2 learning contexts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Pedagogical agents; Mobile learning; Online learning,,"Natural language processing and speech technologies, Cyber-enhanced/Computer-assisted assessments, Formative assessment, Machine learning, Learning analytics","Learning Analytics,Natural language processing and speech technologies,Learning analytics","Analytics,AI Approaches and Technologies",Linguistics
Okim Kang,"L2 speech/intelligibility, Speech perception and production, Speech technology and asr, Assessment",University of Georgia,Northern Arizona University,Department of English,,2140469,EAGER: Collaborative Research: Production of Second Language Speech: Formulation  of Objective Speech Intelligibility Measures and Learner-specific Feedback,"This Early-concept Grants for Exploratory Research (EAGER) project focuses on exploring and developing a novel operational collection of speech, language and perception-based measures to objectively assess speech intelligibility for second language (L2) speech production, as well as providing effective learner-specific feedback. With the rise of English as an international language, intelligibility-based successful communication has been emphasized over native-like accents. However, L2 teachers often raise concerns about learners‚Äô slow or stagnant pronunciation progress. Several primary reasons for this problem may include difficulties in perceptually discerning changes in learners‚Äô speech and interpreting learners‚Äô speech patterns without any learner-specific intelligibility assessment profile. Today, teachers have no systematic way to assess each student‚Äôs speech changes, nor can students monitor and track feedback related to their pronunciation learning progression. Therefore, an exploratory and transformative method is introduced for measuring speech intelligibility that provides both teachers and learners with objective and individualized feedback. This  exploratory project is proposed for EAGER funding  in order to establish a baseline working framework for operational objective measure creation, and proof-of-concept assessment feedback for teachers and learners. This approach will help teachers gauge learners‚Äô intelligibility levels and allow learners to self-regulate their learning progress incrementally over time. The long-term innovation is expected to benefit skilled US professionals from non-English speaking countries, who work in various STEM (science, technology, engineering, and mathematics) fields. Additionally, this interdisciplinary project provides various opportunities for hands-on training and experience for both graduate and undergraduate students in the fields of language education, applied linguistics, computer engineering, and speech technology.<br/><br/>This project explores an idea to assess intelligibility in speech communications based on multiple individual speech measures for non-native speakers. The ideas are currently in their very early stages of development, and a large portion of the research ideas are untested. In order to establish the ground truth of potential individual speech production intelligibility measures, the implementation and feasibility of this intelligibility feedback approach must be validated with evidence. By employing advanced Automatic Speech Recognition-based accent classification technology based on machine learning, the team of researchers plan to provide learners with measured speech property information through operational and a discriminating set of objective speech intelligibility measures. The current innovation builds on language skill acquisition theory with a functional analytic-linguistic approach, arguing that explicit and metalinguistic feedback plays a pivotal role in moving learners forward in their L2 development. The vision is enabled by on-going research on auditory-based neurogram and spectrogram orthogonal polynomial measures that predict speech intelligibility, employing the learners‚Äô unconstrained speech utterances. The project will contribute to the scientific knowledge of what constitutes L2 intelligible speech, understanding how individualized objective speech intelligibility feedback affects L2 speech development, and creating a foundational collection of speech/auditory/signal processing measures as well as ASR/DNN driven measures that assess a speaker‚Äôs intelligibility and identify efficient ways of implementing this technology in L2 learning contexts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Accessibility and technology; Formative assessment; Online learning; Feedback,,"Natural language processing and speech technologies, Cyber-enhanced/Computer-assisted assessments, Formative assessment, Machine learning, Learning analytics","Natural language processing and speech technologies,Cyber-enhanced/Computer-assisted assessments,Literacy (e.g. reading/reading comprehension writing language learning)","Instruments Assessment and Measures,AI Approaches and Technologies,Disciplinary Areas",English
Jacob Whitehill,"Machine learning, Affective computing, Intelligent tutoring systems, Computer vision","Univeristy of California, San Diego",Worcester Polytechnic Institute,Computer Science,,2046505,CAREER: Developing New Scientific Instruments for Classroom Observation: A Multi-modal Machine Learning Approach,"This project will harness artificial intelligence (AI) to improve both the quality of classroom teaching and the precision of educational research by providing teachers and scientists with new methods of observing the inter-personal dynamics between teachers, students, and their peers. Decades of research have demonstrated that the quality and quantity of interactions between teachers and students can have a major impact on student engagement, attitudes toward learning, and downstream academic and socio-emotional outcomes. Despite the progress that has been made in studying classroom interactions and their impact on students' learning, as well as in developing effective interventions to help teachers teach better, the status quo of educational measurement is currently a significant roadblock to further progress in both educational research and teacher training. Specific problems with contemporary methods include ignoring the possibly different classroom experiences of individual students and minority subgroups, and providing only limited actionable feedback for teachers. This project will depart from standard observation protocols, which typically describe the ""average"" classroom experience of the ""average"" learner, and instead focus on characterizing over time the fine-grained experiences of every student in the classroom. The scientific instruments developed during this project will also be used to help teachers to identify potential biases when interacting with particular students in their classes.<br/><br/>To achieve these goals, the team will make advances in multi-modal (vision, speech, natural language) machine learning to devise new architectures that analyze videos of school classrooms and perceive fine-grained interactions. The envisioned AI systems will (1) identify who is interacting with whom, when, and how in a school classroom; (2) find the key events during a teaching session that are most important for teacher feedback; and (3) summarize interactions for each student along different dimensions to find students who need more attention and to uncover possible bias. Based on these new analyses, the team will develop (4) predictive models to estimate socioemotional and academic outcomes outcomes. Finally, the team will (5) devise new teacher training experiences that help teachers to perceive classroom dynamics more accurately. The project will result in contributions to the fields of computer vision, speech analysis, machine learning, and education, and will offer new insights into automatic speaker diarization, person tracking, sentiment analysis, and classroom observation analysis. The scientific and educational agendas provide opportunities for inter-disciplinary training of research assistants; they will also enable and benefit from collaboration between the research team and teachers in both Massachusetts and Virginia.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Formative assessment, Computer vision technologies, Machine learning, Social emotional learning, Bias and equity in AI, AI, Natural language processing and speech technologies","Machine learning,Computer vision technologies,Adaptive/Personalized learning and intelligent tutors,Multimodal data analysis","Analytics,Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
John H. L. Hansen,"Speech processing, Speech recognition, Speaker recognition, Speech under stress, Lombard effect",Georgia Institute of Technology,University of Texas at Dallas,School of Engineering and Computer Science,,2140415,EAGER: Collaborative Research:  Second Language Speech Production: Formulation of Objective Speech Intelligibility Measures and Learner-Specific Feedback,"This Early-concept Grants for Exploratory Research (EAGER) project focuses on exploring and developing a novel operational collection of speech, language and perception-based measures to objectively assess speech intelligibility for second language (L2) speech production, as well as providing effective learner-specific feedback. With the rise of English as an international language, intelligibility-based successful communication has been emphasized over native-like accents. However, L2 teachers often raise concerns about learners‚Äô slow or stagnant pronunciation progress. Several primary reasons for this problem may include difficulties in perceptually discerning changes in learners‚Äô speech and interpreting learners‚Äô speech patterns without any learner-specific intelligibility assessment profile. Today, teachers have no systematic way to assess each student‚Äôs speech changes, nor can students monitor and track feedback related to their pronunciation learning progression. Therefore, an exploratory and transformative method is introduced for measuring speech intelligibility that provides both teachers and learners with objective and individualized feedback. This  exploratory project is proposed for EAGER funding  in order to establish a baseline working framework for operational objective measure creation, and proof-of-concept assessment feedback for teachers and learners. This approach will help teachers gauge learners‚Äô intelligibility levels and allow learners to self-regulate their learning progress incrementally over time. The long-term innovation is expected to benefit skilled US professionals from non-English speaking countries, who work in various STEM (science, technology, engineering, and mathematics) fields. Additionally, this interdisciplinary project provides various opportunities for hands-on training and experience for both graduate and undergraduate students in the fields of language education, applied linguistics, computer engineering, and speech technology.<br/><br/>This project explores an idea to assess intelligibility in speech communications based on multiple individual speech measures for non-native speakers. The ideas are currently in their very early stages of development, and a large portion of the research ideas are untested. In order to establish the ground truth of potential individual speech production intelligibility measures, the implementation and feasibility of this intelligibility feedback approach must be validated with evidence. By employing advanced Automatic Speech Recognition-based accent classification technology based on machine learning, the team of researchers plan to provide learners with measured speech property information through operational and a discriminating set of objective speech intelligibility measures. The current innovation builds on language skill acquisition theory with a functional analytic-linguistic approach, arguing that explicit and metalinguistic feedback plays a pivotal role in moving learners forward in their L2 development. The vision is enabled by on-going research on auditory-based neurogram and spectrogram orthogonal polynomial measures that predict speech intelligibility, employing the learners‚Äô unconstrained speech utterances. The project will contribute to the scientific knowledge of what constitutes L2 intelligible speech, understanding how individualized objective speech intelligibility feedback affects L2 speech development, and creating a foundational collection of speech/auditory/signal processing measures as well as ASR/DNN driven measures that assess a speaker‚Äôs intelligibility and identify efficient ways of implementing this technology in L2 learning contexts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Data mining; Educator professional training; Broadening participation of historically marginalized groups,,"Natural language processing and speech technologies, Cyber-enhanced/Computer-assisted assessments, Formative assessment, Machine learning, Learning analytics","Natural language processing and speech technologies,Mental health","Equity and Social Justice,AI Approaches and Technologies","Engineering, Computer Science"
Lorna Quandt,"Cognitive neuroscience, EEG, Learning, Sign language, emerging technology",Temple University,Gallaudet University,Educational Neuroscience,,2118742,New Dimensions of ASL Learning: Implementing and Testing Signing Avatars & Immersive Learning (SAIL 2),"The highly-spatial three-dimensional nature of American Sign Language (ASL) has created a serious barrier to technology-supported ASL instruction. What if ASL learners could access high-quality ASL instruction from native sign language instructors through a virtual reality-based, game-like environment? This project launches from prior work on the NSF-funded Signing Avatars & Immersive Learning (SAIL) project. The SAIL project yielded a working prototype of an immersive sign language learning environment in virtual reality. The current project expands past the prototype stage into a fully-fledged ASL learning experience. In the new version of SAIL, called SAIL 2, the research team is developing a more complete system where users enter virtual reality and interact with signing avatars (computer-animated virtual humans built from motion capture recordings) who teach users ASL vocabulary. Access to signed language is key to healthy development for many deaf individuals, but it remains a major challenge when access to high quality ASL instruction in limited by time and resources. SAIL 2 sets a foundation for greater access to learning ASL, which has potential for improving the lives of deaf children and adults. The project focuses on developing and testing this entirely novel ASL learning tool and fostering the inclusion of underrepresented minorities in STEM. This work has the potential to substantially advance the fields of virtual reality, ASL instruction, and embodied learning.<br/><br/>Immersive virtual reality is particularly well suited for highly spatial signed languages. The SAIL 2 project leverages head-mounted virtual reality and high-quality signing avatars to create a gamified ASL-learning system. SAIL 2 will be the only ASL learning system in virtual reality which does not require the user to wear specialized gloves or other peripheral devices. The project develops a functioning version of the comprehensive SAIL 2 system, and user testing during the design process guides the details of development. Key features of the system include sign recognition through hand tracking cameras, corrective feedback, and a gamified experience. Following the design and development of SAIL 2, the research team conducts behavioral research to evaluate the learning outcomes of SAIL 2. Evaluation of specific learning outcomes includes both understanding of ASL vocabulary and accuracy of sign production. Because of the embodied nature of signed language, mechanistic measures of the neural substrates of learning, including engagement of the sensorimotor cortices, are obtained through electroencephalography (EEG). The patterns of neural oscillatory activity provide insight into short-term changes in brain activity associated with using SAIL 2. The cognitive neuroscience experiment builds on previous research identifying the neural processes supporting sign language perception, and overall this project extends technological advances in high-fidelity motion capture recordings, avatar creation, and virtual reality.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Inclusive/universal design; Biometrics (e.g., eye-tracking, EEG); Augmented/virtual/mixed reality; Embodied learning and cognition",,"Augmented/virtual/mixed reality, Neuroscience, Accessibility and technology, Literacy (e.g.,reading/reading comprehension,writing,language learning), Games and game making, Embodied learning and cognition, Biometrics (e.g.,eye-tracking,EEG)","Accessibility and technology,Biometrics (e.g. eye-tracking EEG),Neuroscience","Instruments Assessment and Measures,Equity and Social Justice,Learning Processes and Theories",Neuroscience
Dinadayalane Tandabany,"Computational Nanoscience, Carbon based Pure and Hybrid nanoparticles, Artificial Intelligence, Machine Learning, Computational ",,Clark Atlanta University,Department of Chemistry,,2106938,Targeted Infusion Project: Technology Enhanced Education and Practices for Success (TEEPS) in Undergraduate Organic Chemistry at Clark Atlanta University,"The Historically Black Colleges and Universities Undergraduate Program (HBCU-UP) through Targeted Infusion Projects supports the development, implementation, and study of evidence-based innovative models and approaches for improving the preparation and success of HBCU undergraduate students so that they may pursue science, technology, engineering, or mathematics (STEM) graduate programs and/or careers. The project at Clark Atlanta University seeks to improve faculty and students‚Äô teaching and learning experience by revising the sophomore organic chemistry courses to include technological interventions. The project aims to hone students‚Äô ability to utilize and apply advanced technologies to ultimately, increase student preparedness for future STEM graduate and career opportunities.<br/><br/>The goals of this project are to: (1) enhance the quality of the sophomore organic chemistry courses by implementing new technology including visualization, computation, active learning, artificial intelligence, and virtual reality (VC+ALAIVR) and (2) implement the evidence-based practices of faculty-graduate student team mentoring and early intervention/advising. The team of faculty, graduate student teaching assistants (GTAs) and supplemental instructors (SI) will work collaboratively in creating a question bank of 5,000+ questions for student use. CAU‚Äôs undergraduate students will use cyberinfrastructure technological tools for learning organic chemistry. Professional training for the faculty, coupled with the questions database with answers and multimedia tools/presentations has the potential to impact hundreds of students via delivery of the courses with technology implementation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, AI, Science education, Broadening participation of historically marginalized groups","Nanotechnology,Chemistry,Nanotechnology,Machine learning,AI,Computing technology","Other Disciplinary Areas,AI Approaches and Technologies",Chemistry
Salam Khan,"Mathematical Modeling, Mathematical soliton and optics, Complex System Modeling, Applied Statistics, Stochastic Perturbation, Kendall shape space, Experimental Design, Probability Theory and Approximation Theory.",,Alabama A&M University,Mathematics,,2107293,Catalyst Project: Development and Implementation of Intelligent Adaptive Cyberlearning System for Minority Freshmen Students,"Catalyst Projects provide support for Historically Black Colleges and Universities (HBCU) to work towards establishing research capacity of faculty to strengthen science, technology, engineering and mathematics undergraduate education and research. It is expected that the award will further the faculty member's research capability, improve research and teaching at the institution, and involve undergraduate students in research experiences. Alabama A & M University intends to develop and implement an adaptive cyberlearning system to support student education and learning in freshmen-level mathematics courses. This cyberlearning approach seeks to lay the foundation for enhancing student engagement in mathematics, leading to long-term persistence in STEM and serving as a model for other institutional contexts.  <br/><br/>The primary goal of this project is to develop and utilize an innovative, transformative, and focused approach to improve students‚Äô learning and performance of Pre-Calculus Algebra skills at Alabama Agricultural and Mechanical University (AAMU). Central to the approach is an adaptive cyberlearning system referred to as MATH-CyLE. Students and instructors will utilize MATH-CyLE‚Äôs digital learning content and embedded learning and engagement strategies to support pedagogy and provide students with an intelligent interactive adaptive system to support their individualized learning. The impact of the cyberlearning system will be investigated to determine whether there are improvements to the indirect learning of students who use MATH-CyLE, as compared to students who receive traditional instruction.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Adaptive/Personalized learning and intelligent tutors,"Learning analytics,Computer vision,Machine learning,Mathematics,Physics,Modeling and simulation (including agent-based modeling),Experimental Design","Research Methods,Analytics,Other Disciplinary Areas,AI Approaches and Technologies",Mathematics
Alejandra Magana-de-Leon,"Computational model-based reasoning, scientific inquiry, problem-solving, embodied learning, computer and data science literacy, self-regulation, technology enabled environments, learning analytics, AI",,Purdue University,"Computer and Information Technology, Engineering Education",,2113991,Productive Online Teamwork Engagement Through Intelligent Mediation,"Modern work environments are becoming increasingly distributed. As a result, the ability of employees to work in a virtual environment is becoming essential for corporate success. Employers expect higher education institutions to prepare students to operate as productive members and leaders of virtual teams. While research has built compelling pedagogical frameworks to improve in-class teamwork performance, more research-based mechanisms are needed to maximize student engagement and build teamwork skills in online education environments. Focusing on large enrollment courses in higher education, this project will study the use of effective teamwork in the online classroom by (1) developing and testing technologies that promote social presence, (2) identifying pedagogies that facilitate teamwork in an online environment, and (3) promoting productive online teamwork engagement.<br/><br/>To promote productive online teamwork engagement, this design-based research project will develop the PECAS Mediator, an educational innovation that provides (1) AI-enabled monitoring, (2) productive and unproductive interaction detection, and (3) faculty mediation via just-in-time guidance. The high-level conjecture of this project is that monitoring and mediation, enabled by evidence-based pedagogical practices and technological innovations, will increase social presence within online teamwork sessions resulting in increased teamwork engagement. The project has two main objectives: (1) Deploy and validate the intelligent monitoring and mediation PECAS Mediator to promote social presence and collaborative learning, and (2) Investigate the effect of increased social presence and collaborative learning on teamwork engagement. The theoretical conjecture of this project is that social presence mediating processes will lead to productive engagement manifested as behavioral engagement via team effectiveness, cognitive engagement via team performance, and affective engagement via positive attitudes toward teamwork.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Teamwork pedagogy; Workforce development; Online learning; Design-based research (DBR),,"Design-based research (DBR), Collaborative and/or participatory learning, AI","Learning analytics,Inquiry learning (e.g. project/problem based learning),Modeling and simulation (including agent-based modeling),AI knowledge representation and reasoning,AI,Embodied learning and cognition,Computer science education,Data science education","Learning Processes and Theories,Analytics,AI Approaches and Technologies,Disciplinary Areas","Information Technology, Computing Technology"
Colleen Megowan-Romanowicz,Physics education research,,American Modeling Teachers Association,Learning Sciences,,2114586,Combining Smartphone Light Detection and Ranging with Augmented Reality to Enhance Position-Based Teaching and Learning in STEM,"Understanding how to measure, display, and interpret motion is important for many STEM-related careers, particularly in the physical and data sciences. Educational researchers have advocated for numerous approaches to support sense-making with mathematical models of motion, but teachers often struggle to enact them due to limited resources. This project will make high-precision position sensing a reality for anyone who owns a smartphone by building on light-based mobile sensors (LiDAR) that are able to detect one‚Äôs distance from objects and location within a space. The educational research will measure the effect of using this new technology to improve student learning and engagement with regard to mathematical models with motion graphs, by producing a classroom-ready application and gamified lessons for teachers and students to use in traditional classrooms as well as the home. <br/><br/>Researchers and educational software developers will develop new data visualization technology based on iOS‚Äô scanning LiDAR and Android‚Äôs time-of-flight depth imaging. The proposed technological innovation will make use of the novel back-facing infrared beam array to significantly increase precision in position measurements and the placement of augmented reality (AR) visualizations based on users‚Äô movements and environmental data. This project will determine the extent to which LiDAR-aided AR technology can enable high-precision, position-based, and real-time data visualization. It will explore how the new technology can provide the kind of cognitive scaffolding and embodied experiences needed for advancing teaching about modeling motion with graphs and vectors. Research in the learning sciences will entail a collaboration with STEM educators to develop and test the effectiveness of scenarios for exploration in traditional and remote learning contexts. This proposal will assess full-body movement to make sense of motion graphs with a focus on embodied learning and practice with data visualization literacy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Data visualization, representations, and dashboards; Community partnerships; Augmented/virtual/mixed reality; Embodied learning and cognition",,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Science education, Data science education",Science education,Disciplinary Areas,Learning Sciences
Kwangtaek Kim,"haptics enhanced medical imagining, 2D/3D haptic user interfaces, touch feedback-based rehabilitations, smart biomedical devices, content oriented security, cybernetics, human-computer machine interface, cutting edge education, training technologies, immersive game interfaces, VR/AR/MR interfaces",,Kent State University,Computer Science,,2118380,Bimodal Haptic-Mixed Reality (HMR) Needle Insertion Simulation for Hand-Eye Skills,"Although performing intravenous (IV) insertion is a very common medical procedure, it is technically difficult to master as demonstrated by the 35%-50% failure rate resulting in a negative cycle of re-insertions leading to increased patient harm and costs to the healthcare system. Faulty IV insertions in real-world conditions are related to vein variables (vein rolling or resistant to puncture) and patient variables (touch skin, skin coloring). Experts in nursing education have advocated for self-paced integration of simulation-based technologies to deliberately practice IV skills while receiving immediate feedback for error correction. However, using currently developed simulators or manikin arms fails to capture the actual realism and psychomotor techniques adaptive to variability needed to gain procedural mastery of the skill. To enhance the current learning environment, technological advances are needed to create a realistic learning platform with variability that maximizes the skill transfer and long-term retention. The proposed work is to fill the gap by developing a novel simulation system using haptics and mixed reality (HMR) and investigating the learning impacts. This work is significant because current haptic technologies combined with extended reality do not yet provide sufficient realism and variability to effectively develop the fine motor skills. Further, studies have not been conducted on the educational impact of bimodal HMR simulation with variable conditions that can adaptively create realistic patient environments during training. Upon developing the successful nature of the proposed research, new insight into effective learning technology as well as causes of improved learning in hand-eye skills will be provided, which may be used to improve learning in similar settings or be transformative to other fields such as cyber teaching and learning, hand skill training at work, immersive dexterous interfaces, motor skill development for people with disabilities, STEM learning, robotic surgery, and medical training.<br/><br/>This project will develop a bimodal HMR system, using emerging technologies, haptics and MR, to simulate IV needle insertion with variable conditions that will create a realistic learning environment for students to master insertion tactile skills using two hands; and investigate whether variability in practice (disuse theory) improves needle insertion skills. To achieve these goals, the project will be divided into two phases: Phase I and II. Phase I will focus on developing the bimodal haptic simulation using two complimentary haptic devices, a haptic glove and a stylus haptic device, integrated with MR to simulate virtual patients and IV needle insertion with variable training conditions (skin color and stiffness, vein rolled, or resistant to puncture). In Phase II studies, 360 (180 per year) nursing students will be randomly assigned to experience training sessions in one of the three modes (HMR-static, HMR-variable, manikin arm). To measure learners‚Äô IV insertion skills, trained evaluators (faculty members) from the College of Nursing will observe and evaluate participants‚Äô skills based on an established IV insertion skill checklist through exams. Post training surveys will be collected in terms of the realism and the user experience (usability) and those data will be used for continuously improving the HMR system. This research will advance the knowledge related to developing innovative learning and teaching environments using emerging technologies and provide empirical evidence of impactful variables that affect learning performance. The developed platform as an automatic self-practice system will provide free access to this medium for instructors and students alike in healthcare or related communities to extend and use even under a pandemic, for broadening participation for under-represented and financially challenged groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Accessibility and technology; Augmented/virtual/mixed reality; Communities for learning; User-centered design,,"Augmented/virtual/mixed reality, Modeling and simulation (including agent-based modeling), Science education","HCI,Accessibility and technology,Robots,Content security,Smart & connected communities for learning,Interactive Displays,Workforce development,Augmented/virtual/mixed reality,Augmented/virtual/mixed reality,Games and game making","Learning Environments and Platforms,Capacity Building,Other Disciplinary Areas,Research Methods,Equity and Social Justice,AI Approaches and Technologies",Computer Science
Shiting Lan,"Artificial Intelligence, personalized education, learner modeling, content generation, human-in-the-loop AI",,University of Massachusetts Amherst,College of Information and Computer Sciences,,2118706,Collaborative Research: Common Error Diagnostics and Support in Short-answer Math Questions,"One important way to help struggling students improve in math is to deliver personalized support that addresses their specific weaknesses. Many math questions have common wrong answers (CWAs) that correspond to specific errors students make during their answering process, caused by misconceptions or a general lack of knowledge on certain math skills. To date, CWA identification and support remains a labor-intensive process at a limited scale because it requires significant effort by teachers and/or domain experts. In this project, the investigators will develop artificial intelligence (AI)-based mechanisms that can automatically identify CWAs from students‚Äô answers to short-answer math questions and diagnose errors. Once these errors are identified, the investigators will enlist the help of teachers to design feedback and support mechanisms in various formats such as textual feedback messages and short videos. In turn, the investigators will integrate these diagnosis and effective support mechanisms into a teacher interface to support them in either classrooms or online learning environments. Overall, this project has the potential to lead to i) better understanding of CWAs in math questions and the underlying errors and ii) effective CWA support mechanisms for each error type. The project will be grounded in ASSISTments, a free web-based learning platform, therefore directly benefiting the 500,000 US students and 20,000 teachers using it and potentially an even larger number of students and teachers through the dissemination of research findings.<br/> <br/>This project consists of four main research activities. First, the investigators will leverage math expression embedding methods to learn the representations of student errors by clustering CWAs across multiple questions in the latent math expression embedding vector space. These learned representations will enable the automated diagnosis of student errors in real time. Second, the investigators will develop new knowledge tracing algorithms that go beyond typical correctness analysis and analyze the full answer each student submits to each question. These algorithms will enable the automated tracking of students‚Äô progress in correcting their errors. Third, the investigators will crowdsource multiple types of student support from teachers and integrate both student error diagnostics and support mechanisms into the existing ASSISTments teacher interface. This interface will provide feedback to teachers on which students are struggling in real time and recommend a support, which the teacher can either adopt and customize or reject and create their own support instead. Fourth, the investigators will conduct a randomized controlled trial to evaluate the effectiveness of each support mechanism in helping students correct their errors. This experiment will identify which support mechanisms are most effective at helping students correct each error type and improving learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; Machine learning; Natural language processing and speech technologies; Multimodal data analysis,,"Online learning, Cyber-enhanced/Computer-assisted assessments, Formative assessment, AI, Math education","Instructional Design,Adaptive/Personalized learning and intelligent tutors,Modeling and simulation (including agent-based modeling),AI,Human-AI Interaction","Capacity Building,AI Approaches and Technologies,Learning Environments and Platforms","Computer Science, Information Science"
Neil Heffernan,"Artificial Intelligence, Educational Data Mining, User Modeling, Intelligent Tutoring Systems, cognition of mathematics learning",Carnegie Mellon University,Worcester Polytechnic Institute,Computer Science,,2118725,Collaborative Research: Common Error Diagnostics and Support in Short-answer Math Questions,"One important way to help struggling students improve in math is to deliver personalized support that addresses their specific weaknesses. Many math questions have common wrong answers (CWAs) that correspond to specific errors students make during their answering process, caused by misconceptions or a general lack of knowledge on certain math skills. To date, CWA identification and support remains a labor-intensive process at a limited scale because it requires significant effort by teachers and/or domain experts. In this project, the investigators will develop artificial intelligence (AI)-based mechanisms that can automatically identify CWAs from students‚Äô answers to short-answer math questions and diagnose errors. Once these errors are identified, the investigators will enlist the help of teachers to design feedback and support mechanisms in various formats such as textual feedback messages and short videos. In turn, the investigators will integrate these diagnosis and effective support mechanisms into a teacher interface to support them in either classrooms or online learning environments. Overall, this project has the potential to lead to i) better understanding of CWAs in math questions and the underlying errors and ii) effective CWA support mechanisms for each error type. The project will be grounded in ASSISTments, a free web-based learning platform, therefore directly benefiting the 500,000 US students and 20,000 teachers using it and potentially an even larger number of students and teachers through the dissemination of research findings.<br/> <br/>This project consists of four main research activities. First, the investigators will leverage math expression embedding methods to learn the representations of student errors by clustering CWAs across multiple questions in the latent math expression embedding vector space. These learned representations will enable the automated diagnosis of student errors in real time. Second, the investigators will develop new knowledge tracing algorithms that go beyond typical correctness analysis and analyze the full answer each student submits to each question. These algorithms will enable the automated tracking of students‚Äô progress in correcting their errors. Third, the investigators will crowdsource multiple types of student support from teachers and integrate both student error diagnostics and support mechanisms into the existing ASSISTments teacher interface. This interface will provide feedback to teachers on which students are struggling in real time and recommend a support, which the teacher can either adopt and customize or reject and create their own support instead. Fourth, the investigators will conduct a randomized controlled trial to evaluate the effectiveness of each support mechanism in helping students correct their errors. This experiment will identify which support mechanisms are most effective at helping students correct each error type and improving learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Online learning, Cyber-enhanced/Computer-assisted assessments, Formative assessment, AI, Math education","HCI,AI,Data mining,Math education,Cognitive psychology / Cognitive science,Adaptive/Personalized learning and intelligent tutors","Analytics,Research Methods,Learning Processes and Theories,Disciplinary Areas,AI Approaches and Technologies",Computer Science
Qi Wang,"Autobiographical memory, social cognition, culture, internet and social media",,Gallaudet University,"Psycology, College of Human Ecology",,2118824,Collaborative Research:  Advancing STEM Online Learning by Augmenting Accessibility with Explanatory Captions and AI,"Videos are a popular medium for online learning, in which captions are essential for increasing accessibility to students for effective learning. This research identifies two types of video captions: typical closed captions and explanatory captions. Closed captions are a text representation of the spoken part of a video. Explanatory captions are created to give students insights into the visual, textual, and audio content of a video. Existing technologies have focused on automatically generating or improving the quality of closed captions. For STEM learning, explanatory captions have the potential to play a new role in learning. This project will work to devise effective Q/A mechanisms and effective interaction designs that enable students and instructors to generate explanatory captions for STEM videos in a collaborative manner. The proposed technologies will augment accessibility and learning experiences for under-served populations, including the Deaf and Hard-of-Hearing (DHH) community, made up of 48 million Americans, while also improving comprehension for non-native English speakers, even those without hearing impairments. Evaluation sites include both Gallaudet University, the world‚Äôs only liberal arts university dedicated exclusively to educating DHH learners, and the University of Illinois at Urbana-Champaign, which has the largest international student population amongst U.S. public institutions and supports students with disabilities in inclusive learning environments. <br/><br/>This interdisciplinary research draws from and contributes to both computer science and learning science, and accessibility practices in the following areas. The first step is discovering new knowledge about how accessibility-enabled videos (with explanatory and closed captions) broaden the participation of under-served populations in STEM learning. This will provide the foundation for developing a theory of how explanatory captions can contribute to learning and effective mechanisms, based on crowdsourced human contributions and machine learning algorithms, to create these explanatory captions for STEM videos at different learning stages (e.g., preparing, tracking, trouble-shooting, and reflecting). The investigators will then use the theory to create a novel chatbot that enables knowledge sharing for students with diverse backgrounds.  Theoretical frameworks--ICAP (interactive, constructive, active, and passive) and Community of Inquiry will guide the evaluation of how explanatory captions and chatbots can contribute to learning. Finally, the team will acquire empirical understanding of how augmented accessibility with AI agents (e.g., chatbots) impacts students' and instructors‚Äô practices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Accessibility and technology; Online learning; HCI,,"Online learning, Accessibility and technology, Machine learning, AI, Media use","Social welfare development and responsibility,Brain function,Collaborative and/or participatory learning,Cognitive psychology / Cognitive science,Cultural competence/responsiveness","Learning Processes and Theories,Equity and Social Justice,Other Disciplinary Areas",Psychology
Rhonda Christensen,"Technology integration, Research, Mobile learning, simulated techning, STEM",,University of North Texas,Learning technologies,,2118849,Improving Student Learning While Decreasing Bias in Teaching Through Simulation,"This project aims to contribute to a more just and equitable society in the future by encouraging teachers to identify, reflect on, and correct revealed biases. This three-year project will implement a scalable model for developing equitable, culturally responsive teaching practices through a simulated teaching environment. The project will identify best practices to help teachers recognize and mitigate implicit biases that often impact student success. Bias reduction in teaching practices is crucial for enabling future leaders to achieve their highest innate and positively nurtured potential. The COVID-19 pandemic has highlighted disparities in learning and emphasized the importance of socio-emotional stability for the long-term well-being of students and teachers. <br/><br/>The project team will iteratively develop and test a Teaching without Bias curriculum and add an AI-driven set of bias reduction tools to existing simulation instruction modules. The project will use data-driven decisions to confirm the feasibility of a three-phase approach to reducing bias in teaching. Through a randomized-assignment experimental design, the project will also confirm whether any of the three phases alone, in sequence, or in combination, is most effective. Through a simulated teaching environment, the project outcomes will lead to a model for developing equitable, culturally responsive teaching practices. The project will use the simulated teaching environment to develop and refine computational models that lead to improved teaching practices and contribute to the learning sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Multimodal data analysis; Cultural competence/responsiveness; Self-regulation, reflection, and metacognition",,"Modeling and simulation (including agent-based modeling), Cultural competence/responsiveness, Bias and equity in AI, Data mining","Narrative and simulated environments,Science education,Math education,Engineering education,Software engineering,Mobile learning","Learning Processes and Theories,Disciplinary Areas,Other Disciplinary Areas,Learning Environments and Platforms",Learning Technology
Ross Higashi,"Research-design-development and testing of curriculum, products, platforms for K-12 robotics education, Deliver professional development to formal and informal educators",,Carnegie-Mellon University,Robotics academy,,2118883,Using AI to Focus Teacher-Student Troubleshooting in Classroom Robotics,"Maintaining effective instructional interactions between teachers and students around content is challenging, especially in open-ended problem-solving domains such as computer programming. Troubleshooting student programs at the classroom scale becomes difficult, even more so in remote or hybrid instructional contexts. Yet an instructor‚Äôs adaptability, insight, rapport with students, and leadership role in the classroom remain indispensable. This project will explore the use of Machine Learning (ML) algorithms to offload the time-consuming tasks of finding and deciphering student errors while also focusing teacher-student troubleshooting interactions around algorithmically identified episodic ""clips"" of student work-in-progress. This approach differs from the current state of the art in that it neither replaces nor simply informs the teacher, but instead convenes students and instructors around instructionally rich portions of the students‚Äô own code and output. Design, development, and refinement of a prototype Convening AI system for middle school robotics programming will directly impact more than a dozen educators and 2000 of their students, including several schools serving underrepresented minority populations. It will also produce generalizable know-how about the design of Convening AI systems for other educational domains and ultimately inform future directions for the design of human-AI systems.<br/><br/>This project will address the technical and sociotechnical integration challenges of an AI-driven convener through design-based research by developing a proof-of-concept Formative Assessment Suggestion Tool (FAST) in the context of middle school robotics programming. FAST will compare the efficacy of different probabilistic and neural network-based self-supervised learning approaches in identifying a student‚Äôs intended solution from their source code and simulated robot run telemetry, e.g., by comparing the plan generated by a student with that by an optimal planner. It then uses a rollback planner to identify the point at which the student‚Äôs current implementation no longer has a likely path to that solution, such that this point can be expressed to the teacher. FAST‚Äôs ML models are initially trained on an archival data set of 35,000 student code submissions to isomorphic robot programming scenarios. Each source file is re-simulated in an instrumented environment to reconstruct position, collision, and other information. Additional data including longitudinal student code-writing behavior will be collected using instrumentation upgrades developed and deployed to the simulator curriculum‚Äôs active user base during the project. Data from classroom observation will be used to model and monitor proportions of time spent engaged in different instructional actions with and without the tool. User experience around convening will be refined through participatory co-design with teachers and students. Structural equation modeling will be used to test a theory of action around uptake of the tool into classroom practice: faster, more accurate troubleshooting increases student learning and engagement as well as teacher satisfaction, leading to acceptance and continued use of the technology in a virtuous cycle.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Machine learning; Robots; Formative assessment; Design-based research (DBR),,"Cyber-enhanced/Computer-assisted assessments, Design-based research (DBR), Modeling and simulation (including agent-based modeling), Machine learning, AI, Robots","Instructional Design,Educator professional learning,Computational thinking,MOOCs,Robotics Education","Disciplinary Areas,Capacity Building,Learning Environments and Platforms",Computer Science
Cristina Heffernan,"Artificial Intelligence, Educational Data Mining, User Modeling, Intelligent Tutoring Systems, cognition of mathematics learning",,"ASSISTMENTS FOUNDATION, INC.","ASSISTMENTS FOUNDATION, INC.",,2118904,Collaborative Research: Common Error Diagnostics and Support in Short-answer Math Questions,"One important way to help struggling students improve in math is to deliver personalized support that addresses their specific weaknesses. Many math questions have common wrong answers (CWAs) that correspond to specific errors students make during their answering process, caused by misconceptions or a general lack of knowledge on certain math skills. To date, CWA identification and support remains a labor-intensive process at a limited scale because it requires significant effort by teachers and/or domain experts. In this project, the investigators will develop artificial intelligence (AI)-based mechanisms that can automatically identify CWAs from students‚Äô answers to short-answer math questions and diagnose errors. Once these errors are identified, the investigators will enlist the help of teachers to design feedback and support mechanisms in various formats such as textual feedback messages and short videos. In turn, the investigators will integrate these diagnosis and effective support mechanisms into a teacher interface to support them in either classrooms or online learning environments. Overall, this project has the potential to lead to i) better understanding of CWAs in math questions and the underlying errors and ii) effective CWA support mechanisms for each error type. The project will be grounded in ASSISTments, a free web-based learning platform, therefore directly benefiting the 500,000 US students and 20,000 teachers using it and potentially an even larger number of students and teachers through the dissemination of research findings.<br/> <br/>This project consists of four main research activities. First, the investigators will leverage math expression embedding methods to learn the representations of student errors by clustering CWAs across multiple questions in the latent math expression embedding vector space. These learned representations will enable the automated diagnosis of student errors in real time. Second, the investigators will develop new knowledge tracing algorithms that go beyond typical correctness analysis and analyze the full answer each student submits to each question. These algorithms will enable the automated tracking of students‚Äô progress in correcting their errors. Third, the investigators will crowdsource multiple types of student support from teachers and integrate both student error diagnostics and support mechanisms into the existing ASSISTments teacher interface. This interface will provide feedback to teachers on which students are struggling in real time and recommend a support, which the teacher can either adopt and customize or reject and create their own support instead. Fourth, the investigators will conduct a randomized controlled trial to evaluate the effectiveness of each support mechanism in helping students correct their errors. This experiment will identify which support mechanisms are most effective at helping students correct each error type and improving learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Online learning, Cyber-enhanced/Computer-assisted assessments, Formative assessment, AI, Math education","HCI,AI,Data mining,Math education,Cognitive psychology / Cognitive science,Adaptive/Personalized learning and intelligent tutors","Analytics,Research Methods,Learning Processes and Theories,Disciplinary Areas,AI Approaches and Technologies",Learning Technology
Nikolas Martelaro,"Accessibility, Tools, user experience Design (UX), Artificial Intelligence (AI), Context aware computing, Conversational UI (Voice), Design Research, Internet of Things (IoT), Human-Robot Interactions (HRI), Interaction design, Interaction with autonomous systems, Design tools, Mechatronice",,Carnegie-Mellon University,Human Computer Interaction Institute,,2118924,Supporting Designers in Learning to Co-create with AI for Complex Computational Design Tasks,"As modern design tasks grow increasingly challenging, artificially intelligent (AI) design tools have the potential to provide new support to designers and engineers. This project will work to enable a future of computational co-creation, in which humans and AI collaborate and learn from each other to create new designs. The project addresses a vital national need: to prepare the emerging workforce in design, engineering, and manufacturing to better solve the complex problems of today by collaborating with AI design tools. In practice, co-creation with AI presents a significant learning curve for designers. The research team will study how people learn to collaborate with AI on real-world design tasks. The team will continuously build and test new ways for AI and designers to learn and interact through conversational and graphical interfaces. Success in this project is expected to advance our understanding of how people learn to collaborate with AI on complex computational co-creation tasks. This project is expected to lead to new training techniques and software design guidelines for AI-enabled design tools and other human-AI co-creative tasks. The research team will share their new interface designs and strategies to support other researchers in studying human-AI co-creation and to support companies in developing new AI-enabled design tools. The team will also incorporate the developed tools and research knowledge into classes for university and high school students, introducing them to human-AI collaboration and preparing them to work with and develop such systems in the future.<br/><br/>The research team will conduct iterative, human-centered design research to advance our understanding of how people learn to collaborate with AI on complex design tasks, while using widely available AI design tools, in the context of designing actively transforming structures. This is a complex, emerging manufacturing task. Steps in the research include: (1) Conduct a series of think-aloud activities to investigate how designers (try to) learn to collaborate with currently available AI design tools. The findings from these activities are expected to provide understandings of current challenges in human-AI design collaboration and will surface the strategies and mental models that people use when learning to collaborate with AI. (2) Prototype novel interface features to advance human‚ÄìAI co-creation and learning. These will include a range of interactions and interface modalities, building upon theories of effective conversational exchange and supporting controlling actions, delegating actions, and negotiating goals and means. (3) Evaluate these interfaces and interactions to see how well they support designers in learning to interact and productively work with the AI. (4) Use a mix of conversation analysis and multimodal observations to understand how the interface prototypes influence human-AI co-creation. The research is expected to produce new approaches to help researchers study and design human-AI co-creation, including: (a) measures for assessing learning and collaboration in the context of human-AI co-creative tasks; (b) prototyping methods for human-AI collaborative systems; (c) interaction design guidelines for onboarding and supporting designers in human-AI co-creation; and (d) new theory about how conversational interfaces can support designers in learning to co-create with AI.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; Collaborative and/or participatory learning; Design-based research (DBR); HCI,,"Engineering education, AI, Natural language processing and speech technologies, Multimodal data analysis","Learning analytics,HCI,Wearable / physiological technology,Accessibility and technology,AI,Pedagogical agents,Design Research,Human-AI Interaction,Manufacturing,Autonomous technology","Analytics,Learning Environments and Platforms,Other Disciplinary Areas,Research Methods,Equity and Social Justice,AI Approaches and Technologies","Computer Science, Human-Computer Interaction"
Joshua Sunshine,"collaboration and teams, computational statistics, computer architecture, diagrams and visualization, data mining and analysis, embedded systems, human-computer interaction, networking, privacy, program synthesis, program repair, programming languages, security, software architecture, societal computing, software requirements, software testing.",,Carnegie-Mellon University,Computer Science,,2119007,Enhancing flexible STEM thinking by generating interactive diagrams at scale,"Math and science diagrams improve learning, both when diagrams are delivered with instruction, and when they are created for self-explanation. The resulting learning is often more flexible. For example, students that practice diagramming are better at transferring their learning from the problems they have explicitly practiced to more open-ended problems. Unfortunately, diagrams are too uncommon in instructional materials, especially practice problems. This is primarily because diagrams are much harder to produce than text and symbols. Teaching at scale adds further challenges. Ideally, e-learning platforms should deliver different problems to different students. These problems should be tailored to knowledge components, prevent cheating by copying, and be tuned the amount of practice to student needs. Problem templating systems aren‚Äôt built for diagrams and grading student-authored diagrams is hard to do even manually.  To address the challenge, this project aims to develop a new tool for generating diagrammatic instructional content. <br/><br/>This tool developed by the project will enable content authors to generate large problem sets by example. User will author one or two problems and the tool will synthesize a problem set from the examples. The project introduces efficient interaction techniques for viewing and editing these sets. The project will collect data from teachers and students to guide, refine, and evaluate the design of the tool. The project will conduct six studies, three will focus on the effectiveness of the tool in supporting authoring of educational content and three that focus on the impact of the resulting problems on student learning. These studies will enhance our understanding of when and how diagrams can be used to increase student understanding of science, technology, engineering and math (STEM) principles and lead to more flexible STEM thinking.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Other, AI, AI knowledge representation and reasoning","Learning analytics,Social welfare development and responsibility,Programming,HCI,Ethical AI,Machine learning,Data mining,Software engineering,Data visualization representations and dashboards,Computing technology,Computing technology,Software engineering","Research Methods,Analytics,Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Sang Won Lee,"CSCW, Human Computer Interaction, Computer Music, Live Coding",,Virginia Polytechnic Institute and State University,Computer Science,,2119011,"RETTL: Facilitating socially constructed learning through a shared, mobile-based virtual reality platform in informal learning settings","Virtual reality (VR) technologies have great potential in STEM education because they provide immersive learning experiences that one cannot have in the real world. However, interactivity using VR head-mounted displays is often a solitary experience, isolating learners from the social and learning context. This makes it challenging to learn through collaborations with peers and instructors. Furthermore, many learners are excluded from using virtual reality headsets, including children, those who wear glasses, and those vulnerable to health concerns such as motion sickness, nausea, and falling. The project will develop and deploy a mobile-device-based VR platform to enable social learning. The project partners with the Science Museum of Western Virginia and the Institute of Creativity, Arts, and Technology at Virginia Tech to support socially constructed, informal STEM learning for their wide range of visitors, including young children with family members, college students, and local K-12 school students. <br/><br/>The project's overarching objective is to design, develop, and deploy an inclusive, socially connected virtual reality platform and educational content. With the system, museum attendees can collectively interact with STEM topics in virtual reality. The system will use social virtual reality to allow multiple learners to engage with the learning material, the instructor, and one another via and beyond motion-tracked mobile devices. A shared physical space with the mobile-based virtual reality platform will grant a diverse range of learners access to immersive STEM learning content and their peers beyond the screen. The researchers will study how the shared display technology facilitates socially constructed learning and enables novel active learning techniques in informal learning settings. The results will advance understanding of integrating virtual reality into inclusive settings and promoting collaborative learning with VR to enhance learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Collaborative and/or participatory learning, Social emotional learning","Collaborative and/or participatory learning,Programming,HCI,Creativity","Research Methods,Learning Processes and Theories,Other Disciplinary Areas",Computer Science
Mark Riedl,"Artificial Intelligence, Machine learning Storytelling, Explainable AI, Safe AI",,Georgia Tech Research Corporation,College of Computing,,2119135,Exploring Artificial Intelligence-enhanced Electronic Design Process Logs: Empowering High School Engineering Teachers,"The Engineering Design Process (EDP) is a general theoretical framework often used for teaching engineering, STEM, invention, and even science, particularly in K-12 education. While most EDPs used in education are depicted as linear or circular, true design processes are highly creative, non-linear, and often involve ill-posed problem statements and solution criteria.  These traits make it particularly difficult for high school engineering teachers, who tend to skip over key elements of human-centered design, where an engineer takes time to understand the problem through research, interviews, prior literature searches, market analysis, and brainstorming‚Äîthe steps where diversity of thought and experience are of the most value. In addition, it can be hard to provide students with real-time feedback due to the asynchronous nature of group work and large class sizes, and students may not feel comfortable asking for feedback on incomplete work. This project will develop and pilot an artificial intelligence (AI) enhanced Engineering Design Process Log to help students navigate the design process, provide real-time feedback, and encourage meaningful documentation of each step of the process.  This project does not propose to replace teachers with AI; rather, the project will explore a novel approach in which AI systems assist teachers in the creation of instructional modules that adhere to EDP best practices. This project is a collaboration between researchers at Georgia Tech‚Äôs College of Computing (GT CoC) and researchers at Georgia Tech‚Äôs Center for Education Integrating Science, Mathematics and Computing (CEISMC).  <br/> <br/>This project is a teaching-focused technological innovation, representing an early exploration into AI-enhanced design pedagogy. Specifically, the project will: 1) Improve upon an existing web-based Engineering Design Process Log (EDPL) by engaging in teacher user studies, 2) Design, pilot, and implement an AI-based authoring and tutoring system for teachers to customize feedback for students and for specific projects with domain expertise, 3) Design and provide professional development opportunities for alpha and beta testing teachers, and 4) Assess the impact of an AI-based EDP Log (AI-EDPL) on engineering design pedagogy and classroom practice. The AI-EDPL software system will use concepts initially pioneered for intelligent tutoring systems, but applied to scaffolding the creation of custom, teacher-made instructional materials that adhere to best practices in design process pedagogy assessment. Unlike many other educational domains, engineering design problems vary widely in scope and solution pathways, which means there will not be a one-size-fits-all tutoring system that can provide feedback to students. This project will examine (a) whether artificial intelligence can support and scaffold teachers in the creation of the necessary models and knowledge structures needed to scaffold and support learners, and, (b) what professional development teachers need to be successful in developing these models. A multi-phased approach will be used, using value-sensitive design processes from the field of human computer interaction to develop minimalist functional systems that can be tested with teachers in classrooms. In order for AI to help teachers, who do not have a lot of time to tinker with software, they must be able to express their intentions in natural language, which must be automatically converted into functional approximations of the task models that can be easily edited. This project will build on best practices in design theory and pedagogy, design documentation, design instruction, design assessment, and AI tutoring to create a one-of-a-kind technology suitable for engineering design instruction at the high school level. It represents a first attempt at providing real-time feedback in a computational setting for an open-ended design challenge, and it does so without marginalizing or diminishing the role of the instructor in the engineering classroom.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; AI knowledge representation and reasoning,,"Other, User-centered design, Adaptive/Personalized learning and intelligent tutors, AI","Ethical AI,Machine learning,AI,Bias and equity in AI","Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Jennifer Cross,"Human-robot interaction with a focus on educational applications of robotics, Development of novel robotics platforms and programming interfaces for K-12 and undergraduate education, Diversity and accessibility in robotics, engineering education, computer science education, Teacher and student empowerment, technological fluency, computational thinking, Mixed-methods evaluation of educational robotics interventions",,Tufts University,Center for Engineering education and ourtreach,,2119174,Integrating Artificial Intelligence with Smart Engineering and English Language Arts in Upper Elementary Education,"This project will develop upper elementary school students‚Äô abilities to work with Artificial intelligence (AI) in future careers. AI will be a critical tool for influencing and increasing productivity in the future of work. As such, it is increasingly important to introduce K-12 students to basic AI knowledge and skills, build familiarity with AI technologies, and train students to be competitive in the workforce. Through this project, a team of robotics and education researchers at Tufts University in Massachusetts and Maryville University in St. Louis, MO will work with over 50 teachers in St. Louis County to develop a research-informed educational ecosystem bringing AI concepts to upper elementary school students. This ecosystem will include a novel, low-cost, AI-enabled hardware toolset, including components such as sensors, actuators, and a microcontroller, for students to build smart systems, as well as support for teacher professional development. Through after-school and summer programs, the project will engage over 1000 St. Louis County students in constructing functional AI-enabled solutions to problems presented in fictional stories that the students read in English language arts and summer reading programs. The goal of the approach is to encourage transdisciplinary learning at the intersection of AI, engineering, and literacy. The education program testing will include 12 teachers and 500 students from the upper elementary target audience, with other participants in pilot testing across the K-12 grade band. The project aims to generate a new model for introducing vital AI concepts to elementary students that reduces barriers to integrating computational thinking into school curricula and provides tangible, trainable representations of AI for students to explore.<br/><br/>Researchers will investigate three primary research questions: 1) How does the introduction of tangible artificial intelligence elements lead to changes in upper elementary students‚Äô understanding of artificial intelligence concepts and attitudes towards artificial intelligence? 2) How do different levels of complexity and variety of tangible artificial intelligence learning tools impact students' engagement and the diversity of their solutions and designs? 3) What are the potential benefits and challenges of introducing tangible artificial intelligence elements in integrated engineering and literacy activities? The project team will apply a design-based research (DBR) approach to jointly generate interdisciplinary education and learning sciences theory alongside iteratively designing and developing the toolset, professional development, and activities. The research will include interviews and surveys with AI professionals to develop and validate grade-appropriate measures of students‚Äô understanding of AI concepts and attitudes. The team will evaluate the research questions with a mixed-methods analytic approach, triangulating qualitative data from teacher interviews, lesson and professional development observations, student-made artifact analysis, and artifact-based student interviews with quantitative data from teacher and student surveys. The project‚Äôs contribution will shift the artificial intelligence education paradigm towards a convergent curriculum and away from the status quo of coding and computing requiring separate instruction. The project findings will help inform the field about challenges specific to AI education in upper elementary grades. The deliverables from this project will include the AI Animated Inventions (AI2) hardware toolset, a teacher professional development model, a gallery of example activities and student work, and measures of the program‚Äôs effectiveness, as well as the usability and utility of the tangible artificial intelligence elements for learning AI concepts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Design-based research (DBR), Modeling and simulation (including agent-based modeling), AI","Broadening participation of historically marginalized groups,Robots,Workforce development,Mixed Methods,Broadening participation of historically marginalized groups,Robots,Human-AI Interaction","Learning Environments and Platforms,Capacity Building,Research Methods,Equity and Social Justice,AI Approaches and Technologies","Engineering, Education, Outreach"
Emily Moore,"Science Education, Accessibility, Inclusion, Education Technology",,University of Colorado at Boulder,Physics,,2119303,Inclusively-designing sensory extensions for STEM inquiry learning,"This project investigates innovative sensory extension device technologies to create learning materials that are accessible and enable diverse learners to use multiple modalities in science and mathematics learning. The new technologies will be designed, crafted, customized, and personalized by STEM learners with diverse needs. Humans think and communicate using multiple sensory modalities, including sight, sound, gesture, movement, and touch. Most science and mathematics learning materials convey information visually, with displays such as diagrams and simulations, resulting in learning experiences with limited sensory engagement. For many learners with visual or print-related disabilities, visual learning materials are inaccessible. Even for others, these materials constrain learning opportunities. Sensory extension incorporates materials and devices to enable new or enhanced perceptions of real or virtual environments. Familiar sensory extension devices include eyeglasses (refractive lenses improve vision), and Geiger counters (auditory perception of radioactive decay). In an inclusive co-design process, the project team will partner with diverse members of the learning community, together co-designing flexible, adaptive, and personalizable technologies, which enable new sensory experiences (e.g., sound, gesture, movement, and touch) to augment popular and widely used interactive simulation learning tools. The project team brings together experts in educational technologies at the University of Colorado Boulder (PhET Interactive Simulations and the Craft Tech Lab) and partner organizations serving youth with learning disabilities and visual impairments.<br/><br/>This project will work to create new learning materials, practices and processes for inclusive design with youth, as well as theories and frameworks for the use of sensory extension technologies as learning resources. To accomplish this, the team will investigate (1) pedagogical and design practices within inclusive inquiry learning in STEM learning settings; (2) the co-design and evolution of sensory extension devices; (3) learners‚Äô experiences of the impact of the inclusive design process on their own perceptions of self-efficacy and STEM; and (4) the learning experience of youth with diverse needs using sensory extension devices for STEM inquiry. The sensory extension devices are expected to enable new forms of collaboration among learners with differing sensory needs, and couple with existing educational technologies to expand their inclusive and accessible use and enrich the learning experience for all users. A rich corpus of data will be collected, tracking the trajectory of each design, including video and audio recordings of co-design sessions and the sensory extension devices in use, photographs of design artifacts and group activities, co-designer reflections and interviews, and self-efficacy survey responses. Through the inclusive co-design process, the project will work to advance foundational understanding of egalitarian processes of educational technology development, embrace sensory diversity, and empower educationally marginalized learners through the creation, customization, and personalization of their own innovative learning tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Inclusive/universal design; Wearable / physiological technology; Multimodal communication; Makers / making,,"Inquiry learning (e.g.,project/problem based learning), Accessibility and technology, Modeling and simulation (including agent-based modeling), Inclusive/universal design, Data visualization,representations and dashboards","Science education,Inclusive/universal design,Accessibility and technology","Equity and Social Justice,Disciplinary Areas",Physics
Vincent Aleven,"Learning science and technologies, intelligent tutoring systems, educational games",,Carnegie-Mellon University,Human Computer Interaction Institute,,2119501,Supporting collaborative reflection by K-12 teachers with analytics from intelligent tutoring software,"One way K-12 teachers engage in lifelong professional learning is by reflecting on their own practices, for example by reviewing video recordings from their class sessions. Past research shows that reflection has powerful effects on teachers‚Äô classroom practice. A separate line of past research shows that students learn very well with AI-based intelligent tutoring software (ITS), for example, in middle-school and high-school mathematics, and that teachers' support contributes to this effect. It is likely that teachers could help students more effectively if they were to periodically reflect on their classroom practices with regard to this type of software. Yet effective reflection is hampered by the fact that it is nearly impossible for teachers to notice and remember all that happens during any given classroom period. A well-designed tool that presents analytics extracted from class sessions could be a great help. The current research therefore investigates how to design an analytics tool that can support K-12 teachers in reflecting collaboratively with trusted colleagues on their classroom practices around students‚Äô work with intelligent tutoring systems (ITS). The project will build an innovative tool that allows computers to automatically collect and analyze multiple sources of data (i.e., multimodal analytics). The tool will prompt reflection and inform discussion among teachers, for example about their students‚Äô learning progress or challenges, and about their own, possibly implicit, biases towards certain students or groups of students. Through reflection with data, teachers can identify ways to improve their teaching practices, student learning, and equity in their classrooms. The main goal of the project is to design and create such a tool, test whether it supports effective collaborative reflection among teachers, and whether it leads to improved classroom practices. The project will contribute to the broader goal of making analytics useful for teachers. It has the potential to improve a highly effective form of K-12 classroom instruction, namely, learning with ITS, an increasingly common learning environment. <br/><br/>The project will design, create, and pilot-test a new analytics tool for supporting teachers in jointly reflecting on their classroom practices around ITS. The tool will leverage multimodal analytics; it will extract and show trends in students‚Äô learning and teachers‚Äô practices and illustrate them with strategically selected examples from its own data store, recorded during ITS sessions. The tool will take advantage of (1) location data, collected with sensors placed in classrooms, to reveal patterns in teachers‚Äô movement in the classroom, (2) physiological data, collected with physiological wristbands worn by teachers, to reveal ways in which their stress level affects students, (3) log data detailing students‚Äô interactions with the tutoring system, analyzed to detect progress, struggles, knowledge growth, and learning behaviors, and (4) video data that capture important detail about classroom interactions. The reflection tool will be designed with middle-school teachers. Teachers will be involved in the research start-to-finish to make sure the tool matches their preferences and needs. The design will be guided by a proven model of teacher reflection, adapted for multimodal analytics from sessions with an ITS. The tool will be implemented within CTAT+Tutorshop, a widely-used platform for ITS research and development. Many of the needed analytics already exist within CTAT+Tutorshop, but new ones will be developed as well.  Over time, the tool will be continuously improved and pilot tested. At the end, teachers will test a classroom-ready prototype with their classes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Multimodal data analysis; Educator professional training; Cognitive psychology / Cognitive science; User-centered design,,"Adaptive/Personalized learning and intelligent tutors, Bias and equity in AI, Learning analytics, Self-regulation,reflection and metacognition, Multimodal data analysis","Adaptive/Personalized learning and intelligent tutors,Games and game making","AI Approaches and Technologies,Learning Environments and Platforms","Computer Science, Human-Computer Interaction"
Meng Jiang,"Data mining, natural language processing, artificial intelligence",,University of Notre Dame,Computer Science and Engineering,,2119531,Collaborative Research:  Advancing STEM Online Learning by Augmenting Accessibility with Explanatory Captions and AI,"Videos are a popular medium for online learning, in which captions are essential for increasing accessibility to students for effective learning. This research identifies two types of video captions: typical closed captions and explanatory captions. Closed captions are a text representation of the spoken part of a video. Explanatory captions are created to give students insights into the visual, textual, and audio content of a video. Existing technologies have focused on automatically generating or improving the quality of closed captions. For STEM learning, explanatory captions have the potential to play a new role in learning. This project will work to devise effective Q/A mechanisms and effective interaction designs that enable students and instructors to generate explanatory captions for STEM videos in a collaborative manner. The proposed technologies will augment accessibility and learning experiences for under-served populations, including the Deaf and Hard-of-Hearing (DHH) community, made up of 48 million Americans, while also improving comprehension for non-native English speakers, even those without hearing impairments. Evaluation sites include both Gallaudet University, the world‚Äôs only liberal arts university dedicated exclusively to educating DHH learners, and the University of Illinois at Urbana-Champaign, which has the largest international student population amongst U.S. public institutions and supports students with disabilities in inclusive learning environments. <br/><br/>This interdisciplinary research draws from and contributes to both computer science and learning science, and accessibility practices in the following areas. The first step is discovering new knowledge about how accessibility-enabled videos (with explanatory and closed captions) broaden the participation of under-served populations in STEM learning. This will provide the foundation for developing a theory of how explanatory captions can contribute to learning and effective mechanisms, based on crowdsourced human contributions and machine learning algorithms, to create these explanatory captions for STEM videos at different learning stages (e.g., preparing, tracking, trouble-shooting, and reflecting). The investigators will then use the theory to create a novel chatbot that enables knowledge sharing for students with diverse backgrounds.  Theoretical frameworks--ICAP (interactive, constructive, active, and passive) and Community of Inquiry will guide the evaluation of how explanatory captions and chatbots can contribute to learning. Finally, the team will acquire empirical understanding of how augmented accessibility with AI agents (e.g., chatbots) impacts students' and instructors‚Äô practices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Online learning, Accessibility and technology, Machine learning, AI, Media use","Natural language processing and speech technologies,Data mining","Analytics,AI Approaches and Technologies","Computer Science, Engineering"
Wei Yan,"Computational Methods in Design, Augmented Reality, AI, Building Information Modeling, Parametric Modeling, Simulation, Optimization",,Texas A&M University,School of Architecture,,2119549,Using Augmented Reality and Artificial Intelligence to Improve Teaching and Learning Spatial Transformations in STEM Disciplines,"The mathematics that are used to describe spatial transformations can be very difficult for undergraduate students.  While moving something in the physical world may be easy to understand, describing the same operation with math in the digital world can be daunting.  This project will develop new technology using Augmented Reality (AR) and Artificial Intelligence (AI) to improve the teaching and learning of these difficult concepts in STEM disciplines as well as creative endeavors.  The project will test the use of new AR/AI technology to enhance students‚Äô learning of the mathematics behind spatial transformations.  This will improve the use of AR/AI-powered precise motion tracking of objects that can collect high resolution in-situ motion and scene data to enhance learning analytics. The project will identify the AR capabilities that can help students conceive, connect, and compare mathematical representations of motion to overcome the well-documented difficulties students face when learning spatial transformations.  Strengthening this skill will support their continued development across many STEM disciplines.<br/><br/>An AR/AI-powered innovative learning environment will be developed and evaluated for its effects on teaching and learning major rotation and orientation representations in the Euclidean space.  Different levels of abstraction, including Axis-Angle, Euler Angles, Matrices, and Quaternions will be tested. In workshops participants will play with and transform 3D-printed geometry models to evaluate the effectiveness of the AR/AI technology. The project will assess student learning outcomes by comparing math skills in pre- and post-workshop tests compared to students working through the same tasks without the use of the AR/AI technology. The project will contribute to advancing knowledge across disciplines of spatial and mathematical pedagogies, by exploring: a) the role of novel AR interaction that allows the interplay between physical and virtual manipulatives to engage students in embodied learning; b) the capabilities of AR to make difficult invisible concepts visible for supporting an intuitive and formal understanding of spatial reasoning and mathematical formulation; c) the features of AR that help students see relationships between spatial manipulations and mathematical operations; and d) the potential impact of individual differences in spatial transformations when using AR-assisted mathematical learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality; Games and game making; Makers / making,,"Augmented/virtual/mixed reality, Self-regulation,reflection and metacognition, AI, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Learning analytics","Narrative and simulated environments,Machine learning,Modeling and simulation (including agent-based modeling),AI,Augmented/virtual/mixed reality","Other Disciplinary Areas,AI Approaches and Technologies,Learning Environments and Platforms",Architechture
Yun Huang,"Human-computer interaction, social computing, mobile computing, computer-supported cooperative work, human-AI interaction, conversational agents, social media, crowdsourcing.",,University of Illinois at Urbana-Champaign,School of Information Sciences,,2119589,Collaborative Research:  Advancing STEM Online Learning by Augmenting Accessibility with Explanatory Captions and AI,"Videos are a popular medium for online learning, in which captions are essential for increasing accessibility to students for effective learning. This research identifies two types of video captions: typical closed captions and explanatory captions. Closed captions are a text representation of the spoken part of a video. Explanatory captions are created to give students insights into the visual, textual, and audio content of a video. Existing technologies have focused on automatically generating or improving the quality of closed captions. For STEM learning, explanatory captions have the potential to play a new role in learning. This project will work to devise effective Q/A mechanisms and effective interaction designs that enable students and instructors to generate explanatory captions for STEM videos in a collaborative manner. The proposed technologies will augment accessibility and learning experiences for under-served populations, including the Deaf and Hard-of-Hearing (DHH) community, made up of 48 million Americans, while also improving comprehension for non-native English speakers, even those without hearing impairments. Evaluation sites include both Gallaudet University, the world‚Äôs only liberal arts university dedicated exclusively to educating DHH learners, and the University of Illinois at Urbana-Champaign, which has the largest international student population amongst U.S. public institutions and supports students with disabilities in inclusive learning environments. <br/><br/>This interdisciplinary research draws from and contributes to both computer science and learning science, and accessibility practices in the following areas. The first step is discovering new knowledge about how accessibility-enabled videos (with explanatory and closed captions) broaden the participation of under-served populations in STEM learning. This will provide the foundation for developing a theory of how explanatory captions can contribute to learning and effective mechanisms, based on crowdsourced human contributions and machine learning algorithms, to create these explanatory captions for STEM videos at different learning stages (e.g., preparing, tracking, trouble-shooting, and reflecting). The investigators will then use the theory to create a novel chatbot that enables knowledge sharing for students with diverse backgrounds.  Theoretical frameworks--ICAP (interactive, constructive, active, and passive) and Community of Inquiry will guide the evaluation of how explanatory captions and chatbots can contribute to learning. Finally, the team will acquire empirical understanding of how augmented accessibility with AI agents (e.g., chatbots) impacts students' and instructors‚Äô practices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Online learning, Identity, Accessibility and technology, Broadening participation of historically marginalized groups, Self-regulation,reflection and metacognition, Machine learning, Data visualization,representations and dashboards, Embodied learning and cognition, AI, Media use","Social welfare development and responsibility,HCI,Crowdsourcing,Pedagogical agents,Mobile learning,Collaborative and/or participatory learning,Human-AI Interaction","Research Methods,Learning Processes and Theories,AI Approaches and Technologies,Learning Environments and Platforms",Information Sciences
Michael Horn,"Human-Computer Interaction, tangible Computing, Learning Sciences",Tufts University,Northwestern University,Computer Science,,2119701,Supporting Computational Literacy by Designing a Collaborative Platform at the Intersection of Music and Code,"This project will design and build technology that empowers ensemble musical performances with code while advancing the field of collaborative learning. It addresses two critical challenges for science and technology learning in the 21st century. First, how do we develop broad-based computational literacy skills for the next generation of learners? Second, how do we do that in a way that is inclusive‚Äîengaging diverse learners who have been historically marginalized in computational fields? The challenge of developing computational literacy is important across scientific, creative, artistic, and trade professions because computing is rapidly transforming all fields. As a result, skills such as computer programming are becoming foundational for everyone. To support motivation, learning, creative expression, and broadening participation, this research will investigate the intersection of music (as an integral component of contemporary culture) and computer programming in the design of a new collaborative technology platform. The platform takes inspiration from community-centered discourse and participation structures, such as drum circles, improvisational performance, and jam sessions. Participants will collaborate in online compositions by simultaneously writing computer code to play virtual musical instruments. Through a close partnership with the YMCA of Evanston, Illinois, the project will directly impact thousands of young learners in and around Chicago, and beyond, with a focus on students of color. The platform and learning materials (including audio and video tutorials hosted on YouTube) will be made freely available via a website to facilitate widespread adoption. These interconnections have the potential to serve as a foundation for prolonged interest, learning, creative expression, and lead to positive attitudes towards computing from a more representative, computationally empowered population.<br/><br/>This research builds on conceptual connections between music and computer science to contribute to computational literacy, informal learning in STEM and the arts, and creative and embodied approaches to computing. The project designs and studies a collaborative music+coding platform designed to give students freedom to tinker creatively, learn from their peers, and playfully confront culturally ingrained expectations about who can and should be a ""computer person"". The project will investigate the following thematic pairs of research questions: (1) Technology Innovation: How can we design technology that empowers ensemble musical performances with code? What are the foundational affordances of this technology to facilitate both co-located (multiple learners on the same physical stage) and distributed (multiple learners performing on a virtual livestream) musical performances? (2) New Models for Learning with Technology: How do we best design collaborative music+coding environments? What are the affordances of such environments for distributed collaboration, creativity, and computational literacy? (3) Broadening Participation: How can the intersection of music and computational literacy provide a context for prolonged interest and engagement for young people who have been historically marginalized in computing careers? Can code become a socially and culturally relevant medium of expression for creating and sharing music?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Broadening participation of historically marginalized groups; Creativity; Inquiry learning (e.g., project/problem based learning); Design-based research (DBR)",,"Broadening participation of historically marginalized groups, Collaborative and/or participatory learning, Computational thinking, Modeling and simulation (including agent-based modeling), Creativity","Interactive Displays,HCI","Research Methods,Learning Environments and Platforms",Computer Science
Gregory Chung,"games and intelligent tutoring systems on learning, engagement outcomes, the design of telemetry systems for games, analytical approaches to support the modeling of learning outcomes from fine-grained data",,University of California-Los Angeles,Education & Information Studies ,,2119818,Identifying and Extracting Meaningful Indicators of Children's Moment-to-Moment Programming Processes in Scratch,"This project aims to serve the national interest in STEM and computational thinking by developing and validating indicators of students' programming processes. The proposed exploratory research will develop a data logging module for Scratch to collect students' moment-to-moment programming behavior. The project team will develop data processing rules or algorithms to derive indicators of programming processes (e.g., debugging). The project will advance the understanding of what programming processes students use, how these processes unfold over time, and how these processes relate to measures of programming and computational thinking. The data logging module and algorithms will be distributed to the Scratch community to allow the study of programming processes at scale. The research will also produce a systematic and replicable methodology to accelerate the development of algorithms and widespread dissemination of the tools, techniques, and methods used to study programming processes.<br/><br/>The research will observe novice fifth grade and undergraduate students learning to program in Scratch. Students' process data will be used to derive indicators of programming processes. The indicators will be compared between age groups, within each age group over time, and to existing external measures of programming concepts and skills. This research will generate insights about what, how, and potentially why students perform the way they do. The capability to derive indicators of programming processes will complement existing methods of scoring static Scratch code. Algorithm development will focus on theoretically-driven, rule-based indicators of programming processes that are directly interpretable and on methods that systematize and accelerate the algorithm development process. The algorithm development methodology will apply to other block-based environments and applications involving process data such as games, simulations, and innovative item types in educational assessment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Telemetry-based indicators,,"Cyber-enhanced/Computer-assisted assessments, Computational thinking, Learning analytics","Data mining,Games and game making","Analytics,Learning Environments and Platforms","Education, Information Sciences"
Claire Christensen,"STEM, social-emotional learning",,SRI International,Education,,2139219,EAGER: Technology to Review Online Videos for Education (TROVE),"Online videos are becoming increasingly popular with young children. This presents a challenge for parents and educators who want them to watch educational videos but may lack the ability or time to distinguish educational from non-educational content within the rapidly growing universe of online video. To our knowledge, there are currently no machine learning methods for classifying educational video content; current methods rely on humans to identify video content. But human content reviews cannot keep pace when, on average, approximately 500 hours of content are uploaded to YouTube every minute. The goal of this project is to develop Technology to Review Online Videos for Education (TROVE), a machine learning-based tool to identify early childhood mathematics content in a high volume of videos. This capability will enable new approaches to increase young children‚Äôs exposure to developmentally appropriate mathematics content in videos, which has been shown to improve mathematics learning outcomes. TROVE will lay the groundwork to identify a range of subjects in videos, including literacy, science, and social-emotional content. Further, the technological advances developed under this project will have applications in other fields, including adaptive learning, social media analytics, propaganda detection, and video summarization. <br/><br/>Our multidisciplinary team of education and machine learning researchers will develop a content classification engine to identify mathematics content in online videos. We will define developmentally appropriate mathematics content at the toddler, preschool, and kindergarten levels based on the Head Start Early Learning Outcomes Framework and Common Core State Standards. To train the content classification engine, researchers who have demonstrated reliability in identifying the target mathematics content will annotate the mathematics content in 100 hours of online videos. The project‚Äôs central research question asks, how accurately can the content classification engine identify early childhood mathematics content in videos, as compared to humans? To answer this, we will compare the mathematics content identified by TROVE to that identified by researchers in a set of videos that were not used to train the classification engine. We will share our findings with education technology researchers and developers, educators, and policymakers via a peer-reviewed journal article and blog post. TROVE has transformative potential to support young children‚Äôs learning through exposure to high-quality, developmentally appropriate educational videos. Further, this technology may enable large-scale research on the impacts of children‚Äôs exposure to educational and non-educational video content.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Computer vision technologies; Machine learning; Multimodal data analysis; Media use,,Machine learning,"Science education,Math education,Engineering education",Disciplinary Areas,Education
Devin Harris,"Structural Engineering, Bridge Engineering, Condition Assessment, Digital Image Correction",,University of Virginia Main Campus,Civil Engineering,,2136724,EAGER: Adaptive Digital Twinning: An Immersive Visualization Framework for Structural Cyber-Physical Systems,"Infrastructure systems in the United States include a diverse series of assets, systems, and networks that are vital to the nation‚Äôs economy, security, and integrity. Members of every community, ranging from individual families to global corporations, rely on these infrastructure systems to thrive and maintain a high quality of life. This infrastructure is complex, interdependent, interconnected, and diverse, encompassing the water that we drink, the power that we use, the transportation services that move us, and the communication systems that connect us. Many of these infrastructure systems that serve society today were built during the second industrial age, and in many cases are in a state of disrepair with decreasing resources to preserve them. While we have continued to improve design approaches and implement more sustainable preservation strategies, modern infrastructure systems still follow many of the historical approaches used in their early development and have not been modernized. As societal dependence on technology continues to grow, the underlying physical infrastructure systems must be preserved, but also modernized to ensure that these systems are equipped to serve as the smart and agile cyber-physical systems (CPS) the future demands. This project will explore a high-risk/high reward approach to modernizing infrastructure systems using artificial intelligence-informed digital twins. The digital twinning of an infrastructure system will form a collaborative feedback loop between the measurable data of the physical world and simulated processes in the virtual world, providing a domain-specific adaptation of the broader CPS framework necessary to inform decision-making.<br/><br/>Applied to the domain of large-scale structural systems, this project will test the hypothesis that immersive engagement using a digital twin representation of these structural systems will enable participants to observe, interact, and contextualize the complex behavior mechanisms associated with these systems in their operational environment. To test the hypothesis, the research design will explore a series of technology innovations including the formulation of artificial intelligence models to emulate both simulation-based results and experiment-based measurements. Leveraging these technology innovations, we will be able to 1) understand to what extent can artificial intelligence formulated models effectively emulate the complex mechanical behaviors of simulation and experimentation of large-scale structural system; 2) evaluate to what extent does the development of artificial intelligence formulated models enable the real-time, bi-directional interaction between simulation and experimentation required of a digital twin; and 3) characterize how the deployment of artificial intelligence formulated models within an immersive environment allow end users to observe and characterize operational states of an in-service structural system. Success of this work will be realized through the fusion of experimental and numerical descriptions of these complex cyber physical systems and the creation of novel processes necessary to overcome the knowledge gap that exists between the theoretical descriptions of behavior and real-life structural response, forming a foundation for real-time decision-making for structural systems in their operational environments. Results from this project will be disseminated to the broader research community through refereed journals, conference proceedings, and student dissertations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Data visualization,representations and dashboards, AI","Cyber-enhanced/Computer-assisted assessments,Engineering education,Graphics","Instruments Assessment and Measures,Analytics,Disciplinary Areas",Civil Engineering
Julie Washington,"Intersection of language-literacy- poverty in African American children, Impact of Cultural dialects on early literacy skills, language development and disorders.",,University of California-Irvine,School of Education,,2202474,Collaborative Research: Improving Speech Technology for Better Learning Outcomes: The Case of AAE Child Speakers,"The lack of reading proficiency seen in children of underserved school districts has lasting impacts on students‚Äô performances in various subjects. Low literacy is an especially pressing issue for African American students.  Interactive spoken language systems offer the possibility of a powerful tool for assisting in early childhood education, freeing up teachers‚Äô time, and engaging students in repeated opportunities for learning. These systems involve both Automatic Speech Recognition and Text-to-Speech Systems. The goal of this research is to improve the performance of such systems for young speakers of African American English (AAE) such that automated oral literacy assessment can be developed. The research has important societal and technological impacts. It will enhance the usability of speech technology in early education for AAE speaking children, providing a model for better supporting students with diverse dialects. Many under-resourced children do not have access to adequate reading and language assessments, and the proposed work will address these issues by creating methods for adapting spoken language technology to AAE children, increasing fairness in speech technology on a broader scale. The work has strong outreach and dissemination programs and will train undergraduate and graduate students in interdisciplinary research in Electrical and Computer Engineering, Linguistics, Education, and Psychology.<br/><br/> <br/>Challenges facing children‚Äôs Automatic Speech Recognition (ASR) are due to (1) lack of child speech data and, hence, current models used for recognition are trained using data collected from adult speakers, and (2) children display a wider range of intra- and inter- speaker variability than adults.  ASR performance is especially poor for children who are non-native English speakers or those who at times transition into dialects such as AAE that are different from what ASR systems are typically trained on.  In addition, most dialog systems built on text-to-speech (TTS) technology are designed using General American English (GAE) voices, which minority children may not identify with. In the high-stakes area of education, these considerations impact the effectiveness of technology for different groups. The work will utilize a new and continuously developing database of AAE children's speech to research the impact of spoken language systems on children‚Äôs learning outcomes. On the learning side, the research will highlight the impact of dialect on literacy assessment. On the technology side, the work will yield novel machine learning algorithms for low-resource tasks.  Specifically, this project will develop data augmentation techniques that can increase the amount of training data available for low-resource tasks, and data normalization techniques so that ASR performance is improved for AAE child speakers. The work on TTS will explore new methods of disentangling speaker and dialect impacts on spectral realization of phrases that model dialect density (rather than treating dialect as a categorical variable) and separately accounting for pronunciation and prosodic factors.  Methods found to be effective for TTS will be leveraged in the data augmentation work for ASR and explored as a diagnostic in literacy assessment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Natural language processing and speech technologies, Machine learning, Literacy (e.g.,reading/reading comprehension,writing,language learning), Broadening participation of historically marginalized groups","Broadening participation of historically marginalized groups,ELA education,Cultural competence/responsiveness","Equity and Social Justice,Disciplinary Areas",Education
Robin Morris,"Developmental and Clinical Neuropsychology, Developmental Dyslexia, Reading and Attention Related Disabilities, Acquired Brain Injury, Neurogenetic Disorders",,"Georgia State University Research Foundation, Inc.",College of Arts and Sciences,,2202467,Collaborative Research: Improving speech technology for better learning outcomes: the case of AAE child speakers,"The lack of reading proficiency seen in children of underserved school districts has lasting impacts on students‚Äô performances in various subjects. Low literacy is an especially pressing issue for African American students.  Interactive spoken language systems offer the possibility of a powerful tool for assisting in early childhood education, freeing up teachers‚Äô time, and engaging students in repeated opportunities for learning. These systems involve both Automatic Speech Recognition and Text-to-Speech Systems. The goal of this research is to improve the performance of such systems for young speakers of African American English (AAE) such that automated oral literacy assessment can be developed. The research has important societal and technological impacts. It will enhance the usability of speech technology in early education for AAE speaking children, providing a model for better supporting students with diverse dialects. Many under-resourced children do not have access to adequate reading and language assessments, and the proposed work will address these issues by creating methods for adapting spoken language technology to AAE children, increasing fairness in speech technology on a broader scale. The work has strong outreach and dissemination programs and will train undergraduate and graduate students in interdisciplinary research in Electrical and Computer Engineering, Linguistics, Education, and Psychology.<br/><br/> <br/>Challenges facing children‚Äôs Automatic Speech Recognition (ASR) are due to (1) lack of child speech data and, hence, current models used for recognition are trained using data collected from adult speakers, and (2) children display a wider range of intra- and inter- speaker variability than adults.  ASR performance is especially poor for children who are non-native English speakers or those who at times transition into dialects such as AAE that are different from what ASR systems are typically trained on.  In addition, most dialog systems built on text-to-speech (TTS) technology are designed using General American English (GAE) voices, which minority children may not identify with. In the high-stakes area of education, these considerations impact the effectiveness of technology for different groups. The work will utilize a new and continuously developing database of AAE children's speech to research the impact of spoken language systems on children‚Äôs learning outcomes. On the learning side, the research will highlight the impact of dialect on literacy assessment. On the technology side, the work will yield novel machine learning algorithms for low-resource tasks.  Specifically, this project will develop data augmentation techniques that can increase the amount of training data available for low-resource tasks, and data normalization techniques so that ASR performance is improved for AAE child speakers. The work on TTS will explore new methods of disentangling speaker and dialect impacts on spectral realization of phrases that model dialect density (rather than treating dialect as a categorical variable) and separately accounting for pronunciation and prosodic factors.  Methods found to be effective for TTS will be leveraged in the data augmentation work for ASR and explored as a diagnostic in literacy assessment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Natural language processing and speech technologies, Machine learning, Literacy (e.g.,reading/reading comprehension,writing,language learning), Broadening participation of historically marginalized groups","Medicine,Brain function,Inclusive/universal design,Neuroscience","Learning Processes and Theories,Equity and Social Justice,Other Disciplinary Areas",Arts and Sciences
Mari Ostendorf,Speech and language processing,,University of Washington,Electrical and Computer Engineering,,2202049,Collaborative Research: Improving Speech Technology for Better Learning Outcomes: The Case of AAE Child Speakers,"The lack of reading proficiency seen in children of underserved school districts has lasting impacts on students‚Äô performances in various subjects. Low literacy is an especially pressing issue for African American students.  Interactive spoken language systems offer the possibility of a powerful tool for assisting in early childhood education, freeing up teachers‚Äô time, and engaging students in repeated opportunities for learning. These systems involve both Automatic Speech Recognition and Text-to-Speech Systems. The goal of this research is to improve the performance of such systems for young speakers of African American English (AAE) such that automated oral literacy assessment can be developed. The research has important societal and technological impacts. It will enhance the usability of speech technology in early education for AAE speaking children, providing a model for better supporting students with diverse dialects. Many under-resourced children do not have access to adequate reading and language assessments, and the proposed work will address these issues by creating methods for adapting spoken language technology to AAE children, increasing fairness in speech technology on a broader scale. The work has strong outreach and dissemination programs and will train undergraduate and graduate students in interdisciplinary research in Electrical and Computer Engineering, Linguistics, Education, and Psychology.<br/><br/> <br/>Challenges facing children‚Äôs Automatic Speech Recognition (ASR) are due to (1) lack of child speech data and, hence, current models used for recognition are trained using data collected from adult speakers, and (2) children display a wider range of intra- and inter- speaker variability than adults.  ASR performance is especially poor for children who are non-native English speakers or those who at times transition into dialects such as AAE that are different from what ASR systems are typically trained on.  In addition, most dialog systems built on text-to-speech (TTS) technology are designed using General American English (GAE) voices, which minority children may not identify with. In the high-stakes area of education, these considerations impact the effectiveness of technology for different groups. The work will utilize a new and continuously developing database of AAE children's speech to research the impact of spoken language systems on children‚Äôs learning outcomes. On the learning side, the research will highlight the impact of dialect on literacy assessment. On the technology side, the work will yield novel machine learning algorithms for low-resource tasks.  Specifically, this project will develop data augmentation techniques that can increase the amount of training data available for low-resource tasks, and data normalization techniques so that ASR performance is improved for AAE child speakers. The work on TTS will explore new methods of disentangling speaker and dialect impacts on spectral realization of phrases that model dialect density (rather than treating dialect as a categorical variable) and separately accounting for pronunciation and prosodic factors.  Methods found to be effective for TTS will be leveraged in the data augmentation work for ASR and explored as a diagnostic in literacy assessment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Natural language processing and speech technologies, Machine learning, Literacy (e.g.,reading/reading comprehension,writing,language learning), Broadening participation of historically marginalized groups",Natural language processing and speech technologies,AI Approaches and Technologies,"Computer Engineering, Electrical Engineering"
Abeer Alwan,"Digital speech processing, noise robust speech recognition, models of speech production and perception",,University of California-Los Angeles,Electrical and Computer Engineering,,2202585,Collaborative Research: Improving speech technology for better learning outcomes: the case of AAE child speakers,"The lack of reading proficiency seen in children of underserved school districts has lasting impacts on students‚Äô performances in various subjects. Low literacy is an especially pressing issue for African American students.  Interactive spoken language systems offer the possibility of a powerful tool for assisting in early childhood education, freeing up teachers‚Äô time, and engaging students in repeated opportunities for learning. These systems involve both Automatic Speech Recognition and Text-to-Speech Systems. The goal of this research is to improve the performance of such systems for young speakers of African American English (AAE) such that automated oral literacy assessment can be developed. The research has important societal and technological impacts. It will enhance the usability of speech technology in early education for AAE speaking children, providing a model for better supporting students with diverse dialects. Many under-resourced children do not have access to adequate reading and language assessments, and the proposed work will address these issues by creating methods for adapting spoken language technology to AAE children, increasing fairness in speech technology on a broader scale. The work has strong outreach and dissemination programs and will train undergraduate and graduate students in interdisciplinary research in Electrical and Computer Engineering, Linguistics, Education, and Psychology.<br/><br/> <br/>Challenges facing children‚Äôs Automatic Speech Recognition (ASR) are due to (1) lack of child speech data and, hence, current models used for recognition are trained using data collected from adult speakers, and (2) children display a wider range of intra- and inter- speaker variability than adults.  ASR performance is especially poor for children who are non-native English speakers or those who at times transition into dialects such as AAE that are different from what ASR systems are typically trained on.  In addition, most dialog systems built on text-to-speech (TTS) technology are designed using General American English (GAE) voices, which minority children may not identify with. In the high-stakes area of education, these considerations impact the effectiveness of technology for different groups. The work will utilize a new and continuously developing database of AAE children's speech to research the impact of spoken language systems on children‚Äôs learning outcomes. On the learning side, the research will highlight the impact of dialect on literacy assessment. On the technology side, the work will yield novel machine learning algorithms for low-resource tasks.  Specifically, this project will develop data augmentation techniques that can increase the amount of training data available for low-resource tasks, and data normalization techniques so that ASR performance is improved for AAE child speakers. The work on TTS will explore new methods of disentangling speaker and dialect impacts on spectral realization of phrases that model dialect density (rather than treating dialect as a categorical variable) and separately accounting for pronunciation and prosodic factors.  Methods found to be effective for TTS will be leveraged in the data augmentation work for ASR and explored as a diagnostic in literacy assessment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Natural language processing and speech technologies, Machine learning, Literacy (e.g.,reading/reading comprehension,writing,language learning), Broadening participation of historically marginalized groups",Natural language processing and speech technologies,AI Approaches and Technologies,"Computer Engineering, Electrical Engineering"
Diane Litman,"Artificial Intelligence, Artificial Intelligence and education, computational linguistics, spoken language, user modeling",University of Rochester,University of Pittsburgh,Computer Science,,2202347,Collaborative Research: Development of Natural Language Processing Techniques to Improve Students' Revision of Evidence Use in Argument Writing,"Writing is foundational to learning in multiple disciplines. It is a critical process by which students make sense of ideas ‚Äì particularly from source texts ‚Äì and bring them to bear to demonstrate their emerging understanding of concepts and to make sound arguments. Recognizing the importance of argumentative writing, multiple educational technologies driven by natural language processing (NLP) have been developed to support students and teachers in these processes. However, evidence is modest that such systems improve writing skills, and this is especially the case for younger students. One reason is that NLP technologies have only recently matured to the point that it is possible to provide feedback keyed to the content of students‚Äô writing. A second reason is that many students lack the strategic knowledge and skills needed to revise their essays even after receiving writing feedback. An educational technology that assesses students‚Äô skill at revising their writing and that provides feedback on their revision attempts would support the development of this critical skill, while placing no additional burden on teachers. Such a technology has the potential to prepare a new generation of students for productively writing and revising argumentative essays, a skill they will need in order to be prepared for the educational and workplace settings of the future.<br/><br/>To address the limitations of existing educational technologies for writing, the research team will develop a system that leverages NLP to provide students with formative feedback on the quality of their revisions. The team will 1) develop and establish the reliability and validity of new measures of revision quality in response to formative feedback on evidence use, 2) use NLP to automate the scoring of revisions using these measures, 3) provide formative feedback to students based on the automated revision scoring, and 4) evaluate the utility of this feedback in improving student writing and revision in classroom settings. The team hypothesizes that such a system will improve students‚Äô implementation of feedback messages on text-based argument writing, leading toward more successful revision and ultimately more successful writing. For learning researchers and educators, the revision quality measures will provide detailed information about how students implement formative feedback. Few summative or formative assessments currently exist that provide this type of information. For technology researchers, the automated revision scoring will extend prior writing analysis research in novel ways, e.g., by assessing the quality of revisions between essay drafts and by incorporating alignment with prior formative feedback into the assessment. Multiple types of NLP models will be developed to examine tradeoffs between model type and differing evaluation dimensions such as reliability, transparency, and fairness.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Cyber-enhanced/Computer-assisted assessments; Formative assessment; Argumentation,,"Formative assessment, Cyber-enhanced/Computer-assisted assessments, Literacy (e.g.,reading/reading comprehension,writing,language learning), Natural language processing and speech technologies","Natural language processing and speech technologies,AI,Spoken language,HCI","Research Methods,Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Elaine Wang,"Education Curriculum, Education Policy, Education Reform, Educational Program Evaluation, Elementary Education, Literacy, Principals, Secondary Education, Teacher Effectiveness, Teachers and Teaching",,Rand Corporation,Policy researcher,,2202345,Collaborative Research: Development of Natural Language Processing Techniques to Improve Students' Revision of Evidence Use in Argument Writing,"Writing is foundational to learning in multiple disciplines. It is a critical process by which students make sense of ideas ‚Äì particularly from source texts ‚Äì and bring them to bear to demonstrate their emerging understanding of concepts and to make sound arguments. Recognizing the importance of argumentative writing, multiple educational technologies driven by natural language processing (NLP) have been developed to support students and teachers in these processes. However, evidence is modest that such systems improve writing skills, and this is especially the case for younger students. One reason is that NLP technologies have only recently matured to the point that it is possible to provide feedback keyed to the content of students‚Äô writing. A second reason is that many students lack the strategic knowledge and skills needed to revise their essays even after receiving writing feedback. An educational technology that assesses students‚Äô skill at revising their writing and that provides feedback on their revision attempts would support the development of this critical skill, while placing no additional burden on teachers. Such a technology has the potential to prepare a new generation of students for productively writing and revising argumentative essays, a skill they will need in order to be prepared for the educational and workplace settings of the future.<br/><br/>To address the limitations of existing educational technologies for writing, the research team will develop a system that leverages NLP to provide students with formative feedback on the quality of their revisions. The team will 1) develop and establish the reliability and validity of new measures of revision quality in response to formative feedback on evidence use, 2) use NLP to automate the scoring of revisions using these measures, 3) provide formative feedback to students based on the automated revision scoring, and 4) evaluate the utility of this feedback in improving student writing and revision in classroom settings. The team hypothesizes that such a system will improve students‚Äô implementation of feedback messages on text-based argument writing, leading toward more successful revision and ultimately more successful writing. For learning researchers and educators, the revision quality measures will provide detailed information about how students implement formative feedback. Few summative or formative assessments currently exist that provide this type of information. For technology researchers, the automated revision scoring will extend prior writing analysis research in novel ways, e.g., by assessing the quality of revisions between essay drafts and by incorporating alignment with prior formative feedback into the assessment. Multiple types of NLP models will be developed to examine tradeoffs between model type and differing evaluation dimensions such as reliability, transparency, and fairness.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Formative assessment, Cyber-enhanced/Computer-assisted assessments, Literacy (e.g.,reading/reading comprehension,writing,language learning), Natural language processing and speech technologies","Instructional Design,Policy,Educator professional learning,ELA education,Evaluation","Capacity Building,Disciplinary Areas",Policy
Richard Mayer,"Cognition, Perception, Cognitive Neuroscience, multimedia learning, computer-supported learning, computer games for learning",0,University of California-Santa Barbara,Psychological & Brain Sciences,,2201020,Collaborative Research: Using Artificial Intelligence to Transform Online Video Lectures into Effective and Inclusive Agent-Based Presentations,"Students in introductory STEM courses frequently encounter video lectures that include an instructor standing next to a progression of slides. A challenge with these video lectures is that students may lose interest in science when they see the instructors as unhelpful (e.g., when they portray negative emotions while teaching) or unwelcoming (e.g., when they do not reflect the gender, ethnic, and racial diversity of the audience). This project aims to develop, validate, study, and make publicly available an artificial-intelligence (AI)-based framework that takes existing online instructional video lectures on introductory STEM topics created by human instructors and transforms them into instructionally effective and inclusive agent-based presentations. This work is intended to help improve science instruction and attract students from under-represented groups.<br/><br/>The research team will apply artificial intelligence methods to extract gesture and voice from instructional videos with human instructors and transform them into instruction delivered by a diverse set of emotionally and socially sensitive onscreen animated embodied agents. Experimental research studies will investigate: 1) whether students learn better from an AI-transformed version of a video lecture than the original instructor-made video lecture; and 2) which features of onscreen agents in AI-transformed video lectures produce improved learning outcomes and processes, comparing delivery from an onscreen agent who does or does not match the student's gender, ethnicity, or race. Overall, results from the project will impact access to high-quality inclusive STEM learning experiences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",0,,"AI, Adaptive/Personalized learning and intelligent tutors","Cognitive psychology / Cognitive science,Online learning,Media use","Learning Processes and Theories,Learning Environments and Platforms","Psychology, Neuroscience"
Nicoletta Adamo-Villani,"HCC, Visualization, Character Animation, Computer Graphics, HCI",0,Purdue University,Computer Graphics Technology,,2201019,Collaborative Research: Using Artificial Intelligence to Transform Online Video Lectures into Effective and Inclusive Agent-Based Presentations,"Students in introductory STEM courses frequently encounter video lectures that include an instructor standing next to a progression of slides. A challenge with these video lectures is that students may lose interest in science when they see the instructors as unhelpful (e.g., when they portray negative emotions while teaching) or unwelcoming (e.g., when they do not reflect the gender, ethnic, and racial diversity of the audience). This project aims to develop, validate, study, and make publicly available an artificial-intelligence (AI)-based framework that takes existing online instructional video lectures on introductory STEM topics created by human instructors and transforms them into instructionally effective and inclusive agent-based presentations. This work is intended to help improve science instruction and attract students from under-represented groups.<br/><br/>The research team will apply artificial intelligence methods to extract gesture and voice from instructional videos with human instructors and transform them into instruction delivered by a diverse set of emotionally and socially sensitive onscreen animated embodied agents. Experimental research studies will investigate: 1) whether students learn better from an AI-transformed version of a video lecture than the original instructor-made video lecture; and 2) which features of onscreen agents in AI-transformed video lectures produce improved learning outcomes and processes, comparing delivery from an onscreen agent who does or does not match the student's gender, ethnicity, or race. Overall, results from the project will impact access to high-quality inclusive STEM learning experiences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"AI, Adaptive/Personalized learning and intelligent tutors","HCI,Pedagogical agents,Data visualization representations and dashboards","Research Methods,Analytics,AI Approaches and Technologies","Computer Science, Human-Computer Interaction"
Katharina Kann,"Machine learning, deep learning, natural language processing",,University of Colorado at Boulder,Computer Science,,2223917,EAGER: Automatic Story Generation in Support of Early Vocabulary Learning,"In child development, small early differences can compound into big long-term effects. One example of this is the relationship between early vocabulary size, literacy, and later academic achievement. With this relationship in mind, many vocabulary enrichment programs based on shared reading with a caregiver have been developed, with mixed success. Evidence suggests that individualizing target-vocabulary selection can improve learning, but manually generating stories that include personalized target words for every child is infeasible. Automatic story generation using natural language processing techniques has the potential to solve this problem. Although there has been some progress in automatic story generation for adults, this is an unsolved and particularly challenging problem when stories are targeted for preschoolers, because both content and complexity need to be tailored to the age group. Thus, the researchers explore multiple innovative machine learning methods to generate engaging, high-quality child-directed stories that contain specific words that will enrich a child‚Äôs vocabulary. Furthermore, preschoolers and their caregivers participate in story-sharing activities to investigate if the automatically generated stories are effective tools for teaching words to children. This research is particularly critical for low-income families and dual language learners, who are more likely to exhibit vocabulary delays while, at the same time, being less likely to receive intervention support.<br/><br/>This EArly Grant for Exploratory Research makes novel and potentially transformative contributions to the area of automatic story generation by taking necessary exploratory steps towards flexible, adaptive technology that can automatically generate personalized, engaging, and effective stories for toddlers and their caregivers to share at home as a vehicle for early vocabulary enrichment. Specifically, the first part of this project consists of the following: 1) an investigation of multiple computational models with regards to their suitability for preschooler-directed story generation; 2) a study of strategies to avoid the generation of content that is not suitable for children by machine learning-based story generation models; and 3) an exploration of how to automatically incorporate a set of predefined target words into generated stories. Furthermore, the team of researchers investigates the quality of story generation models and the stories' effectiveness for word learning via the following: 4) obtaining feedback from families in the local community as to whether the automatically generated stories are appropriate and engaging for preschoolers and 5) conducting a laboratory study in which stories will be shared by caregivers and their children in a setting that resembles a natural home environment and subsequently comparing the children‚Äôs knowledge of target words against control words.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Natural language processing and speech technologies, Machine learning, Literacy (e.g.,reading/reading comprehension,writing,language learning)","Natural language processing and speech technologies,Machine learning","Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Joseph Polman,"Learning Sciences, Learning Technologies, Inquiry, Science Education, History Education",Northwestern University,University of Colorado at Boulder,School of Education,,2228412,ISLS 2022 Mentoring Workshops,"This project supports a group of 15 US-based doctoral students, early and mid-career professionals to virtually attend the Doctoral Consortium, Early Career Workshop, and Mid-Career Workshop at the Annual Meeting of the International Society of the Learning Sciences to be held virtually in June 2022. This workshop will enhance the capacity of the learning sciences as a field to address important challenges associated with the transformation of education and broadening of participation in the digital age. Additionally, the workshop will target diverse participants within the field and mentor scholars who are underrepresented. The overall goal is to support new scholars in the interdisciplinary learning science research community and contribute to impactful research on learning that will benefit society as a whole.<br/><br/>Given the virtual setting due to the continuing Covid-19 pandemic, the project will employ new technologies to create virtual-based opportunities for community building and networking for the participants. The workshop organization builds on a successful model documented as effective in similar past workshops, providing opportunities for the participants to interact with international researchers and practitioners. The activities provide participants with a deeper understanding of the field combined with hands-on mentorship. This will support early career scholars to succeed in the field and go on to make valuable intellectual contributions. Ultimately, the workshop will enhance the capacity of the learning sciences as an interdisciplinary field to address important challenges associated with the transformation of education and broadening of participation in the digital age.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Educator professional training; Workshop; Broadening participation of historically marginalized groups,,Workshop,"Inquiry learning (e.g. project/problem based learning),Science education,Social sciences education","Learning Processes and Theories,Disciplinary Areas",Education
Zachary Alstad,"Educational technology, Virtual environments for education",,TERC Inc,Educational researcher,,2202291,Using Augmented Reality to Enhance Attention in STEM Learning for Students with Executive Function Disabilities,"Using Augmented Reality to Enhance Attention in Science, Technology, Engineering and Mathematics Learning for Students with Executive Function Disabilities<br/><br/>Executive functioning represents a broad skill set that is central to STEM learning and academic success, including skills related to attention, persistence, emotion regulation, and inhibition control. For students with executive function difficulties, focusing during homework and other independent learning tasks is a challenge. Many existing assistive technologies supplementing a student‚Äôs organizational capabilities are expensive and exclusionary and rely on students‚Äô ability to organize or initiate their own task monitoring. This project provides an innovative, scalable intervention that enables individuals who struggle with executive functioning to persist and thrive in academic and workplace settings by using Augmented Reality technology to support an individual‚Äôs ability to self-monitor their attention and re-engage with the content when they are off task. In the long term, the system has the potential to become a widely used learning technology that improves outcomes for students with and without executive functioning difficulties. The project will serve the public interest by increasing the participation of a population that is currently underrepresented in STEM education and the STEM workforce.<br/><br/>This project will make a novel contribution to both the computer sciences and the learning sciences, achieved through two overarching project goals. First, using a temporal analysis of head position, head orientation, and gaze orientation, the project team will develop an open-source tool based on deep learning algorithms that can detect off-task behavior as undergraduate students work on math homework problems. Second, the team will use augmented reality to provide appropriate feedback to students in the form of redirection or breaks related to their own level of focus and distractibility. Development of this system will involve an iterative prototyping and testing process, and will conclude with an early efficacy study. To explore the most effective prompts, students with executive functioning issues will participate as co-designers of the system. The deep learning algorithm for the detection of off-task behavior is a novel contribution to the computer science field that has potential applications for other subject areas and other types of learning difficulties. Furthermore, the resultant self-monitoring and redirection prompts are a contribution to the learning sciences that can benefit most learners. Thus, this research will be a significant development in the application of augmented reality to learning as it explores the most productive means of student interaction with educational technology in a complex problem space.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Accessibility and technology; Augmented/virtual/mixed reality; Attention; Argumentation,,"Formative assessment, Augmented/virtual/mixed reality, Accessibility and technology",Augmented/virtual/mixed reality,Learning Environments and Platforms,Education
Robert LiKamWa,"Mobile operating systems, mobile computer architecture, low-power mobile systems, computational imaging systems, computer vision systems, augmented reality systems, virtual reality systems, holographic computing
",,Arizona State University,"Electrical , Computer and Energy Engineering; Arts Media and Engineering",,2202630,Multi-modal Learning for Enhanced Engagement and Presence,"The sense of smell plays a central role in how people navigate many common workplace situations. Despite this, contemporary educational approaches have only recently begun to explore using olfaction to improve education, and research on multimedia learning has almost completely overlooked it. As researchers, policy makers, and educators continue to expand digital platforms for teaching and learning, the failure to understand the role played by situational cues such as smell threatens the effectiveness of implementing STEM learning in digital environments. This integrative transdisciplinary project draws together insights from engineering, computational neurosciences, neurobiology, teaching and learning sciences, and the social sciences to advance understanding of the role that olfaction plays in learning in virtual learning environments.<br/><br/>To investigate the role of olfaction into virtual learning environments, the project team will design software platforms that integrate control of hardware that delivers a physical olfactory stimulus into real-time 3D virtual environments. This project will advance learning and teaching technologies by: (i) developing portable hardware and software systems to reliably synthesize virtual odors through miniaturized physical apparatuses, (ii) designing principles of easy-to-use development tools for virtual odor space design, and (iii) developing cloud-powered systems to model complex odor propagation. This project aims to advance understanding of the role that explicit olfactory training plays in improving a learner‚Äôs ability to identify, localize, and describe odors. By exploring how incorporating odor affects cognitive and procedural learning and its impact on learning transfer for tasks related to olfactory identification, this research will expand understanding of multimedia learning theory. Insights from this research will be used to develop pedagogical teaching approaches for domains where olfaction is important and aligns with vocational skills. By infusing olfaction into virtual reality education spaces, this project aims to create broadly accessible education opportunities around overlooked sensory cues.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Augmented/virtual/mixed reality,"Graphics,Augmented/virtual/mixed reality,Computer vision technologies,Computing technology","Analytics,Other Disciplinary Areas,AI Approaches and Technologies,Learning Environments and Platforms",Electrical Engineering
Erin Ottmar,"Mathematics Education, Educational Psychology, Applied Developmental Science, Social and Emotional Learning and Development, Perceptual Learning, Interventions in Mathematics, Educational Technology",,Worcester Polytechnic Institute,Learning Sciences; Social Science and Policy Studies,,2142984,CAREER: Grasping Understandings of Students Mathematical and Perceptual Strategies Using Real-Time Teacher Orchestration Tools,"Many middle and high school students in the United States do not reach proficiency in algebra. When solving algebraic expressions and equations, students not only need to perform procedures, but also identify mathematical structure, attend to important perceptual cues, and make decisions about which steps are most appropriate or productive in a particular problem context. Math teachers are critical to supporting and improving students‚Äô math achievement by providing high-quality feedback, instruction, discourse, and opportunities to their students. However, many teachers struggle to find algebra-based teaching tools that efficiently provide a means to challenge students to think conceptually, keep their students engaged, review student work efficiently in real-time, and better support their instruction. This project focuses on the design, development, and use of new algebra-focused teacher tools that use artificial intelligence (AI) to efficiently provide teachers with detailed information about their students‚Äô math problem solving steps, behaviors, errors, and learning in real-time. The underlying hypothesis is that if teachers are given detailed information and feedback about their students‚Äô perceptual and mathematical processes using real-time analytics, teachers will better notice and interpret student struggles. In turn, teachers will be able to make better decisions and differentiate their instruction for a broader range of students.<br/><br/>The main research question is to determine whether teachers are better able to detect, attend to, interpret, and make actionable decisions when using the AI-supported tool. Researchers will conduct a sequence of activities during this five-year project. First, to determine what behaviors best predict learning, a database of log files generated from students solving problems will be analyzed using statistical and learning analytics methods. Next, researchers will utilize machine learning approaches to create automated detectors that capture the use of effective math strategies, errors, and focus that has led to improved learning. Third, the project will use design-based research alongside teachers to co-design, develop, and prototype AI-supported teacher tools. The tools provide critical information about students‚Äô mathematical and perceptual processes and help teachers quickly identify what gaps students have in their math knowledge. The researchers will conduct classroom-based observations and interviews to examine how  teachers‚Äô instruction and students‚Äô understanding might be altered with the real-time tools and feedback. The outcome of the project will advance theories and foundational research in the fields of learning science, computational data science, human-computer interaction, and math education, as well as offer new insights into automatic detection of mathematical strategies and classroom orchestration. The technical and educational agendas also provide opportunities for interdisciplinary research and practical training and collaboration between graduate students, postdocs, teachers, and students. This award is funded in whole or in part under the American Rescue Plan Act of 2021 (Public Law 117-2).<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Data visualization, representations, and dashboards; Cognitive psychology / Cognitive science; Embodied learning and cognition; User-centered design",,"Design-based research (DBR), Formative assessment, Math education, Machine learning, AI, Learning analytics","Social welfare development and responsibility,Social emotional learning,Math education,Cognitive psychology / Cognitive science,Creativity","Learning Processes and Theories,Disciplinary Areas","Learning Sciences, Social Sciences, Policy"
Vitaliy Popov,"multi-user VR simulations, multimodal learning analytics in the context of co-located and virtually distributed teams in clinical simulations, perception and processing of feedback in interprofessional and multicultural teams, simulation-based education, sequential behavioral analysis, quantified ethnography methods, scaffolding in computer-supported collaborative learning, team cognition, discourse analysis, multi-channel learning data",,Regents of the University of Michigan - Ann Arbor,Medical School,,2202451,Project mTEAM: Advancing Emergency Medicine Trainee Skills using Multimodal Debriefing System in Simulation-based Training,"With the United States population living longer and having more chronic health conditions, the incidence of sudden medical emergencies is continually growing. These acute events create a complex, high-stress environment that requires teams of healthcare professionals to act precisely and quickly to give patients the best chance of survival.  The need for knowledge about how to better prepare teams for work in fast-paced, acute care settings is more important than ever. Healthcare professionals need frequent, realistic training opportunities that offer meaningful feedback on the skills that are essential for quality team-based clinical care. The research team has developed a multi-user Virtual Reality (VR) platform for Cardiac Arrest Resuscitation. This platform is designed to create realistic time pressure and rapid workload changes for the training of healthcare professionals. However, existing healthcare simulation training, including VR and manikin‚Äìbased learning, requires constant and real-time human observation. This limitation results in learners receiving feedback that is of variable quality - often generalized, inconsistent, and highly dependent on simulation instructors. With feedback being essential for learning and development, this limits the effectiveness and scalability of simulation training. To fill this gap, the research team will develop and evaluate a novel debriefing system that aims to capture and visualize multimodal data streams that evaluate learners‚Äô cognitive (e.g., clinical decision-making) and behavioral (e.g., situational awareness, communication) processes to provide data-informed feedback focused on improving team-based care of patients who suffer sudden medical emergencies. <br/><br/>Through this new multimodal debriefing system, instructors will be able to provide new insights and personalized feedback to clinicians during post-simulation debriefing sessions to allow for more meaningful reflection, targeted intervention, and rapid development of these complex skills. The project objectives are to: 1) conduct a human-centered design study with trainees and faculty to refine the concept of a multimodal debriefing system 2) engineer and evolve an unobtrusive multi-modal sensor-based data collection system; and 3) conduct a quasi-experimental study to evaluate the potential of this study‚Äôs debriefing system to improve clinical knowledge and teamwork skills. The proposed research not only provides a strong path forward to impact the way cardiac arrest training is carried out across institutions, but it will also create knowledge and systems that can be translated to develop data-informed, team-based training programs for other medical domains and other high-risk industries that rely on expert teams.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Augmented/virtual/mixed reality; Wearable / physiological technology; Collaborative and/or participatory learning; HCI,,"Formative assessment, Augmented/virtual/mixed reality, Modeling and simulation (including agent-based modeling), Multimodal data analysis, Learning analytics","Learning analytics,Narrative and simulated environments,Enthnographic methods,Cyber-enhanced/Computer-assisted assessments,Collaborative and/or participatory learning,Multimodal data analysis,Augmented/virtual/mixed reality,Qualitative Methods,Collaborative and/or participatory learning,Cognitive psychology / Cognitive science,Learning analytics,Collaborative and/or participatory learning,Formative assessment","Analytics,Learning Environments and Platforms,Instruments Assessment and Measures,Research Methods,Learning Processes and Theories",Medicine
Neil Heffernan,"Artificial Intelligence, Educational Data Mining, User Modeling, Intelligent Tutoring Systems, cognition of mathematics learning",Carnegie Mellon University,Worcester Polytechnic Institute,Computer Science,,2225091,Support for U.S. Doctoral Students to Participate in the Annual Artificial Intelligence in Education (AIED) and co-located Educational Data Mining (EDM) Conferences,"The United States has historically been the global leader in the field of artificial intelligence in education (AIED), or ways to use computerized artificial intelligence to enhance teaching and learning in contexts ranging from children learning math in school, to soldiers learning highly technical jobs in the US military. The preeminent conference in this field is the AIED conference; at this conference the latest research is presented and practitioners learn the state of the art techniques that allow creation of these important educational technologies. A related conference that is equally significant is the Educational Data Mining (EDM) conference, which focuses on research on big data and analytics for education. <br/><br/>This proposal would provide partial travel support for 10 Ph.D. students from the United States, selected through a competitive process, to attend the AIED conference and/or EDM conference, present their work, and receive additional mentoring outside of their dissertation committees as part of a doctoral consortium. The intellectual merit of the work rests on the studies the graduate students submit to be considered for participation in the early career track of the conference; this work is then enhanced by guidance from world-class mentors who meet with the students in a structured format to improve their research. The broader impact includes the career impact on the twenty selected students, especially since promising graduate students whose advisors may not have funding to send them to the conference can still be included, and their work can be showcased and improved. Possible long-term broader impacts include building the field of artificial intelligence in education and data analytics researchers and thus eventually, improving the quality of education.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Workforce development,"HCI,AI,Data mining,Math education,Cognitive psychology / Cognitive science,Adaptive/Personalized learning and intelligent tutors","Analytics,Research Methods,Learning Processes and Theories,Disciplinary Areas,AI Approaches and Technologies",Computer Science
Matthew Anderson,"the generation and measurement of femtosecond vortex beams with applications to microfluidics, and the use of femtosecond lasers in two-photon microscopy with applications in neuroscience.",,San Diego State University Foundation,Physics,,2202413,Seeing Virtually: Toward a Vision of Teaching Physics in 3-D Space,"One reason that students struggle in introductory physics classes, which are often key entry points for science, technology, engineering, and math majors, is that certain topics are difficult to mentally visualize and manipulate. For example, vectors and fields are challenging in their own right, and even more so when presented using static two-dimensional imagery. Conversely, in virtual reality where students are able to be present in a tactile environment and use familiar gestures to interact with objects, the potential for deeper learning is enhanced. The scope of this project involves developing virtual reality-based physics learning spaces in which students can explore models from multiple angles, manipulate the components, and interact with an instructor who is also engaged within the environment. A critical component of the design is inclusive access, as the platform does not require expensive or complicated equipment. All students will be able to participate from anywhere with nothing more than a smartphone and a desire to learn.<br/><br/>The goal of this project is to develop spatial computing environments that are specialized for undergraduate physics education. By leveraging expertise in educational research and state-of-the-art technologies, the team will prototype, iteratively develop, and optimize collaborative educational spaces where students can interact with three-dimensional renderings of physics phenomena and engage with each other and instructors in real time. The scope of this project involves (1) constructing three fundamental learning spaces: electric fields, magnetic fields, and electromagnetic waves, and (2) developing research-based theory regarding how virtual reality experiences can improve students‚Äô learning gains. The spaces will include dynamic graphical elements relevant to the physics phenomenon, interaction tools to modify those phenomena, a live instructor who can assume a student‚Äôs perspective to see exactly what the student is viewing, and learning assessment measures. The students‚Äô actions in these virtual environments and their learning gains will be studied in order to optimize the design and implementation of this novel approach. Access to the environment will be inclusive because it is platform-agnostic: while the instructor may use sophisticated tools, students can join with a tablet or smartphone.  This will foster successful learning opportunities for all students, and particularly for underrepresented minorities and at-risk students. Findings will advance knowledge on embodied cognition in spatial computing learning environments by investigating the ways in which various composition elements and tasks engage students in deeper levels of visualization and conceptual understanding.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Accessibility and technology; Augmented/virtual/mixed reality; Embodied learning and cognition; Inquiry learning (e.g., project/problem based learning)",,"Augmented/virtual/mixed reality, Science education",Wearable / physiological technology,Learning Environments and Platforms,Physics
Zhen Bai,"Human-Computer Interaction, Augmented and Virtual Reality, Tangible User Interface, Embodied Conversational Agent, Technology-Enhanced Collaborative Learning, Assistive Technology",,University of Rochester,Computer Science,,2225227,EAGER: Cultivating Scientific Mindsets in the Machine Learning Era,"Artificial Intelligence (AI) is woven into the fabric of everyday life. There is currently an enormous skills gap in AI for the future workforce. Limited AI learning opportunities among K-12 students and professional development opportunities for teachers may lead to AI inequity in the workforce and education. This project addresses these challenges by introducing Machine Learning (ML) as a discovery tool for data-driven scientific inquiry in K-12 STEM classroom. The project focuses on creating and studying a novel programming-free and visual-based ML-powered learning environment. It aims to enable high school students and teachers with limited mathematical, programming and data skills to discover complex scientific phenomena and ask big questions from thought-provoking patterns hidden in real-world data. Researchers will include high school students from marginalized backgrounds in STEM throughout the research activities and engage in outreach in collaboration with the David T. Kearns Center for Diversity and Leadership at the University of Rochester. This project will contribute to NSF‚Äôs missions on promoting inclusion in next-generation STEM education, and advance K-12 AI literacy as a driving force of national prosperity. <br/><br/>     Researchers will carry out three synergistic research activities: (1) creating a ML-powered visual learning environment that utilizes a combination of novel glyph-based data visualization and analogical learning process to mitigate the steep learning curve of ML and multi-dimensional pattern discovery for high school learners; (2) adopting a co-design approach to include K-12 STEM teachers and data science experts in creating ML-powered scientific inquiry activities; and (3) iteratively evaluating the effectiveness of the new learning environment in supporting three key learning goals for high school students: multi-dimensional pattern discovery, ML concepts and methods around clustering and classification, and pattern-inspired scientific inquiry through question asking, hypothesis generation, explanation and argument. Findings of this project will advance our knowledge on the design and pedagogical guidelines of ML-powered visual learning environments that minimize cognitive load for novice K-12 AI learners. The resulting novel learning environment, and ML-powered scientific inquiry activities will be made publicly available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Machine learning; Data visualization, representations, and dashboards; Online learning; Inquiry learning (e.g., project/problem based learning)",,"Data visualization,representations and dashboards, Machine learning, Data science education","HCI,Accessibility and technology,Pedagogical agents,Augmented/virtual/mixed reality,Collaborative and/or participatory learning,Cognitive psychology / Cognitive science,Collaborative and/or participatory learning","Learning Environments and Platforms,Research Methods,Learning Processes and Theories,Equity and Social Justice,AI Approaches and Technologies",Computer Science
Shuchisnigdha Deb,"human factors engineering and ergonomics, human computer/robot interaction, human-centered design, virtual reality in autonomous vehicle research, virtual reality in engineering education, training, assessment.",,University of Texas at Arlington,"Industrial, Manufacturing, and Systems Engineering",,2202598,"Enhancing Active Learning in Additive Manufacturing Using a Bilingual, Assisted Virtual-Reality Platform","Technology is integrated into every aspect of today‚Äôs world; therefore, the education system needs to train students in the use of technology. Virtual reality is one method that can be incorporated as a part of the curriculum, as an instructional delivery system, an instrument to enhance the learning process, and a tool for evaluation. This project focuses on additive manufacturing and will leverage emerging technologies by using virtual reality to develop a bilingual (English/Spanish) immersive learning environment for engineering students. All students, including students with disabilities, will be given access to the cutting-edge learning modules within virtual environments. Additive manufacturing technologies play a critical role in future manufacturing; however, they pose high-level safety-related threats to workers and environments. Hence, workers who need to directly or indirectly work with these technologies must be professionally trained with hands-on experience to gain the specific certified skills needed. The learning platform developed during this project will transform traditional approaches of learning and teaching, and improve engineering education in additive manufacturing.<br/><br/>The proposed project includes four distinct activities: (i) development of a virtual reality learning platform, (ii) design of course modules, (iii) development of software to track students‚Äô interactions, and (iv) deployment of the developed software in the target courses. The learning platform will be a virtual additive manufacturing lab equipped with different types of 3D printers, a computer workstation, a station for hand tools, and a station for personal protective equipment. Students will be assigned operational or safety training projects, based on the printer chosen, with instructions to complete tasks in sequence. After the development of the learning platform and course modules, a pilot study will be performed to collect data on student interactions with the course modules. Students‚Äô facial expressions and eye movements will be collected in real-time along with their interactions with the learning platform and course materials. Data from this study will enable us to develop a model to design assistive functionalities within the virtual platform. This model can create useful feedback and additional instructions or question students‚Äô selections, substitute instructors‚Äô supervision, and provide assistance. The outcomes of this project will be a novel bilingual learning and teaching platform with real-time assistance to significantly enhance student engagement and performance in active learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Computer vision technologies; Accessibility and technology; Virtual and remote laboratories / field trips; Attention,,"Augmented/virtual/mixed reality, Accessibility and technology, Engineering education, Learning analytics","Human-AI Interaction,Workforce development,Augmented/virtual/mixed reality,HCI","Research Methods,Capacity Building,Learning Environments and Platforms","Industrial Engineering,Manufacturing Engineering, Systems Engineering"
Paulo Blikstein,"Technology in teaching and learning, Computer modeling in Social and Behavioral Sciences, Science and Mathematics Education, Low-cost computational technologies, Maker education, Computer science education, Tangible interfaces for learning, Constructivism, Constructionist, Critical Pedagogy",,"Teachers College, Columbia University","Communications, Media and Learning Technologies Design",,2202579,Collaborative Research: Seeing Science: Using Computer Vision to Explore the Scientific Principles Behind Everyday Objects,"Understanding science is critical for preparing students to make sense of the world around them, make informed decisions, and participate in civic society and in the workforce. However, for many youth, science is a mysterious body of knowledge that feels disconnected from their lives. This project aims to bring science into middle school students‚Äô homes, allowing them to see the science behind everyday objects and transforming lived environments into engaging learning spaces. Students will work on inquiry-based learning units on mobile phones that explore STEM phenomena topics like diffusion, electricity, and simple machines that are present in their kitchens, bedrooms, and local parks. They will be able to take photos and videos of their home and neighborhood, and computer vision algorithms will augment these images with diagrams, models, and simulations that illustrate the principles and mechanisms that explain the STEM phenomena. These overlays will allow students to observe, experiment with, and make predictions for phenomena such as tea diffusing in hot water or heat traveling through walls. The project will capitalize on existing technological devices, such as camera phones, to create ‚Äúlenses‚Äù which enable students to see the science that is all around them.<br/> <br/>By committing to such low-cost solutions, the project aims to make science education accessible to more students, and enable at-home learning while avoiding undue pressures on family resources. Operating in diverse, low-resource environments motivates fundamental advances in computer vision: First, algorithms must automatically build up a 3D and temporal representation of a scene of a given physical phenomenon. Second, the system must expose hooks for educators to decide which graphics should be overlaid at which time and in which place atop this scene. Further, the project will engage in human-centered design to bring cutting-edge technologies to youth in ways that are accessible, easy to use, and achieve educational goals. Investigators will conduct extensive interviews with parents, students, and teachers about the aspects of students‚Äô out-of-school lives that they would be willing to share with researchers, peers, and teachers. These data will enable the team to realize the benefits of equitable science education that builds on students‚Äô lives and cultures. This research will help foster the development of a more agentic, inclusive way of engaging in science inquiry at home, encouraging students to have a personal connection with science from a young age. This is particularly important for students most at risk to perceive science as disconnected from their lives, and whom can benefit most from seeing science at work in their lives and community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Computer vision technologies; Mobile learning; Inquiry learning (e.g., project/problem based learning); HCI",,"Computer vision technologies, Science education","Science education,Computer science education,Inquiry learning (e.g. project/problem based learning),Modeling and simulation (including agent-based modeling),Critical theory and identity,Games and game making,Computing technology,Interactive Displays","Learning Environments and Platforms,Other Disciplinary Areas,Learning Processes and Theories,Equity and Social Justice,Disciplinary Areas,AI Approaches and Technologies",Learning Technology
Lydia Chilton,"Artificial Intelligence, computing systems, design, visualizations, creative humanity",,Columbia University,Computer Science,,2202578,Collaborative Research: Seeing Science: Using Computer Vision to Explore the Scientific Principles Behind Everyday Objects,"Understanding science is critical for preparing students to make sense of the world around them, make informed decisions, and participate in civic society and in the workforce. However, for many youth, science is a mysterious body of knowledge that feels disconnected from their lives. This project aims to bring science into middle school students‚Äô homes, allowing them to see the science behind everyday objects and transforming lived environments into engaging learning spaces. Students will work on inquiry-based learning units on mobile phones that explore STEM phenomena topics like diffusion, electricity, and simple machines that are present in their kitchens, bedrooms, and local parks. They will be able to take photos and videos of their home and neighborhood, and computer vision algorithms will augment these images with diagrams, models, and simulations that illustrate the principles and mechanisms that explain the STEM phenomena. These overlays will allow students to observe, experiment with, and make predictions for phenomena such as tea diffusing in hot water or heat traveling through walls. The project will capitalize on existing technological devices, such as camera phones, to create ‚Äúlenses‚Äù which enable students to see the science that is all around them.<br/> <br/>By committing to such low-cost solutions, the project aims to make science education accessible to more students, and enable at-home learning while avoiding undue pressures on family resources. Operating in diverse, low-resource environments motivates fundamental advances in computer vision: First, algorithms must automatically build up a 3D and temporal representation of a scene of a given physical phenomenon. Second, the system must expose hooks for educators to decide which graphics should be overlaid at which time and in which place atop this scene. Further, the project will engage in human-centered design to bring cutting-edge technologies to youth in ways that are accessible, easy to use, and achieve educational goals. Investigators will conduct extensive interviews with parents, students, and teachers about the aspects of students‚Äô out-of-school lives that they would be willing to share with researchers, peers, and teachers. These data will enable the team to realize the benefits of equitable science education that builds on students‚Äô lives and cultures. This research will help foster the development of a more agentic, inclusive way of engaging in science inquiry at home, encouraging students to have a personal connection with science from a young age. This is particularly important for students most at risk to perceive science as disconnected from their lives, and whom can benefit most from seeing science at work in their lives and community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Computer vision technologies, Science education","AI,Data visualization representations and dashboards,Computing technology,Creativity,Design Research","Analytics,Other Disciplinary Areas,Research Methods,Learning Processes and Theories,AI Approaches and Technologies",Computer Science
Dong Wang,"Social (Human-centric) sensing, computing and intelligence, human-centered AI, big data analytics, reliable information distillation systems, human-cyber-physical systems, edge computing, Internet of Things/Everything (IoT/IoE), smart cities.",,University of Illinois at Urbana-Champaign,School of Information Sciences,,2202481,FairFL-MC: A Metacognitive Calibration Intervention Powered by Fair and Private Machine Learning,"Students often have difficulty estimating their own level of knowledge. The goal of this project is to research ways to improve students' ability to estimate their knowledge, using a student support system consisting of short training exercises that will be personalized with artificial intelligence (AI) methods. While there is abundant research on AI methods in educational contexts, such projects rarely consider some of the key social and human factors, such as privacy and fairness, that are needed for widespread adoption of personalized educational software. This project addresses these issues with a novel decentralized AI framework that is specifically for education contexts. The project framework will enable researchers to create AI systems that provide feedback to students as part of their training exercises, all without directly accessing their data and while also training the AI system to reduce biases related to key aspects of students' identity, such as their demographics. The training exercises will include educational activities where students estimate their test scores, receive feedback from the AI system, and reflect on their knowledge. The privacy and fairness capabilities of the project framework will transform postsecondary online learning, which is poised to benefit from emerging AI-driven learning technologies but has yet to fully realize these benefits. The project will directly benefit students participating in the research as they will improve their knowledge estimation skills, prepare more effectively for tests in class, and learn about potential privacy violations and AI biases. Given the fairness focus of the project, the team of researchers will pay special attention to benefits for students from groups traditionally underrepresented in STEM (Science, Technology, Engineering, and Mathematics), ensuring that the AI-powered framework is equally helpful for them and that their perspectives on privacy and fairness receive special attention.<br/><br/>This project will advance AI research by incorporating, both, a strict privacy guarantee for student data and fairness considerations across multiple student demographic groups. Additionally, it will advance education research by determining how effective preemptive feedback is for improving knowledge estimation skills, and will examine the mechanism by which preemptively improving knowledge estimation influences academic outcomes. In particular, the project will achieve four research objectives through interdisciplinary innovations in both learning sciences and technology. First, the team will determine how much students' metacognitive calibration can be improved via AI-powered preemptive feedback, which may be perceived differently by students than post hoc feedback. Second, the project will expand theoretical understanding of metacognitive calibration and calibration interventions by studying the mechanism by which the intervention in the project works. Third, the team will address the fundamental tradeoff between the fairness and accuracy of AI models via an innovative federated learning model. Fourth, the team will evaluate the AI framework on real-world education datasets and compare its performance with the state-of-the-art baselines in terms of protecting privacy and mitigating bias. The project team will disseminate results of the project through workshops, publications, and interactive activities, and will train undergraduate and graduate students from diverse backgrounds throughout the project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Machine learning, AI, Self-regulation,reflection and metacognition","HCI,Wearable / physiological technology,Smart & connected communities for learning,Data mining,Computing technology,Human-AI Interaction","Research Methods,Analytics,Other Disciplinary Areas,Learning Environments and Platforms",Information Sciences
Wei Wang,"Cloud Computing, Software Engineering, Applied Artificial Intelligence, Computer Systems, Compilers, Parellel Computer Architecture",,University of Texas at San Antonio,Computer Science,,2202632,"Enhancing Programming and Machine Learning Education for Students with Visual Impairments through the Use of Compilers, AI and Cloud Technologies","Attractive high-paying and highly flexible Computer Science careers should be more readily accessible for people with blindness or visual impairments (BVI). Unfortunately, teaching the required computer programming and data science skills to students with BVI is extremely challenging due to two major difficulties. The first difficulty comes from the limited capability of current screen readers to properly read computer codes that are a mix of English letters, digits, and punctuation marks. The specialized set of keystrokes used in programming is also not conveniently read by screen readers (e.g., spaces and tabs). The second difficulty comes from time-consuming and frustrating code navigation, whereby students with BVI must repeatedly use screen readers to read every line to locate the desired line for editing. Partnering with San Antonio Lighthouse for the Blind and Vision Impaired, the project will develop new accessibility tools, including a program syntax- and semantics-aware screen reader and a voice-command-based code navigation framework to address the above two difficulties. These accessibility tools will be offered through cloud-based web interfaces to provide nationwide access to students and educators. The success of this project will improve the effectiveness of teaching computer programming and data science to students with BVI, which in turn will increase accessibility for more individuals with BVI to participate in Computing Science with high-paying career opportunities and could lead to a more-diverse Computer Science workforce. <br/> <br/>These accessibility tools will use compilers, Artificial Intelligence (AI), and cloud technologies to read computer code statements based on their meanings, rather than only reading one character at a time. The screen reader will articulate the necessary information that beginning coders need and help them more easily understand the lexicon and semantics used in computer programming and data science. The voice-command-based code navigation will employ speech recognition and natural language processing so that students will be able to use their voice to easily locate a specific statement (e.g., a variable declaration) within their code. These accessibility tools will be integrated into Jupyter notebook and offered through the cloud which will give nationwide access to students and educators. This cloud-based solution will also allow sophisticated AI models to be employed without requiring the students to have powerful and expensive computers to run these accessibility tools. The project will conduct a systematic evaluation of these accessibility tools using single-case research design to deepen the understanding of how technologies, including compilers, AI, and cloud computing, can be applied to teaching Computer Science skills to students with BVI. The evaluation will also provide feedback on the effectiveness of different speech styles and provide additional feedback for future improvements of these accessibility tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Workforce development; Accessibility and technology; Single-case Research Design,,"Natural language processing and speech technologies, Accessibility and technology, Machine learning, AI","AI,Software engineering,Computing technology","Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Pengbo Chu,"Interfacial phenomena e.g. fine particle/particle/bubble interaction, bubble acoustics, Particle tracking and image processing, Beneficiation of critical minerals from primary and secondary resources, Optimization of mineral processing systems using machine learning, data analytics, Development of enhanced dry processing techniques",,"Board of Regents, NSHE, obo University of Nevada, Reno",Mining and Metalurgical Engineering,,2202640,Impact of Utilizing Immersive Virtual Reality and Dynamic Assessment on Mining Engineering Education from the Community of Inquiry Perspective,"A qualified workforce for domestic mining production of critical minerals is essential to a clean energy transition. However, current U.S. mining engineering education programs are not adequately producing mining graduates with the desired qualifications. A lack of in-depth understanding of the scientific principles involved in mining engineering is one the primary factors prohibiting mining engineers from excelling in their duties. To improve the situation, innovations are needed to transform traditional mining engineering education. This project will study the application of immersive virtual reality (IVR) technology as an innovative tool to improve mining engineering education, with froth flotation as a test topic. Froth flotation is a complex three-phase mineral separation process that relies on interactions between physics, chemistry, and the flotation machine to recover valuable minerals. The project takes an interdisciplinary approach, with experts in mining engineering, computer science and engineering, cognitive psychology, learning analytics, and chemistry, working alongside multi-national mining companies to develop an IVR based platform for froth flotation education. Although the primary focus is on froth flotation, the IVR platform can be applied to a broad range of learning domains by substituting new content. The project also collaborates with the University Libraries @Reality Virtual + Augmented Reality Lab at the University of Nevada, Reno to promote learning with emerging technologies for a wide range of visitors, including university students and educators, Northern Nevada residents with their young children, and local K-12 students. <br/><br/>The project will be conducted with the community of inquiry (CoI) as the pedagogical framework and a dynamic assessment approach as a measurement tool. Three objectives will be achieved: 1) determining the implications of the CoI framework in an IVR environment in the context of froth flotation education, 2) developing dynamic assessment models to predict students‚Äô learning outcomes using the CoI indicators measured in the IVR environment, and 3) demonstrating to what extent the application of IVR observed within the CoI framework and augmented by dynamic assessment can enhance froth flotation education. The research outcomes can potentially advance the current state-of-the-art in three areas: 1) improving froth flotation education by adopting an innovative teaching and learning platform, 2) adding new knowledge to the science of education by understanding how the integration of the CoI framework and dynamic assessment can impact the efficacy of the IVR application, and 3) advancing IVR software engineering in terms of software specification, design and implementation, usability, and testing and evaluation. This project is a critical first step in addressing gaps in the preparation of a U.S. workforce for domestic mining of critical minerals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Cyber-enhanced/Computer-assisted assessments, Augmented/virtual/mixed reality, Engineering education, Learning analytics","Learning analytics,Graphics,Mineral processing,Chemistry,Machine learning,Mineral processing","Analytics,Other Disciplinary Areas,AI Approaches and Technologies",Mining and Metalurgical Engineering
Jung Hyup Kim,"Human-in-the-loop simulation, eye tracking, workload, metacognition, Situation awareness",,University of Missouri-Columbia,Industrial and manufacturing Systems Engineering,,2202108,Research on the Use of Real-Time Tracking and Eye-Tracking Technology for Integrating Metacognition and Augmented Reality into Undergraduate Engineering Laboratories,"This project aims to innovate Augmented Reality (AR) learning platforms in an undergraduate engineering laboratory. Recently, due to the COVID-19 pandemic, in-person engineering laboratories faced significant challenges in providing hands-on exercise. AR technology might be a solution to the current challenge. Unlike virtual reality, AR does not cover a physical world but mixes 3D virtual objects into physical objects to improve students‚Äô laboratory experiences and spatial awareness. However, students faced difficulties navigating the AR device and have experienced a mismatch between computer-generated 3D images and physical objects while learning in an AR environment. To transform AR learning from a static and isolated experience into a dynamic self-study, this project includes research on using a real-time tracking sensor with a 3D full-body motion capture system to improve AR usability and detect student‚Äôs premature termination of learning using metacognitive monitoring feedback and eye-tracking technology.  <br/><br/>The primary goal of this project is to integrate real-time 3D motion and location tracking systems to meet a series of objectives to gain insight into scientific development and technological innovation in a location-based AR environment. The first objective is to create the next generation of an AR learning platform by integrating state-of-the-art indoor real-time location technology and a 3D full-body motion capture system. The second objective is to detect the early termination of learning by using metacognitive monitoring feedback and eye movement data. The researchers will apply advanced gaze behavior metrics, such as fractal analysis of pupil dilation and eye inter-fixation duration, to identify significant eye gaze behavior representing student‚Äôs premature termination of learning. The last objective is to implement the research findings to promote instructional improvement in an engineering laboratory on the impact of receiving metacognitive feedback on learning performance. The current project will address integrated research and education activities to enhance our knowledge of effective undergraduate engineering laboratory education using real-time 3D motion and location tracking capabilities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Formative assessment, Augmented/virtual/mixed reality, Biometrics (e.g.,eye-tracking,EEG), Self-regulation,reflection and metacognition","Learning analytics,Research Partnerships,Biometrics (e.g. eye-tracking EEG),Human-AI Interaction,Self-regulation reflection and metacognition","Analytics,Learning Environments and Platforms,Capacity Building,Instruments Assessment and Measures,Learning Processes and Theories","Industrical Engineering, Manufacturing Engineering"
Martina Rau,"Multiple representations, intelligent tutoring systems, educational data mining, visual representations, representations competencies",Carnegie Mellon University,University of Wisconsin-Madison,School of Education,,2202457,Digitally Inoculating Viewers Against Visual Misinformation With a Perceptual Training,"Misinformation impedes people‚Äôs ability to make informed decisions in many areas, for example politics, health care, purchasing, or investing. Misinformation can be created by accident or intentionally. Misleading graphs are a particularly dangerous form of misinformation because they can make false information more believable and reach viewers faster. To combat misinformation in graphs, one needs to consider two aspects of graph comprehension: conceptual reasoning and perception. Prior research has focused on conceptual reasoning about graphs. Yet, because perception is automatic it is especially prone to false information in misleading graphs. This project focuses on perception. The investigators will develop a perceptual training method that helps viewers to extract correct information from misleading graphs. The perceptual training method will be provided as a web browser plugin. It will provide feedback as viewers see misleading graphs on the web. The investigators will use machine learning algorithms to design the perceptual training method. The project will advance scientific understanding of perception in graph comprehension. It will also develop machine learning algorithms for educational purposes. The project will provide new tools for addressing issues of misinformation. <br/><br/>Misinformation poses a severe risk to society. Misleading graphs are a type of visual misinformation that can quickly convey false information to viewers. While existing interventions for visual misinformation target conceptual processes, perceptual processes also play an important role. Perceptual processes are automatic and prone to biases. Visual misinformation often targets perceptual over conceptual processing. Therefore, this project directly targets perceptual processes. Investigators will develop a perceptual training method that will teach viewers to extract correct information from misleading graphs so that they become ‚Äúimmune‚Äù against visual misinformation. The perceptual training method will be delivered as a web browser plugin and will have two components. First, upon installing the browser plugin, viewers will receive a 2-minute massed training that will serve as the initial ‚Äúvaccine‚Äù against misleading graphs. Second, the browser plugin will deliver a spaced training by giving feedback when viewers encounter misleading graphs on the web, which serves as a ‚Äúbooster‚Äù for their immunity. The investigators will use machine learning algorithms to decide which type of feedback the perceptual training should offer and how often such feedback should be provided. Two randomized experiments will evaluate components of the perceptual training method while participants browse the web. This project will advance scientific understanding of perceptual learning, educational applications of machine learning algorithms, and will develop novel approaches to combat misinformation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Machine learning; Data visualization, representations, and dashboards; Misinformation; Cognitive psychology / Cognitive science",,"Machine learning, Data visualization,representations and dashboards","Cultural competence/responsiveness,Multimodal data analysis,Data mining,Data visualization representations and dashboards,Adaptive/Personalized learning and intelligent tutors","Analytics,Equity and Social Justice,AI Approaches and Technologies",Education
Evgeny Chukharev-Hudilainen,"Language processing, language acquisition, language change",Herzen State University of Russia,Iowa State University,Department of English,,2230225,Collaborative Research: Conference: Promoting Cross-Disciplinary Dialogue Between Experts in Argumentation and Innovative Technologies,"Helping students develop the ability to construct high-quality arguments and to engage in productive argumentation with others is now widely seen as an essential goal of schooling that should be at the forefront of our efforts to develop an educated citizenry. From major policy documents, academic publications, and the popular press, we hear the call for teachers to prepare their students to make well-reasoned judgments about complex, controversial issues. Today, students are expected to actively engage in knowledge construction through inquiry and argumentation, by asking questions, defining problems, challenging the ideas of others, formulating their own positions, and supplying reasons and evidence for what otherwise would be unsupported opinions. These ambitious educational goals call for profound changes in the roles and responsibilities traditionally assigned to students and teachers. They require creative solutions, which include the use of innovative pedagogies and technologies.<br/><br/>This project will organize a workshop to support a dialogue among scholars in argumentation and technology, creating a shared space for researchers to discuss existing barriers and blind spots and engage in cross-disciplinary collaboration. During the two-day, online workshop, participants will present innovative research in their respective fields and form cross-disciplinary teams to discuss opportunities for joint projects and grant applications. In addition, participants will complete an open-ended online survey to address ideas, barriers, and opportunities for continued collaboration. They will also evaluate their experience during the workshop and suggest improvements for promoting dialogue between the fields of argumentation and technology. The workshop will bring together learning scientists specializing in research on argumentation and computer science experts developing innovative technologies, thus supporting frontier research in both fields. It will survey existing challenges in argumentation and technology, identify additional areas of concern, explore possible solutions, and create new opportunities for cross-disciplinary collaboration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Modeling and simulation (including agent-based modeling); Natural language processing and speech technologies; Argumentation; Inquiry learning (e.g., project/problem based learning)",,Workshop,"Natural language processing and speech technologies,Cognitive psychology / Cognitive science,Spoken language","Learning Processes and Theories,Other Disciplinary Areas,AI Approaches and Technologies",English
Alina Reznitskaya,"educational psychology, quantitative research methodology, educational measurement, pedagogic theory, teacher education, teaching methods",,Montclair State University,Education and Human Services,,2230224,Collaborative Research: Conference: Promoting Cross-Disciplinary Dialogue Between Experts in Argumentation and Innovative Technologies,"Helping students develop the ability to construct high-quality arguments and to engage in productive argumentation with others is now widely seen as an essential goal of schooling that should be at the forefront of our efforts to develop an educated citizenry. From major policy documents, academic publications, and the popular press, we hear the call for teachers to prepare their students to make well-reasoned judgments about complex, controversial issues. Today, students are expected to actively engage in knowledge construction through inquiry and argumentation, by asking questions, defining problems, challenging the ideas of others, formulating their own positions, and supplying reasons and evidence for what otherwise would be unsupported opinions. These ambitious educational goals call for profound changes in the roles and responsibilities traditionally assigned to students and teachers. They require creative solutions, which include the use of innovative pedagogies and technologies.<br/><br/>This project will organize a workshop to support a dialogue among scholars in argumentation and technology, creating a shared space for researchers to discuss existing barriers and blind spots and engage in cross-disciplinary collaboration. During the two-day, online workshop, participants will present innovative research in their respective fields and form cross-disciplinary teams to discuss opportunities for joint projects and grant applications. In addition, participants will complete an open-ended online survey to address ideas, barriers, and opportunities for continued collaboration. They will also evaluate their experience during the workshop and suggest improvements for promoting dialogue between the fields of argumentation and technology. The workshop will bring together learning scientists specializing in research on argumentation and computer science experts developing innovative technologies, thus supporting frontier research in both fields. It will survey existing challenges in argumentation and technology, identify additional areas of concern, explore possible solutions, and create new opportunities for cross-disciplinary collaboration.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Workshop,"Cognitive psychology / Cognitive science,Educator professional learning,Quantitative Methods,Pedagogy","Research Methods,Capacity Building,Learning Processes and Theories,Other Disciplinary Areas","Education, Psychology"
Elisa Shernoff,evidence-based culturally responsive interventions with teachers and students in underrepresented communities,,Rutgers University,Applied and Professional Psychology,,2119265,The Role of Agency and Interactivity in Embodied Conversational Agents to Support Teacher Training in High Poverty Schools,"Challenges with classroom behavior management predicts teacher stress and attrition and support for behavior management is a top professional priority identified by teachers. Traditional training for teachers in behavior management (e.g., workshops, whole group in-service training) has failed to produce substantial improvements in teachers‚Äô work-related knowledge and skills. Virtual Reality-based training provides an opportunity for teachers to practice responding positively to disruptive behaviors with the freedom to explore and fail in a low-stakes setting. However, existing  platforms suffer from low usability and limited realism, particularly when simulating conversational interactions. This project offers a synergistic exploration of the educational impact of immersive, conversational learning environments, and the fundamental technical capabilities for building intelligent virtual agents. Specifically, the aim of the project is to systematically study the impact of embodied conversational agents on learning outcomes of teachers in high poverty schools, where discipline disparities and exclusionary discipline practices are prominent and positive discipline approaches are needed to promote engagement and learning.<br/><br/>This project supports the development and release of a new platform for specifying embodied conversational interaction, combining recent advances in intelligent virtual agents, generative modeling of communicative behavior, and human-in-the-loop design. The project outcomes will push the boundaries of agency and interactivity in virtual reality training platforms, where teachers can fully immerse themselves in virtual classrooms and engage with autonomous virtual students capable of expressing themselves using facial expressions, hand and body gestures, and spoken language. These free-form interactions are theorized to support transfer of learning from one setting (e.g., virtual classroom) to a new setting (e.g., live classroom), where teachers may carry forward applicable knowledge and skills. The research plan includes a series of studies over a 3-year time period, to systematically study the impact of agency and interactivity in virtual training platforms on the training outcomes of teachers, and their ability to transfer knowledge and skills to real classrooms. This type of training in behavior management provides an unique opportunity to augment existing support to teachers and foster the dissemination and implementation of effective training that can ultimately enhance student achievement and student/teacher well-being.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality,,"Augmented/virtual/mixed reality, Workshop, Modeling and simulation (including agent-based modeling)","Culturally responsive,Broadening participation of historically marginalized groups",Equity and Social Justice,Psychology
Matthew Stone,"Natural Language Generation, Computational Semantics, Knowledge Representation, Conversational Agents",,Rutgers University,Computer Science,,2119265,The Role of Agency and Interactivity in Embodied Conversational Agents to Support Teacher Training in High Poverty Schools,"Challenges with classroom behavior management predicts teacher stress and attrition and support for behavior management is a top professional priority identified by teachers. Traditional training for teachers in behavior management (e.g., workshops, whole group in-service training) has failed to produce substantial improvements in teachers‚Äô work-related knowledge and skills. Virtual Reality-based training provides an opportunity for teachers to practice responding positively to disruptive behaviors with the freedom to explore and fail in a low-stakes setting. However, existing  platforms suffer from low usability and limited realism, particularly when simulating conversational interactions. This project offers a synergistic exploration of the educational impact of immersive, conversational learning environments, and the fundamental technical capabilities for building intelligent virtual agents. Specifically, the aim of the project is to systematically study the impact of embodied conversational agents on learning outcomes of teachers in high poverty schools, where discipline disparities and exclusionary discipline practices are prominent and positive discipline approaches are needed to promote engagement and learning.<br/><br/>This project supports the development and release of a new platform for specifying embodied conversational interaction, combining recent advances in intelligent virtual agents, generative modeling of communicative behavior, and human-in-the-loop design. The project outcomes will push the boundaries of agency and interactivity in virtual reality training platforms, where teachers can fully immerse themselves in virtual classrooms and engage with autonomous virtual students capable of expressing themselves using facial expressions, hand and body gestures, and spoken language. These free-form interactions are theorized to support transfer of learning from one setting (e.g., virtual classroom) to a new setting (e.g., live classroom), where teachers may carry forward applicable knowledge and skills. The research plan includes a series of studies over a 3-year time period, to systematically study the impact of agency and interactivity in virtual training platforms on the training outcomes of teachers, and their ability to transfer knowledge and skills to real classrooms. This type of training in behavior management provides an unique opportunity to augment existing support to teachers and foster the dissemination and implementation of effective training that can ultimately enhance student achievement and student/teacher well-being.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality,,"Augmented/virtual/mixed reality, Workshop, Modeling and simulation (including agent-based modeling)","Natural language processing and speech technologies,Pedagogical agents,AI knowledge representation and reasoning",AI Approaches and Technologies,Computer Science
Breanne Litts,designing at the intersection of physical and digital worlds,,Utah State University,Instructional Technology and Learning Sciences,,2119573,Transformative Computational Models of Narrative to Support Teaching Indigenous Perspectives in K-12 Classrooms,"This project will contribute to the national need for sharing Indigenous perspectives in US K-12 education. By providing accurate representations of Indigenous narratives within social studies curricula, this project will address misconceptions of Indigenous peoples and their communities. The project will mitigate potential impacts of misrepresentations such as cultural identity silencing, disconnection, and lower graduation rates for Indigenous students and lack of cultural competence for non-Indigenous students. Often, Tribal Knowledge Holders visit classrooms and share their histories and perspectives class by class, which has the potential to overburden Indigenous communities. Technology can support both teachers and Indigenous communities to develop sustainable processes and practices to appropriately preserve and share Indigenous knowledge, culture, and perspectives. To date, little work has examined the role of Indigenous representation in the creation of narrative technologies designed to mitigate the lack of Indigenous representation in the classroom. This project will develop emerging narrative technologies from an Indigenous perspective to support teachers and classroom learning. The broader impact of the work includes benefits for tribal communities, K-12 educators, and policymakers, and other community and education organizations that wish to expand representations of diverse knowledge, cultures, education, and computations.<br/><br/>The proposed work builds on existing efforts to address pressing issues of bias embedded in emerging technologies and expand current notions of how to design new forms of technology for more equitable futures. The proposed project will deconstruct and culturally reformulate the basis of emerging technologies: the underlying computational models, data, algorithms, and interfaces. The overarching research question is: What does a culturally sustaining/revitalizing computational model of Indigenous narrative(s) look like? Building on an existing partnership with the Northwestern Band of the Shoshone Nation and K-12 teachers, the project team will use the social studies classroom as a design context to address issues of representation of Indigenous knowledge and culture via computational models. The proposed work seeks to empower Tribal members to (re)engage technologies that have historically perpetuated disparities and caused significant harm to their community to develop prototypes that represent their ways of being and knowing. The prototypes will be Tribally-created design experiences that preserve Indigenous history and effectively share it with students in fourth grade classrooms. This project will offer empirical insights for effective strategies and processes of how to engage Indigenous communities through a community-driven design methodological approach. The project has the potential to reimagine not only how models and algorithms are designed, but also who designs them. This project will inform and advance diverse fields including computer science, learning sciences, psychology, Indigenous education, teacher education, and social studies education.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Identity, Motivation and engagement, Broadening participation of historically marginalized groups, Cultural competence/responsiveness, Bias and equity in AI",,,"Learning Sciences, Curriculum and Instruction"
Melissa Malzkuhn,"creative literature and digital technology techniques to create immersive learning experiences- from storybook apps, motion-capture projects that build signing avatars- all of which expand the 3D technology landscape for deaf children, visual learners.",,Gallaudet University,Motion Light Lab,,2118742,New Dimensions of ASL Learning: Implementing and Testing Signing Avatars & Immersive Learning (SAIL 2),"The highly-spatial three-dimensional nature of American Sign Language (ASL) has created a serious barrier to technology-supported ASL instruction. What if ASL learners could access high-quality ASL instruction from native sign language instructors through a virtual reality-based, game-like environment? This project launches from prior work on the NSF-funded Signing Avatars & Immersive Learning (SAIL) project. The SAIL project yielded a working prototype of an immersive sign language learning environment in virtual reality. The current project expands past the prototype stage into a fully-fledged ASL learning experience. In the new version of SAIL, called SAIL 2, the research team is developing a more complete system where users enter virtual reality and interact with signing avatars (computer-animated virtual humans built from motion capture recordings) who teach users ASL vocabulary. Access to signed language is key to healthy development for many deaf individuals, but it remains a major challenge when access to high quality ASL instruction in limited by time and resources. SAIL 2 sets a foundation for greater access to learning ASL, which has potential for improving the lives of deaf children and adults. The project focuses on developing and testing this entirely novel ASL learning tool and fostering the inclusion of underrepresented minorities in STEM. This work has the potential to substantially advance the fields of virtual reality, ASL instruction, and embodied learning.<br/><br/>Immersive virtual reality is particularly well suited for highly spatial signed languages. The SAIL 2 project leverages head-mounted virtual reality and high-quality signing avatars to create a gamified ASL-learning system. SAIL 2 will be the only ASL learning system in virtual reality which does not require the user to wear specialized gloves or other peripheral devices. The project develops a functioning version of the comprehensive SAIL 2 system, and user testing during the design process guides the details of development. Key features of the system include sign recognition through hand tracking cameras, corrective feedback, and a gamified experience. Following the design and development of SAIL 2, the research team conducts behavioral research to evaluate the learning outcomes of SAIL 2. Evaluation of specific learning outcomes includes both understanding of ASL vocabulary and accuracy of sign production. Because of the embodied nature of signed language, mechanistic measures of the neural substrates of learning, including engagement of the sensorimotor cortices, are obtained through electroencephalography (EEG). The patterns of neural oscillatory activity provide insight into short-term changes in brain activity associated with using SAIL 2. The cognitive neuroscience experiment builds on previous research identifying the neural processes supporting sign language perception, and overall this project extends technological advances in high-fidelity motion capture recordings, avatar creation, and virtual reality.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Inclusive/universal design; Biometrics (e.g., eye-tracking, EEG); Augmented/virtual/mixed reality; Embodied learning and cognition",,"Augmented/virtual/mixed reality, Neuroscience, Accessibility and technology, Literacy (e.g.,reading/reading comprehension,writing,language learning), Games and game making, Embodied learning and cognition, Biometrics (e.g.,eye-tracking,EEG)","Pedagogical agents,Creativity,Inquiry learning (e.g. project/problem based learning),Data visualization representations and dashboards","Learning Processes and Theories,Analytics,AI Approaches and Technologies","Computer Science, Human-Computer Interaction"
Issifu Harruna,Chemistry,,Clark Atlanta University,Chemistry,,2106938,Targeted Infusion Project: Technology Enhanced Education and Practices for Success (TEEPS) in Undergraduate Organic Chemistry at Clark Atlanta University,"The Historically Black Colleges and Universities Undergraduate Program (HBCU-UP) through Targeted Infusion Projects supports the development, implementation, and study of evidence-based innovative models and approaches for improving the preparation and success of HBCU undergraduate students so that they may pursue science, technology, engineering, or mathematics (STEM) graduate programs and/or careers. The project at Clark Atlanta University seeks to improve faculty and students‚Äô teaching and learning experience by revising the sophomore organic chemistry courses to include technological interventions. The project aims to hone students‚Äô ability to utilize and apply advanced technologies to ultimately, increase student preparedness for future STEM graduate and career opportunities.<br/><br/>The goals of this project are to: (1) enhance the quality of the sophomore organic chemistry courses by implementing new technology including visualization, computation, active learning, artificial intelligence, and virtual reality (VC+ALAIVR) and (2) implement the evidence-based practices of faculty-graduate student team mentoring and early intervention/advising. The team of faculty, graduate student teaching assistants (GTAs) and supplemental instructors (SI) will work collaboratively in creating a question bank of 5,000+ questions for student use. CAU‚Äôs undergraduate students will use cyberinfrastructure technological tools for learning organic chemistry. Professional training for the faculty, coupled with the questions database with answers and multimedia tools/presentations has the potential to impact hundreds of students via delivery of the courses with technology implementation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, AI, Science education, Broadening participation of historically marginalized groups",Science education,Disciplinary Areas,Chemistry
Conrad Ingram,Chemistry,,Clark Atlanta University,Chemistry,,2106938,Targeted Infusion Project: Technology Enhanced Education and Practices for Success (TEEPS) in Undergraduate Organic Chemistry at Clark Atlanta University,"The Historically Black Colleges and Universities Undergraduate Program (HBCU-UP) through Targeted Infusion Projects supports the development, implementation, and study of evidence-based innovative models and approaches for improving the preparation and success of HBCU undergraduate students so that they may pursue science, technology, engineering, or mathematics (STEM) graduate programs and/or careers. The project at Clark Atlanta University seeks to improve faculty and students‚Äô teaching and learning experience by revising the sophomore organic chemistry courses to include technological interventions. The project aims to hone students‚Äô ability to utilize and apply advanced technologies to ultimately, increase student preparedness for future STEM graduate and career opportunities.<br/><br/>The goals of this project are to: (1) enhance the quality of the sophomore organic chemistry courses by implementing new technology including visualization, computation, active learning, artificial intelligence, and virtual reality (VC+ALAIVR) and (2) implement the evidence-based practices of faculty-graduate student team mentoring and early intervention/advising. The team of faculty, graduate student teaching assistants (GTAs) and supplemental instructors (SI) will work collaboratively in creating a question bank of 5,000+ questions for student use. CAU‚Äôs undergraduate students will use cyberinfrastructure technological tools for learning organic chemistry. Professional training for the faculty, coupled with the questions database with answers and multimedia tools/presentations has the potential to impact hundreds of students via delivery of the courses with technology implementation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, AI, Science education, Broadening participation of historically marginalized groups",Science education,Disciplinary Areas,Chemistry
Xinle Li,Chemistry,,Clark Atlanta University,Chemistry,,2106938,Targeted Infusion Project: Technology Enhanced Education and Practices for Success (TEEPS) in Undergraduate Organic Chemistry at Clark Atlanta University,"The Historically Black Colleges and Universities Undergraduate Program (HBCU-UP) through Targeted Infusion Projects supports the development, implementation, and study of evidence-based innovative models and approaches for improving the preparation and success of HBCU undergraduate students so that they may pursue science, technology, engineering, or mathematics (STEM) graduate programs and/or careers. The project at Clark Atlanta University seeks to improve faculty and students‚Äô teaching and learning experience by revising the sophomore organic chemistry courses to include technological interventions. The project aims to hone students‚Äô ability to utilize and apply advanced technologies to ultimately, increase student preparedness for future STEM graduate and career opportunities.<br/><br/>The goals of this project are to: (1) enhance the quality of the sophomore organic chemistry courses by implementing new technology including visualization, computation, active learning, artificial intelligence, and virtual reality (VC+ALAIVR) and (2) implement the evidence-based practices of faculty-graduate student team mentoring and early intervention/advising. The team of faculty, graduate student teaching assistants (GTAs) and supplemental instructors (SI) will work collaboratively in creating a question bank of 5,000+ questions for student use. CAU‚Äôs undergraduate students will use cyberinfrastructure technological tools for learning organic chemistry. Professional training for the faculty, coupled with the questions database with answers and multimedia tools/presentations has the potential to impact hundreds of students via delivery of the courses with technology implementation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, AI, Science education, Broadening participation of historically marginalized groups",Science education,Disciplinary Areas,Chemistry
Lydia Davenport,Educator preparation and certification,,Alabama A&M University,Center for Education Preparation and Certification Services,,2107293,Catalyst Project: Development and Implementation of Intelligent Adaptive Cyberlearning System for Minority Freshmen Students,"Catalyst Projects provide support for Historically Black Colleges and Universities (HBCU) to work towards establishing research capacity of faculty to strengthen science, technology, engineering and mathematics undergraduate education and research. It is expected that the award will further the faculty member's research capability, improve research and teaching at the institution, and involve undergraduate students in research experiences. Alabama A & M University intends to develop and implement an adaptive cyberlearning system to support student education and learning in freshmen-level mathematics courses. This cyberlearning approach seeks to lay the foundation for enhancing student engagement in mathematics, leading to long-term persistence in STEM and serving as a model for other institutional contexts.  <br/><br/>The primary goal of this project is to develop and utilize an innovative, transformative, and focused approach to improve students‚Äô learning and performance of Pre-Calculus Algebra skills at Alabama Agricultural and Mechanical University (AAMU). Central to the approach is an adaptive cyberlearning system referred to as MATH-CyLE. Students and instructors will utilize MATH-CyLE‚Äôs digital learning content and embedded learning and engagement strategies to support pedagogy and provide students with an intelligent interactive adaptive system to support their individualized learning. The impact of the cyberlearning system will be investigated to determine whether there are improvements to the indirect learning of students who use MATH-CyLE, as compared to students who receive traditional instruction.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Adaptive/Personalized learning and intelligent tutors,Educator professional learning,Capacity Building,"Education, Outreach"
Jacob Oluwoye,Transportation and environmental health,,Alabama A&M University,Community and Regional planning,,2107293,Catalyst Project: Development and Implementation of Intelligent Adaptive Cyberlearning System for Minority Freshmen Students,"Catalyst Projects provide support for Historically Black Colleges and Universities (HBCU) to work towards establishing research capacity of faculty to strengthen science, technology, engineering and mathematics undergraduate education and research. It is expected that the award will further the faculty member's research capability, improve research and teaching at the institution, and involve undergraduate students in research experiences. Alabama A & M University intends to develop and implement an adaptive cyberlearning system to support student education and learning in freshmen-level mathematics courses. This cyberlearning approach seeks to lay the foundation for enhancing student engagement in mathematics, leading to long-term persistence in STEM and serving as a model for other institutional contexts.  <br/><br/>The primary goal of this project is to develop and utilize an innovative, transformative, and focused approach to improve students‚Äô learning and performance of Pre-Calculus Algebra skills at Alabama Agricultural and Mechanical University (AAMU). Central to the approach is an adaptive cyberlearning system referred to as MATH-CyLE. Students and instructors will utilize MATH-CyLE‚Äôs digital learning content and embedded learning and engagement strategies to support pedagogy and provide students with an intelligent interactive adaptive system to support their individualized learning. The impact of the cyberlearning system will be investigated to determine whether there are improvements to the indirect learning of students who use MATH-CyLE, as compared to students who receive traditional instruction.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Adaptive/Personalized learning and intelligent tutors,Environmental Science,Other Disciplinary Areas,Social Sciences
Peter Clarke,"Software testing, software metrics, model-driven software development, domain-specific modeling languages, computer science education.",,Florida International University,Computing and Information Sciences,,2107293,Catalyst Project: Development and Implementation of Intelligent Adaptive Cyberlearning System for Minority Freshmen Students,"Catalyst Projects provide support for Historically Black Colleges and Universities (HBCU) to work towards establishing research capacity of faculty to strengthen science, technology, engineering and mathematics undergraduate education and research. It is expected that the award will further the faculty member's research capability, improve research and teaching at the institution, and involve undergraduate students in research experiences. Alabama A & M University intends to develop and implement an adaptive cyberlearning system to support student education and learning in freshmen-level mathematics courses. This cyberlearning approach seeks to lay the foundation for enhancing student engagement in mathematics, leading to long-term persistence in STEM and serving as a model for other institutional contexts.  <br/><br/>The primary goal of this project is to develop and utilize an innovative, transformative, and focused approach to improve students‚Äô learning and performance of Pre-Calculus Algebra skills at Alabama Agricultural and Mechanical University (AAMU). Central to the approach is an adaptive cyberlearning system referred to as MATH-CyLE. Students and instructors will utilize MATH-CyLE‚Äôs digital learning content and embedded learning and engagement strategies to support pedagogy and provide students with an intelligent interactive adaptive system to support their individualized learning. The impact of the cyberlearning system will be investigated to determine whether there are improvements to the indirect learning of students who use MATH-CyLE, as compared to students who receive traditional instruction.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Adaptive/Personalized learning and intelligent tutors,"Computer science education,Software engineering,Modeling and simulation (including agent-based modeling),Machine learning,Modeling and simulation (including agent-based modeling),Software engineering","Other Disciplinary Areas,AI Approaches and Technologies,Disciplinary Areas","Computer Science, Information Science"
Anjan Biswas,Mathematics,,Alabama A&M University,Mathematics,,2107293,Catalyst Project: Development and Implementation of Intelligent Adaptive Cyberlearning System for Minority Freshmen Students,"Catalyst Projects provide support for Historically Black Colleges and Universities (HBCU) to work towards establishing research capacity of faculty to strengthen science, technology, engineering and mathematics undergraduate education and research. It is expected that the award will further the faculty member's research capability, improve research and teaching at the institution, and involve undergraduate students in research experiences. Alabama A & M University intends to develop and implement an adaptive cyberlearning system to support student education and learning in freshmen-level mathematics courses. This cyberlearning approach seeks to lay the foundation for enhancing student engagement in mathematics, leading to long-term persistence in STEM and serving as a model for other institutional contexts.  <br/><br/>The primary goal of this project is to develop and utilize an innovative, transformative, and focused approach to improve students‚Äô learning and performance of Pre-Calculus Algebra skills at Alabama Agricultural and Mechanical University (AAMU). Central to the approach is an adaptive cyberlearning system referred to as MATH-CyLE. Students and instructors will utilize MATH-CyLE‚Äôs digital learning content and embedded learning and engagement strategies to support pedagogy and provide students with an intelligent interactive adaptive system to support their individualized learning. The impact of the cyberlearning system will be investigated to determine whether there are improvements to the indirect learning of students who use MATH-CyLE, as compared to students who receive traditional instruction.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Adaptive/Personalized learning and intelligent tutors,Math education,Disciplinary Areas,Mathematics
Jennifer Richardson,"Online Learning, E-Learning, Technology Integration, Professional Development, Instructional Technology, Educational Evaluation, Instructional Design, Teaching and Learning, Technology Enhanced Learning, Teacher Training, Learning, Teaching",,Purdue University,Curriculum and Instruction,,2113991,Productive Online Teamwork Engagement Through Intelligent Mediation,"Modern work environments are becoming increasingly distributed. As a result, the ability of employees to work in a virtual environment is becoming essential for corporate success. Employers expect higher education institutions to prepare students to operate as productive members and leaders of virtual teams. While research has built compelling pedagogical frameworks to improve in-class teamwork performance, more research-based mechanisms are needed to maximize student engagement and build teamwork skills in online education environments. Focusing on large enrollment courses in higher education, this project will study the use of effective teamwork in the online classroom by (1) developing and testing technologies that promote social presence, (2) identifying pedagogies that facilitate teamwork in an online environment, and (3) promoting productive online teamwork engagement.<br/><br/>To promote productive online teamwork engagement, this design-based research project will develop the PECAS Mediator, an educational innovation that provides (1) AI-enabled monitoring, (2) productive and unproductive interaction detection, and (3) faculty mediation via just-in-time guidance. The high-level conjecture of this project is that monitoring and mediation, enabled by evidence-based pedagogical practices and technological innovations, will increase social presence within online teamwork sessions resulting in increased teamwork engagement. The project has two main objectives: (1) Deploy and validate the intelligent monitoring and mediation PECAS Mediator to promote social presence and collaborative learning, and (2) Investigate the effect of increased social presence and collaborative learning on teamwork engagement. The theoretical conjecture of this project is that social presence mediating processes will lead to productive engagement manifested as behavioral engagement via team effectiveness, cognitive engagement via team performance, and affective engagement via positive attitudes toward teamwork.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Teamwork pedagogy; Workforce development; Online learning; Design-based research (DBR),,"Design-based research (DBR), Collaborative and/or participatory learning, AI","Instructional Design,Educator professional learning,Online learning,Pedagogy,Software engineering,Evaluation","Capacity Building,Other Disciplinary Areas,Learning Environments and Platforms",Curriculum and Instruction
Mina Johnson-Glenberg,XR for education,,Arizona State University,Herberger Institute for Design and the Arts,,2114586,Combining Smartphone Light Detection and Ranging with Augmented Reality to Enhance Position-Based Teaching and Learning in STEM,"Understanding how to measure, display, and interpret motion is important for many STEM-related careers, particularly in the physical and data sciences. Educational researchers have advocated for numerous approaches to support sense-making with mathematical models of motion, but teachers often struggle to enact them due to limited resources. This project will make high-precision position sensing a reality for anyone who owns a smartphone by building on light-based mobile sensors (LiDAR) that are able to detect one‚Äôs distance from objects and location within a space. The educational research will measure the effect of using this new technology to improve student learning and engagement with regard to mathematical models with motion graphs, by producing a classroom-ready application and gamified lessons for teachers and students to use in traditional classrooms as well as the home. <br/><br/>Researchers and educational software developers will develop new data visualization technology based on iOS‚Äô scanning LiDAR and Android‚Äôs time-of-flight depth imaging. The proposed technological innovation will make use of the novel back-facing infrared beam array to significantly increase precision in position measurements and the placement of augmented reality (AR) visualizations based on users‚Äô movements and environmental data. This project will determine the extent to which LiDAR-aided AR technology can enable high-precision, position-based, and real-time data visualization. It will explore how the new technology can provide the kind of cognitive scaffolding and embodied experiences needed for advancing teaching about modeling motion with graphs and vectors. Research in the learning sciences will entail a collaboration with STEM educators to develop and test the effectiveness of scenarios for exploration in traditional and remote learning contexts. This proposal will assess full-body movement to make sense of motion graphs with a focus on embodied learning and practice with data visualization literacy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Data visualization, representations, and dashboards; Community partnerships; Augmented/virtual/mixed reality; Embodied learning and cognition",,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Science education, Data science education",Augmented/virtual/mixed reality,Learning Environments and Platforms,Arts and Sciences
Robert Clements,"Biomedical Imaging and Visualization, Virtual Reality, Automated Data Anaylsis, Biomaterials, Nuclear Magnetic Resonance, Neuroendocrinology, Haptics",,Kent State University,Biology,,2118380,Bimodal Haptic-Mixed Reality (HMR) Needle Insertion Simulation for Hand-Eye Skills,"Although performing intravenous (IV) insertion is a very common medical procedure, it is technically difficult to master as demonstrated by the 35%-50% failure rate resulting in a negative cycle of re-insertions leading to increased patient harm and costs to the healthcare system. Faulty IV insertions in real-world conditions are related to vein variables (vein rolling or resistant to puncture) and patient variables (touch skin, skin coloring). Experts in nursing education have advocated for self-paced integration of simulation-based technologies to deliberately practice IV skills while receiving immediate feedback for error correction. However, using currently developed simulators or manikin arms fails to capture the actual realism and psychomotor techniques adaptive to variability needed to gain procedural mastery of the skill. To enhance the current learning environment, technological advances are needed to create a realistic learning platform with variability that maximizes the skill transfer and long-term retention. The proposed work is to fill the gap by developing a novel simulation system using haptics and mixed reality (HMR) and investigating the learning impacts. This work is significant because current haptic technologies combined with extended reality do not yet provide sufficient realism and variability to effectively develop the fine motor skills. Further, studies have not been conducted on the educational impact of bimodal HMR simulation with variable conditions that can adaptively create realistic patient environments during training. Upon developing the successful nature of the proposed research, new insight into effective learning technology as well as causes of improved learning in hand-eye skills will be provided, which may be used to improve learning in similar settings or be transformative to other fields such as cyber teaching and learning, hand skill training at work, immersive dexterous interfaces, motor skill development for people with disabilities, STEM learning, robotic surgery, and medical training.<br/><br/>This project will develop a bimodal HMR system, using emerging technologies, haptics and MR, to simulate IV needle insertion with variable conditions that will create a realistic learning environment for students to master insertion tactile skills using two hands; and investigate whether variability in practice (disuse theory) improves needle insertion skills. To achieve these goals, the project will be divided into two phases: Phase I and II. Phase I will focus on developing the bimodal haptic simulation using two complimentary haptic devices, a haptic glove and a stylus haptic device, integrated with MR to simulate virtual patients and IV needle insertion with variable training conditions (skin color and stiffness, vein rolled, or resistant to puncture). In Phase II studies, 360 (180 per year) nursing students will be randomly assigned to experience training sessions in one of the three modes (HMR-static, HMR-variable, manikin arm). To measure learners‚Äô IV insertion skills, trained evaluators (faculty members) from the College of Nursing will observe and evaluate participants‚Äô skills based on an established IV insertion skill checklist through exams. Post training surveys will be collected in terms of the realism and the user experience (usability) and those data will be used for continuously improving the HMR system. This research will advance the knowledge related to developing innovative learning and teaching environments using emerging technologies and provide empirical evidence of impactful variables that affect learning performance. The developed platform as an automatic self-practice system will provide free access to this medium for instructors and students alike in healthcare or related communities to extend and use even under a pandemic, for broadening participation for under-represented and financially challenged groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Accessibility and technology; Augmented/virtual/mixed reality; Communities for learning; User-centered design,,"Augmented/virtual/mixed reality, Modeling and simulation (including agent-based modeling), Science education","Graphics,Physcial Sciences,Medicine,Data mining,Augmented/virtual/mixed reality,Biometrics (e.g. eye-tracking EEG),Interactive Displays","Instruments Assessment and Measures,Analytics,Other Disciplinary Areas,Learning Environments and Platforms",Biology
Bedrich Benes,"Computer Graphics, Geometric Modeling, Computer Science, Procedural Modeling, Graphics",,Purdue University,Computer Science,,2113991,Productive Online Teamwork Engagement Through Intelligent Mediation,"Modern work environments are becoming increasingly distributed. As a result, the ability of employees to work in a virtual environment is becoming essential for corporate success. Employers expect higher education institutions to prepare students to operate as productive members and leaders of virtual teams. While research has built compelling pedagogical frameworks to improve in-class teamwork performance, more research-based mechanisms are needed to maximize student engagement and build teamwork skills in online education environments. Focusing on large enrollment courses in higher education, this project will study the use of effective teamwork in the online classroom by (1) developing and testing technologies that promote social presence, (2) identifying pedagogies that facilitate teamwork in an online environment, and (3) promoting productive online teamwork engagement.<br/><br/>To promote productive online teamwork engagement, this design-based research project will develop the PECAS Mediator, an educational innovation that provides (1) AI-enabled monitoring, (2) productive and unproductive interaction detection, and (3) faculty mediation via just-in-time guidance. The high-level conjecture of this project is that monitoring and mediation, enabled by evidence-based pedagogical practices and technological innovations, will increase social presence within online teamwork sessions resulting in increased teamwork engagement. The project has two main objectives: (1) Deploy and validate the intelligent monitoring and mediation PECAS Mediator to promote social presence and collaborative learning, and (2) Investigate the effect of increased social presence and collaborative learning on teamwork engagement. The theoretical conjecture of this project is that social presence mediating processes will lead to productive engagement manifested as behavioral engagement via team effectiveness, cognitive engagement via team performance, and affective engagement via positive attitudes toward teamwork.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Teamwork pedagogy; Workforce development; Online learning; Design-based research (DBR),,"Design-based research (DBR), Collaborative and/or participatory learning, AI","Graphics,Data visualization representations and dashboards",Analytics,Computer Science
Stacy Shaw,"Rest, Math Axiety, Mathematics education, creativity, transfer students",,Worcester Polytechnic Institute,Sociial Science and Policy Studies; Learning Sciences and technology,,2118725,Collaborative Research: Common Error Diagnostics and Support in Short-answer Math Questions,"One important way to help struggling students improve in math is to deliver personalized support that addresses their specific weaknesses. Many math questions have common wrong answers (CWAs) that correspond to specific errors students make during their answering process, caused by misconceptions or a general lack of knowledge on certain math skills. To date, CWA identification and support remains a labor-intensive process at a limited scale because it requires significant effort by teachers and/or domain experts. In this project, the investigators will develop artificial intelligence (AI)-based mechanisms that can automatically identify CWAs from students‚Äô answers to short-answer math questions and diagnose errors. Once these errors are identified, the investigators will enlist the help of teachers to design feedback and support mechanisms in various formats such as textual feedback messages and short videos. In turn, the investigators will integrate these diagnosis and effective support mechanisms into a teacher interface to support them in either classrooms or online learning environments. Overall, this project has the potential to lead to i) better understanding of CWAs in math questions and the underlying errors and ii) effective CWA support mechanisms for each error type. The project will be grounded in ASSISTments, a free web-based learning platform, therefore directly benefiting the 500,000 US students and 20,000 teachers using it and potentially an even larger number of students and teachers through the dissemination of research findings.<br/> <br/>This project consists of four main research activities. First, the investigators will leverage math expression embedding methods to learn the representations of student errors by clustering CWAs across multiple questions in the latent math expression embedding vector space. These learned representations will enable the automated diagnosis of student errors in real time. Second, the investigators will develop new knowledge tracing algorithms that go beyond typical correctness analysis and analyze the full answer each student submits to each question. These algorithms will enable the automated tracking of students‚Äô progress in correcting their errors. Third, the investigators will crowdsource multiple types of student support from teachers and integrate both student error diagnostics and support mechanisms into the existing ASSISTments teacher interface. This interface will provide feedback to teachers on which students are struggling in real time and recommend a support, which the teacher can either adopt and customize or reject and create their own support instead. Fourth, the investigators will conduct a randomized controlled trial to evaluate the effectiveness of each support mechanism in helping students correct their errors. This experiment will identify which support mechanisms are most effective at helping students correct each error type and improving learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Online learning, Cyber-enhanced/Computer-assisted assessments, Formative assessment, AI, Math education","Math education,Software engineering,Creativity,Math education,Mental health","Learning Processes and Theories,Equity and Social Justice,Other Disciplinary Areas,Disciplinary Areas","Learning Sciences, Social Sciences, Policy, Learning Technology"
Dominic Kao,"Virtual worlds, games, HCI and education",,Purdue University,Computer and Information Technology,,2113991,Productive Online Teamwork Engagement Through Intelligent Mediation,"Modern work environments are becoming increasingly distributed. As a result, the ability of employees to work in a virtual environment is becoming essential for corporate success. Employers expect higher education institutions to prepare students to operate as productive members and leaders of virtual teams. While research has built compelling pedagogical frameworks to improve in-class teamwork performance, more research-based mechanisms are needed to maximize student engagement and build teamwork skills in online education environments. Focusing on large enrollment courses in higher education, this project will study the use of effective teamwork in the online classroom by (1) developing and testing technologies that promote social presence, (2) identifying pedagogies that facilitate teamwork in an online environment, and (3) promoting productive online teamwork engagement.<br/><br/>To promote productive online teamwork engagement, this design-based research project will develop the PECAS Mediator, an educational innovation that provides (1) AI-enabled monitoring, (2) productive and unproductive interaction detection, and (3) faculty mediation via just-in-time guidance. The high-level conjecture of this project is that monitoring and mediation, enabled by evidence-based pedagogical practices and technological innovations, will increase social presence within online teamwork sessions resulting in increased teamwork engagement. The project has two main objectives: (1) Deploy and validate the intelligent monitoring and mediation PECAS Mediator to promote social presence and collaborative learning, and (2) Investigate the effect of increased social presence and collaborative learning on teamwork engagement. The theoretical conjecture of this project is that social presence mediating processes will lead to productive engagement manifested as behavioral engagement via team effectiveness, cognitive engagement via team performance, and affective engagement via positive attitudes toward teamwork.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Teamwork pedagogy; Workforce development; Online learning; Design-based research (DBR),,"Design-based research (DBR), Collaborative and/or participatory learning, AI","HCI,Augmented/virtual/mixed reality,Games and game making","Research Methods,Learning Environments and Platforms","Information Technology, Computing Technology"
Gerald Knezek,"measuring attitudes and dispositions toward information technology, developing and testing formal models of technology integration, developing practical research designs, refining scaling methods and techniques",,University of North Texas,College of Information; Department of Learning Technologies,,2118849,Improving Student Learning While Decreasing Bias in Teaching Through Simulation,"This project aims to contribute to a more just and equitable society in the future by encouraging teachers to identify, reflect on, and correct revealed biases. This three-year project will implement a scalable model for developing equitable, culturally responsive teaching practices through a simulated teaching environment. The project will identify best practices to help teachers recognize and mitigate implicit biases that often impact student success. Bias reduction in teaching practices is crucial for enabling future leaders to achieve their highest innate and positively nurtured potential. The COVID-19 pandemic has highlighted disparities in learning and emphasized the importance of socio-emotional stability for the long-term well-being of students and teachers. <br/><br/>The project team will iteratively develop and test a Teaching without Bias curriculum and add an AI-driven set of bias reduction tools to existing simulation instruction modules. The project will use data-driven decisions to confirm the feasibility of a three-phase approach to reducing bias in teaching. Through a randomized-assignment experimental design, the project will also confirm whether any of the three phases alone, in sequence, or in combination, is most effective. Through a simulated teaching environment, the project outcomes will lead to a model for developing equitable, culturally responsive teaching practices. The project will use the simulated teaching environment to develop and refine computational models that lead to improved teaching practices and contribute to the learning sciences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Multimodal data analysis; Cultural competence/responsiveness; Self-regulation, reflection, and metacognition",,"Modeling and simulation (including agent-based modeling), Cultural competence/responsiveness, Bias and equity in AI, Data mining","Survey measures,Software engineering","Research Methods,Other Disciplinary Areas","Learning Technology, Information Sciences"
Jean Oh,"semantic robot navigation, social robot navigation, human-robot interaction/collaboration, vision language planning, creative AI, arts and robotics, simulation-to-real adaptation, robotic intelligence, cognitive robotics",,Carnegie Mellon University,Robotics Institute,,2118883,Using AI to Focus Teacher-Student Troubleshooting in Classroom Robotics,"Maintaining effective instructional interactions between teachers and students around content is challenging, especially in open-ended problem-solving domains such as computer programming. Troubleshooting student programs at the classroom scale becomes difficult, even more so in remote or hybrid instructional contexts. Yet an instructor‚Äôs adaptability, insight, rapport with students, and leadership role in the classroom remain indispensable. This project will explore the use of Machine Learning (ML) algorithms to offload the time-consuming tasks of finding and deciphering student errors while also focusing teacher-student troubleshooting interactions around algorithmically identified episodic ""clips"" of student work-in-progress. This approach differs from the current state of the art in that it neither replaces nor simply informs the teacher, but instead convenes students and instructors around instructionally rich portions of the students‚Äô own code and output. Design, development, and refinement of a prototype Convening AI system for middle school robotics programming will directly impact more than a dozen educators and 2000 of their students, including several schools serving underrepresented minority populations. It will also produce generalizable know-how about the design of Convening AI systems for other educational domains and ultimately inform future directions for the design of human-AI systems.<br/><br/>This project will address the technical and sociotechnical integration challenges of an AI-driven convener through design-based research by developing a proof-of-concept Formative Assessment Suggestion Tool (FAST) in the context of middle school robotics programming. FAST will compare the efficacy of different probabilistic and neural network-based self-supervised learning approaches in identifying a student‚Äôs intended solution from their source code and simulated robot run telemetry, e.g., by comparing the plan generated by a student with that by an optimal planner. It then uses a rollback planner to identify the point at which the student‚Äôs current implementation no longer has a likely path to that solution, such that this point can be expressed to the teacher. FAST‚Äôs ML models are initially trained on an archival data set of 35,000 student code submissions to isomorphic robot programming scenarios. Each source file is re-simulated in an instrumented environment to reconstruct position, collision, and other information. Additional data including longitudinal student code-writing behavior will be collected using instrumentation upgrades developed and deployed to the simulator curriculum‚Äôs active user base during the project. Data from classroom observation will be used to model and monitor proportions of time spent engaged in different instructional actions with and without the tool. User experience around convening will be refined through participatory co-design with teachers and students. Structural equation modeling will be used to test a theory of action around uptake of the tool into classroom practice: faster, more accurate troubleshooting increases student learning and engagement as well as teacher satisfaction, leading to acceptance and continued use of the technology in a virtuous cycle.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Machine learning; Robots; Formative assessment; Design-based research (DBR),,"Cyber-enhanced/Computer-assisted assessments, Design-based research (DBR), Modeling and simulation (including agent-based modeling), Machine learning, AI, Robots","Narrative and simulated environments,Robots,AI,Computer vision technologies,Human-AI Interaction","AI Approaches and Technologies,Learning Environments and Platforms",Computer Science
Jeremy Jarzembak,"Nursing Simulation, Nursing Informatics",,Kent State University,Nursing,,2118380,Bimodal Haptic-Mixed Reality (HMR) Needle Insertion Simulation for Hand-Eye Skills,"Although performing intravenous (IV) insertion is a very common medical procedure, it is technically difficult to master as demonstrated by the 35%-50% failure rate resulting in a negative cycle of re-insertions leading to increased patient harm and costs to the healthcare system. Faulty IV insertions in real-world conditions are related to vein variables (vein rolling or resistant to puncture) and patient variables (touch skin, skin coloring). Experts in nursing education have advocated for self-paced integration of simulation-based technologies to deliberately practice IV skills while receiving immediate feedback for error correction. However, using currently developed simulators or manikin arms fails to capture the actual realism and psychomotor techniques adaptive to variability needed to gain procedural mastery of the skill. To enhance the current learning environment, technological advances are needed to create a realistic learning platform with variability that maximizes the skill transfer and long-term retention. The proposed work is to fill the gap by developing a novel simulation system using haptics and mixed reality (HMR) and investigating the learning impacts. This work is significant because current haptic technologies combined with extended reality do not yet provide sufficient realism and variability to effectively develop the fine motor skills. Further, studies have not been conducted on the educational impact of bimodal HMR simulation with variable conditions that can adaptively create realistic patient environments during training. Upon developing the successful nature of the proposed research, new insight into effective learning technology as well as causes of improved learning in hand-eye skills will be provided, which may be used to improve learning in similar settings or be transformative to other fields such as cyber teaching and learning, hand skill training at work, immersive dexterous interfaces, motor skill development for people with disabilities, STEM learning, robotic surgery, and medical training.<br/><br/>This project will develop a bimodal HMR system, using emerging technologies, haptics and MR, to simulate IV needle insertion with variable conditions that will create a realistic learning environment for students to master insertion tactile skills using two hands; and investigate whether variability in practice (disuse theory) improves needle insertion skills. To achieve these goals, the project will be divided into two phases: Phase I and II. Phase I will focus on developing the bimodal haptic simulation using two complimentary haptic devices, a haptic glove and a stylus haptic device, integrated with MR to simulate virtual patients and IV needle insertion with variable training conditions (skin color and stiffness, vein rolled, or resistant to puncture). In Phase II studies, 360 (180 per year) nursing students will be randomly assigned to experience training sessions in one of the three modes (HMR-static, HMR-variable, manikin arm). To measure learners‚Äô IV insertion skills, trained evaluators (faculty members) from the College of Nursing will observe and evaluate participants‚Äô skills based on an established IV insertion skill checklist through exams. Post training surveys will be collected in terms of the realism and the user experience (usability) and those data will be used for continuously improving the HMR system. This research will advance the knowledge related to developing innovative learning and teaching environments using emerging technologies and provide empirical evidence of impactful variables that affect learning performance. The developed platform as an automatic self-practice system will provide free access to this medium for instructors and students alike in healthcare or related communities to extend and use even under a pandemic, for broadening participation for under-represented and financially challenged groups.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Accessibility and technology; Augmented/virtual/mixed reality; Communities for learning; User-centered design,,"Augmented/virtual/mixed reality, Modeling and simulation (including agent-based modeling), Science education","Learning analytics,Virtual and remote laboratories / field trips","Analytics,Learning Environments and Platforms",Medicine
Lining Yao,"Computational Fabrication, Design Research, Enabling Technologies, End-User Programming, Learning Sciences and Technologies, Tools, Wearables",,Carnegie Mellon University,Human Computer Interaction Institute; College of Engineering,,2118924,Supporting Designers in Learning to Co-create with AI for Complex Computational Design Tasks,"As modern design tasks grow increasingly challenging, artificially intelligent (AI) design tools have the potential to provide new support to designers and engineers. This project will work to enable a future of computational co-creation, in which humans and AI collaborate and learn from each other to create new designs. The project addresses a vital national need: to prepare the emerging workforce in design, engineering, and manufacturing to better solve the complex problems of today by collaborating with AI design tools. In practice, co-creation with AI presents a significant learning curve for designers. The research team will study how people learn to collaborate with AI on real-world design tasks. The team will continuously build and test new ways for AI and designers to learn and interact through conversational and graphical interfaces. Success in this project is expected to advance our understanding of how people learn to collaborate with AI on complex computational co-creation tasks. This project is expected to lead to new training techniques and software design guidelines for AI-enabled design tools and other human-AI co-creative tasks. The research team will share their new interface designs and strategies to support other researchers in studying human-AI co-creation and to support companies in developing new AI-enabled design tools. The team will also incorporate the developed tools and research knowledge into classes for university and high school students, introducing them to human-AI collaboration and preparing them to work with and develop such systems in the future.<br/><br/>The research team will conduct iterative, human-centered design research to advance our understanding of how people learn to collaborate with AI on complex design tasks, while using widely available AI design tools, in the context of designing actively transforming structures. This is a complex, emerging manufacturing task. Steps in the research include: (1) Conduct a series of think-aloud activities to investigate how designers (try to) learn to collaborate with currently available AI design tools. The findings from these activities are expected to provide understandings of current challenges in human-AI design collaboration and will surface the strategies and mental models that people use when learning to collaborate with AI. (2) Prototype novel interface features to advance human‚ÄìAI co-creation and learning. These will include a range of interactions and interface modalities, building upon theories of effective conversational exchange and supporting controlling actions, delegating actions, and negotiating goals and means. (3) Evaluate these interfaces and interactions to see how well they support designers in learning to interact and productively work with the AI. (4) Use a mix of conversation analysis and multimodal observations to understand how the interface prototypes influence human-AI co-creation. The research is expected to produce new approaches to help researchers study and design human-AI co-creation, including: (a) measures for assessing learning and collaboration in the context of human-AI co-creative tasks; (b) prototyping methods for human-AI collaborative systems; (c) interaction design guidelines for onboarding and supporting designers in human-AI co-creation; and (d) new theory about how conversational interfaces can support designers in learning to co-create with AI.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; Collaborative and/or participatory learning; Design-based research (DBR); HCI,,"Engineering education, AI, Natural language processing and speech technologies, Multimodal data analysis","Wearable / physiological technology,Design Research,Inclusive/universal design,HCI","Research Methods,Equity and Social Justice,Learning Environments and Platforms","Engineering, Human-Computer Interaction"
Keenan Crane,"applied geometry, discrete differential geometry, digital geometry processing",,Carnegie Mellon University,Computer Science and Robotics,,2119007,Enhancing flexible STEM thinking by generating interactive diagrams at scale,"Math and science diagrams improve learning, both when diagrams are delivered with instruction, and when they are created for self-explanation. The resulting learning is often more flexible. For example, students that practice diagramming are better at transferring their learning from the problems they have explicitly practiced to more open-ended problems. Unfortunately, diagrams are too uncommon in instructional materials, especially practice problems. This is primarily because diagrams are much harder to produce than text and symbols. Teaching at scale adds further challenges. Ideally, e-learning platforms should deliver different problems to different students. These problems should be tailored to knowledge components, prevent cheating by copying, and be tuned the amount of practice to student needs. Problem templating systems aren‚Äôt built for diagrams and grading student-authored diagrams is hard to do even manually.  To address the challenge, this project aims to develop a new tool for generating diagrammatic instructional content. <br/><br/>This tool developed by the project will enable content authors to generate large problem sets by example. User will author one or two problems and the tool will synthesize a problem set from the examples. The project introduces efficient interaction techniques for viewing and editing these sets. The project will collect data from teachers and students to guide, refine, and evaluate the design of the tool. The project will conduct six studies, three will focus on the effectiveness of the tool in supporting authoring of educational content and three that focus on the impact of the resulting problems on student learning. These studies will enhance our understanding of when and how diagrams can be used to increase student understanding of science, technology, engineering and math (STEM) principles and lead to more flexible STEM thinking.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Other, AI, AI knowledge representation and reasoning",Pedagogical agents,AI Approaches and Technologies,Computer Science
Jeffrey Ogle,"Early Modern Philosophy, Ancient Philosophy, Ethics, Applied Ethics, Professional Ethics, Existentialism, Philosophy of Religion, Critical Thinking",,Regis University,Professional Advancement,,2119011,"RETTL: Facilitating socially constructed learning through a shared, mobile-based virtual reality platform in informal learning settings","Virtual reality (VR) technologies have great potential in STEM education because they provide immersive learning experiences that one cannot have in the real world. However, interactivity using VR head-mounted displays is often a solitary experience, isolating learners from the social and learning context. This makes it challenging to learn through collaborations with peers and instructors. Furthermore, many learners are excluded from using virtual reality headsets, including children, those who wear glasses, and those vulnerable to health concerns such as motion sickness, nausea, and falling. The project will develop and deploy a mobile-device-based VR platform to enable social learning. The project partners with the Science Museum of Western Virginia and the Institute of Creativity, Arts, and Technology at Virginia Tech to support socially constructed, informal STEM learning for their wide range of visitors, including young children with family members, college students, and local K-12 school students. <br/><br/>The project's overarching objective is to design, develop, and deploy an inclusive, socially connected virtual reality platform and educational content. With the system, museum attendees can collectively interact with STEM topics in virtual reality. The system will use social virtual reality to allow multiple learners to engage with the learning material, the instructor, and one another via and beyond motion-tracked mobile devices. A shared physical space with the mobile-based virtual reality platform will grant a diverse range of learners access to immersive STEM learning content and their peers beyond the screen. The researchers will study how the shared display technology facilitates socially constructed learning and enables novel active learning techniques in informal learning settings. The results will advance understanding of integrating virtual reality into inclusive settings and promoting collaborative learning with VR to enhance learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Collaborative and/or participatory learning, Social emotional learning","Other,Inquiry learning (e.g. project/problem based learning),Educator professional learning,Cultural competence/responsiveness,Philosophy,Anthropology,Ethics","Capacity Building,Other Disciplinary Areas,Learning Processes and Theories,Equity and Social Justice,Disciplinary Areas",Outreach
Meltem Alemdar,"improving K-12 STEM education through research on curriculum development, teacher professional development, student learning in integrated STEM environments",,Georgia Tech,"Center for Education Integrating Science, Mathematics and Computing",,2119135,Exploring Artificial Intelligence-enhanced Electronic Design Process Logs: Empowering High School Engineering Teachers,"The Engineering Design Process (EDP) is a general theoretical framework often used for teaching engineering, STEM, invention, and even science, particularly in K-12 education. While most EDPs used in education are depicted as linear or circular, true design processes are highly creative, non-linear, and often involve ill-posed problem statements and solution criteria.  These traits make it particularly difficult for high school engineering teachers, who tend to skip over key elements of human-centered design, where an engineer takes time to understand the problem through research, interviews, prior literature searches, market analysis, and brainstorming‚Äîthe steps where diversity of thought and experience are of the most value. In addition, it can be hard to provide students with real-time feedback due to the asynchronous nature of group work and large class sizes, and students may not feel comfortable asking for feedback on incomplete work. This project will develop and pilot an artificial intelligence (AI) enhanced Engineering Design Process Log to help students navigate the design process, provide real-time feedback, and encourage meaningful documentation of each step of the process.  This project does not propose to replace teachers with AI; rather, the project will explore a novel approach in which AI systems assist teachers in the creation of instructional modules that adhere to EDP best practices. This project is a collaboration between researchers at Georgia Tech‚Äôs College of Computing (GT CoC) and researchers at Georgia Tech‚Äôs Center for Education Integrating Science, Mathematics and Computing (CEISMC).  <br/> <br/>This project is a teaching-focused technological innovation, representing an early exploration into AI-enhanced design pedagogy. Specifically, the project will: 1) Improve upon an existing web-based Engineering Design Process Log (EDPL) by engaging in teacher user studies, 2) Design, pilot, and implement an AI-based authoring and tutoring system for teachers to customize feedback for students and for specific projects with domain expertise, 3) Design and provide professional development opportunities for alpha and beta testing teachers, and 4) Assess the impact of an AI-based EDP Log (AI-EDPL) on engineering design pedagogy and classroom practice. The AI-EDPL software system will use concepts initially pioneered for intelligent tutoring systems, but applied to scaffolding the creation of custom, teacher-made instructional materials that adhere to best practices in design process pedagogy assessment. Unlike many other educational domains, engineering design problems vary widely in scope and solution pathways, which means there will not be a one-size-fits-all tutoring system that can provide feedback to students. This project will examine (a) whether artificial intelligence can support and scaffold teachers in the creation of the necessary models and knowledge structures needed to scaffold and support learners, and, (b) what professional development teachers need to be successful in developing these models. A multi-phased approach will be used, using value-sensitive design processes from the field of human computer interaction to develop minimalist functional systems that can be tested with teachers in classrooms. In order for AI to help teachers, who do not have a lot of time to tinker with software, they must be able to express their intentions in natural language, which must be automatically converted into functional approximations of the task models that can be easily edited. This project will build on best practices in design theory and pedagogy, design documentation, design instruction, design assessment, and AI tutoring to create a one-of-a-kind technology suitable for engineering design instruction at the high school level. It represents a first attempt at providing real-time feedback in a computational setting for an open-ended design challenge, and it does so without marginalizing or diminishing the role of the instructor in the engineering classroom.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; AI knowledge representation and reasoning,,"Other, User-centered design, Adaptive/Personalized learning and intelligent tutors, AI","Instructional Design,Educator professional learning,Science education,Math education,Engineering education","Capacity Building,Disciplinary Areas","Learning Sciences,Mathematics, Computing Technology"
Jivko Sinapov,"Multimodal Learning, Interaction, Cognitive and Developmental Robotics, Human-Robot Interaction, Robot Learning, Computer Perception",,Tufts University,Computer Science,,2119174,Integrating Artificial Intelligence with Smart Engineering and English Language Arts in Upper Elementary Education,"This project will develop upper elementary school students‚Äô abilities to work with Artificial intelligence (AI) in future careers. AI will be a critical tool for influencing and increasing productivity in the future of work. As such, it is increasingly important to introduce K-12 students to basic AI knowledge and skills, build familiarity with AI technologies, and train students to be competitive in the workforce. Through this project, a team of robotics and education researchers at Tufts University in Massachusetts and Maryville University in St. Louis, MO will work with over 50 teachers in St. Louis County to develop a research-informed educational ecosystem bringing AI concepts to upper elementary school students. This ecosystem will include a novel, low-cost, AI-enabled hardware toolset, including components such as sensors, actuators, and a microcontroller, for students to build smart systems, as well as support for teacher professional development. Through after-school and summer programs, the project will engage over 1000 St. Louis County students in constructing functional AI-enabled solutions to problems presented in fictional stories that the students read in English language arts and summer reading programs. The goal of the approach is to encourage transdisciplinary learning at the intersection of AI, engineering, and literacy. The education program testing will include 12 teachers and 500 students from the upper elementary target audience, with other participants in pilot testing across the K-12 grade band. The project aims to generate a new model for introducing vital AI concepts to elementary students that reduces barriers to integrating computational thinking into school curricula and provides tangible, trainable representations of AI for students to explore.<br/><br/>Researchers will investigate three primary research questions: 1) How does the introduction of tangible artificial intelligence elements lead to changes in upper elementary students‚Äô understanding of artificial intelligence concepts and attitudes towards artificial intelligence? 2) How do different levels of complexity and variety of tangible artificial intelligence learning tools impact students' engagement and the diversity of their solutions and designs? 3) What are the potential benefits and challenges of introducing tangible artificial intelligence elements in integrated engineering and literacy activities? The project team will apply a design-based research (DBR) approach to jointly generate interdisciplinary education and learning sciences theory alongside iteratively designing and developing the toolset, professional development, and activities. The research will include interviews and surveys with AI professionals to develop and validate grade-appropriate measures of students‚Äô understanding of AI concepts and attitudes. The team will evaluate the research questions with a mixed-methods analytic approach, triangulating qualitative data from teacher interviews, lesson and professional development observations, student-made artifact analysis, and artifact-based student interviews with quantitative data from teacher and student surveys. The project‚Äôs contribution will shift the artificial intelligence education paradigm towards a convergent curriculum and away from the status quo of coding and computing requiring separate instruction. The project findings will help inform the field about challenges specific to AI education in upper elementary grades. The deliverables from this project will include the AI Animated Inventions (AI2) hardware toolset, a teacher professional development model, a gallery of example activities and student work, and measures of the program‚Äôs effectiveness, as well as the usability and utility of the tangible artificial intelligence elements for learning AI concepts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Design-based research (DBR), Modeling and simulation (including agent-based modeling), AI","Machine learning,Robots,Human-AI Interaction,Multimodal communication","Learning Processes and Theories,Other Disciplinary Areas,AI Approaches and Technologies,Learning Environments and Platforms",Computer Science
Ann Eisenberg,design and creation of objects that combine computation with real-world craft materials (e.g. Arduino-controlled sunflowers; software-generated polyhedral paper sculpture; RFID-augmented stuffed zombies),,University of Colorado at Boulder,Cognitive Science,,2119303,Inclusively-designing sensory extensions for STEM inquiry learning,"This project investigates innovative sensory extension device technologies to create learning materials that are accessible and enable diverse learners to use multiple modalities in science and mathematics learning. The new technologies will be designed, crafted, customized, and personalized by STEM learners with diverse needs. Humans think and communicate using multiple sensory modalities, including sight, sound, gesture, movement, and touch. Most science and mathematics learning materials convey information visually, with displays such as diagrams and simulations, resulting in learning experiences with limited sensory engagement. For many learners with visual or print-related disabilities, visual learning materials are inaccessible. Even for others, these materials constrain learning opportunities. Sensory extension incorporates materials and devices to enable new or enhanced perceptions of real or virtual environments. Familiar sensory extension devices include eyeglasses (refractive lenses improve vision), and Geiger counters (auditory perception of radioactive decay). In an inclusive co-design process, the project team will partner with diverse members of the learning community, together co-designing flexible, adaptive, and personalizable technologies, which enable new sensory experiences (e.g., sound, gesture, movement, and touch) to augment popular and widely used interactive simulation learning tools. The project team brings together experts in educational technologies at the University of Colorado Boulder (PhET Interactive Simulations and the Craft Tech Lab) and partner organizations serving youth with learning disabilities and visual impairments.<br/><br/>This project will work to create new learning materials, practices and processes for inclusive design with youth, as well as theories and frameworks for the use of sensory extension technologies as learning resources. To accomplish this, the team will investigate (1) pedagogical and design practices within inclusive inquiry learning in STEM learning settings; (2) the co-design and evolution of sensory extension devices; (3) learners‚Äô experiences of the impact of the inclusive design process on their own perceptions of self-efficacy and STEM; and (4) the learning experience of youth with diverse needs using sensory extension devices for STEM inquiry. The sensory extension devices are expected to enable new forms of collaboration among learners with differing sensory needs, and couple with existing educational technologies to expand their inclusive and accessible use and enrich the learning experience for all users. A rich corpus of data will be collected, tracking the trajectory of each design, including video and audio recordings of co-design sessions and the sensory extension devices in use, photographs of design artifacts and group activities, co-designer reflections and interviews, and self-efficacy survey responses. Through the inclusive co-design process, the project will work to advance foundational understanding of egalitarian processes of educational technology development, embrace sensory diversity, and empower educationally marginalized learners through the creation, customization, and personalization of their own innovative learning tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Inclusive/universal design; Wearable / physiological technology; Multimodal communication; Makers / making,,"Inquiry learning (e.g.,project/problem based learning), Accessibility and technology, Modeling and simulation (including agent-based modeling), Inclusive/universal design, Data visualization,representations and dashboards",Inquiry learning (e.g. project/problem based learning),Learning Processes and Theories,Cognitive Science
Kenneth Holstein,"Applied Machine Learning, Artificial Intelligence (AI), Design Research, Ethics, Human Assistance, Learning Sciences and Technologies, Methods, Social Computing, Societal Problems, Tools",,Carnegie Mellon University,Human Computer Interaction Institute,,2118924,Supporting Designers in Learning to Co-create with AI for Complex Computational Design Tasks,"As modern design tasks grow increasingly challenging, artificially intelligent (AI) design tools have the potential to provide new support to designers and engineers. This project will work to enable a future of computational co-creation, in which humans and AI collaborate and learn from each other to create new designs. The project addresses a vital national need: to prepare the emerging workforce in design, engineering, and manufacturing to better solve the complex problems of today by collaborating with AI design tools. In practice, co-creation with AI presents a significant learning curve for designers. The research team will study how people learn to collaborate with AI on real-world design tasks. The team will continuously build and test new ways for AI and designers to learn and interact through conversational and graphical interfaces. Success in this project is expected to advance our understanding of how people learn to collaborate with AI on complex computational co-creation tasks. This project is expected to lead to new training techniques and software design guidelines for AI-enabled design tools and other human-AI co-creative tasks. The research team will share their new interface designs and strategies to support other researchers in studying human-AI co-creation and to support companies in developing new AI-enabled design tools. The team will also incorporate the developed tools and research knowledge into classes for university and high school students, introducing them to human-AI collaboration and preparing them to work with and develop such systems in the future.<br/><br/>The research team will conduct iterative, human-centered design research to advance our understanding of how people learn to collaborate with AI on complex design tasks, while using widely available AI design tools, in the context of designing actively transforming structures. This is a complex, emerging manufacturing task. Steps in the research include: (1) Conduct a series of think-aloud activities to investigate how designers (try to) learn to collaborate with currently available AI design tools. The findings from these activities are expected to provide understandings of current challenges in human-AI design collaboration and will surface the strategies and mental models that people use when learning to collaborate with AI. (2) Prototype novel interface features to advance human‚ÄìAI co-creation and learning. These will include a range of interactions and interface modalities, building upon theories of effective conversational exchange and supporting controlling actions, delegating actions, and negotiating goals and means. (3) Evaluate these interfaces and interactions to see how well they support designers in learning to interact and productively work with the AI. (4) Use a mix of conversation analysis and multimodal observations to understand how the interface prototypes influence human-AI co-creation. The research is expected to produce new approaches to help researchers study and design human-AI co-creation, including: (a) measures for assessing learning and collaboration in the context of human-AI co-creative tasks; (b) prototyping methods for human-AI collaborative systems; (c) interaction design guidelines for onboarding and supporting designers in human-AI co-creation; and (d) new theory about how conversational interfaces can support designers in learning to co-create with AI.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; Collaborative and/or participatory learning; Design-based research (DBR); HCI,,"Engineering education, AI, Natural language processing and speech technologies, Multimodal data analysis","Social welfare development and responsibility,Machine learning,Cultural competence/responsiveness,AI,Design Research,Human-AI Interaction","Learning Environments and Platforms,Other Disciplinary Areas,Research Methods,Equity and Social Justice,AI Approaches and Technologies","Computer Science, Human-Computer Interaction"
Chris Rogers,"education, music instrument design",,Tufts University,Mechanical Engineering,,2119174,Integrating Artificial Intelligence with Smart Engineering and English Language Arts in Upper Elementary Education,"This project will develop upper elementary school students‚Äô abilities to work with Artificial intelligence (AI) in future careers. AI will be a critical tool for influencing and increasing productivity in the future of work. As such, it is increasingly important to introduce K-12 students to basic AI knowledge and skills, build familiarity with AI technologies, and train students to be competitive in the workforce. Through this project, a team of robotics and education researchers at Tufts University in Massachusetts and Maryville University in St. Louis, MO will work with over 50 teachers in St. Louis County to develop a research-informed educational ecosystem bringing AI concepts to upper elementary school students. This ecosystem will include a novel, low-cost, AI-enabled hardware toolset, including components such as sensors, actuators, and a microcontroller, for students to build smart systems, as well as support for teacher professional development. Through after-school and summer programs, the project will engage over 1000 St. Louis County students in constructing functional AI-enabled solutions to problems presented in fictional stories that the students read in English language arts and summer reading programs. The goal of the approach is to encourage transdisciplinary learning at the intersection of AI, engineering, and literacy. The education program testing will include 12 teachers and 500 students from the upper elementary target audience, with other participants in pilot testing across the K-12 grade band. The project aims to generate a new model for introducing vital AI concepts to elementary students that reduces barriers to integrating computational thinking into school curricula and provides tangible, trainable representations of AI for students to explore.<br/><br/>Researchers will investigate three primary research questions: 1) How does the introduction of tangible artificial intelligence elements lead to changes in upper elementary students‚Äô understanding of artificial intelligence concepts and attitudes towards artificial intelligence? 2) How do different levels of complexity and variety of tangible artificial intelligence learning tools impact students' engagement and the diversity of their solutions and designs? 3) What are the potential benefits and challenges of introducing tangible artificial intelligence elements in integrated engineering and literacy activities? The project team will apply a design-based research (DBR) approach to jointly generate interdisciplinary education and learning sciences theory alongside iteratively designing and developing the toolset, professional development, and activities. The research will include interviews and surveys with AI professionals to develop and validate grade-appropriate measures of students‚Äô understanding of AI concepts and attitudes. The team will evaluate the research questions with a mixed-methods analytic approach, triangulating qualitative data from teacher interviews, lesson and professional development observations, student-made artifact analysis, and artifact-based student interviews with quantitative data from teacher and student surveys. The project‚Äôs contribution will shift the artificial intelligence education paradigm towards a convergent curriculum and away from the status quo of coding and computing requiring separate instruction. The project findings will help inform the field about challenges specific to AI education in upper elementary grades. The deliverables from this project will include the AI Animated Inventions (AI2) hardware toolset, a teacher professional development model, a gallery of example activities and student work, and measures of the program‚Äôs effectiveness, as well as the usability and utility of the tangible artificial intelligence elements for learning AI concepts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Design-based research (DBR), Modeling and simulation (including agent-based modeling), AI",Creativity,Learning Processes and Theories,Mechanical Engineering
Francis Quek,"Human Computer Interaction, Computer Vision, Visualization",,Texas A&M University,Computer Science,,2119549,Using Augmented Reality and Artificial Intelligence to Improve Teaching and Learning Spatial Transformations in STEM Disciplines,"The mathematics that are used to describe spatial transformations can be very difficult for undergraduate students.  While moving something in the physical world may be easy to understand, describing the same operation with math in the digital world can be daunting.  This project will develop new technology using Augmented Reality (AR) and Artificial Intelligence (AI) to improve the teaching and learning of these difficult concepts in STEM disciplines as well as creative endeavors.  The project will test the use of new AR/AI technology to enhance students‚Äô learning of the mathematics behind spatial transformations.  This will improve the use of AR/AI-powered precise motion tracking of objects that can collect high resolution in-situ motion and scene data to enhance learning analytics. The project will identify the AR capabilities that can help students conceive, connect, and compare mathematical representations of motion to overcome the well-documented difficulties students face when learning spatial transformations.  Strengthening this skill will support their continued development across many STEM disciplines.<br/><br/>An AR/AI-powered innovative learning environment will be developed and evaluated for its effects on teaching and learning major rotation and orientation representations in the Euclidean space.  Different levels of abstraction, including Axis-Angle, Euler Angles, Matrices, and Quaternions will be tested. In workshops participants will play with and transform 3D-printed geometry models to evaluate the effectiveness of the AR/AI technology. The project will assess student learning outcomes by comparing math skills in pre- and post-workshop tests compared to students working through the same tasks without the use of the AR/AI technology. The project will contribute to advancing knowledge across disciplines of spatial and mathematical pedagogies, by exploring: a) the role of novel AR interaction that allows the interplay between physical and virtual manipulatives to engage students in embodied learning; b) the capabilities of AR to make difficult invisible concepts visible for supporting an intuitive and formal understanding of spatial reasoning and mathematical formulation; c) the features of AR that help students see relationships between spatial manipulations and mathematical operations; and d) the potential impact of individual differences in spatial transformations when using AR-assisted mathematical learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality; Games and game making; Makers / making,,"Augmented/virtual/mixed reality, Self-regulation,reflection and metacognition, AI, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Learning analytics","HCI,Computer vision technologies,Data visualization representations and dashboards","Research Methods,Analytics,AI Approaches and Technologies",Computer Science
Lawrence Angrave,"Accessible Education, Effective computer science instruction at scale",,University of Illinois at Urbana-Champaign,Computer Science,,2119589,Collaborative Research:  Advancing STEM Online Learning by Augmenting Accessibility with Explanatory Captions and AI,"Videos are a popular medium for online learning, in which captions are essential for increasing accessibility to students for effective learning. This research identifies two types of video captions: typical closed captions and explanatory captions. Closed captions are a text representation of the spoken part of a video. Explanatory captions are created to give students insights into the visual, textual, and audio content of a video. Existing technologies have focused on automatically generating or improving the quality of closed captions. For STEM learning, explanatory captions have the potential to play a new role in learning. This project will work to devise effective Q/A mechanisms and effective interaction designs that enable students and instructors to generate explanatory captions for STEM videos in a collaborative manner. The proposed technologies will augment accessibility and learning experiences for under-served populations, including the Deaf and Hard-of-Hearing (DHH) community, made up of 48 million Americans, while also improving comprehension for non-native English speakers, even those without hearing impairments. Evaluation sites include both Gallaudet University, the world‚Äôs only liberal arts university dedicated exclusively to educating DHH learners, and the University of Illinois at Urbana-Champaign, which has the largest international student population amongst U.S. public institutions and supports students with disabilities in inclusive learning environments. <br/><br/>This interdisciplinary research draws from and contributes to both computer science and learning science, and accessibility practices in the following areas. The first step is discovering new knowledge about how accessibility-enabled videos (with explanatory and closed captions) broaden the participation of under-served populations in STEM learning. This will provide the foundation for developing a theory of how explanatory captions can contribute to learning and effective mechanisms, based on crowdsourced human contributions and machine learning algorithms, to create these explanatory captions for STEM videos at different learning stages (e.g., preparing, tracking, trouble-shooting, and reflecting). The investigators will then use the theory to create a novel chatbot that enables knowledge sharing for students with diverse backgrounds.  Theoretical frameworks--ICAP (interactive, constructive, active, and passive) and Community of Inquiry will guide the evaluation of how explanatory captions and chatbots can contribute to learning. Finally, the team will acquire empirical understanding of how augmented accessibility with AI agents (e.g., chatbots) impacts students' and instructors‚Äô practices.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Online learning, Identity, Accessibility and technology, Broadening participation of historically marginalized groups, Self-regulation,reflection and metacognition, Machine learning, Data visualization,representations and dashboards, Embodied learning and cognition, AI, Media use","Accessibility and technology,Instructional Design","Equity and Social Justice,Capacity Building",Computer Science
Michael Zang,Outreach,,McGaw YMCA MetaMedia,Program Administrator,,2119701,Supporting Computational Literacy by Designing a Collaborative Platform at the Intersection of Music and Code,"This project will design and build technology that empowers ensemble musical performances with code while advancing the field of collaborative learning. It addresses two critical challenges for science and technology learning in the 21st century. First, how do we develop broad-based computational literacy skills for the next generation of learners? Second, how do we do that in a way that is inclusive‚Äîengaging diverse learners who have been historically marginalized in computational fields? The challenge of developing computational literacy is important across scientific, creative, artistic, and trade professions because computing is rapidly transforming all fields. As a result, skills such as computer programming are becoming foundational for everyone. To support motivation, learning, creative expression, and broadening participation, this research will investigate the intersection of music (as an integral component of contemporary culture) and computer programming in the design of a new collaborative technology platform. The platform takes inspiration from community-centered discourse and participation structures, such as drum circles, improvisational performance, and jam sessions. Participants will collaborate in online compositions by simultaneously writing computer code to play virtual musical instruments. Through a close partnership with the YMCA of Evanston, Illinois, the project will directly impact thousands of young learners in and around Chicago, and beyond, with a focus on students of color. The platform and learning materials (including audio and video tutorials hosted on YouTube) will be made freely available via a website to facilitate widespread adoption. These interconnections have the potential to serve as a foundation for prolonged interest, learning, creative expression, and lead to positive attitudes towards computing from a more representative, computationally empowered population.<br/><br/>This research builds on conceptual connections between music and computer science to contribute to computational literacy, informal learning in STEM and the arts, and creative and embodied approaches to computing. The project designs and studies a collaborative music+coding platform designed to give students freedom to tinker creatively, learn from their peers, and playfully confront culturally ingrained expectations about who can and should be a ""computer person"". The project will investigate the following thematic pairs of research questions: (1) Technology Innovation: How can we design technology that empowers ensemble musical performances with code? What are the foundational affordances of this technology to facilitate both co-located (multiple learners on the same physical stage) and distributed (multiple learners performing on a virtual livestream) musical performances? (2) New Models for Learning with Technology: How do we best design collaborative music+coding environments? What are the affordances of such environments for distributed collaboration, creativity, and computational literacy? (3) Broadening Participation: How can the intersection of music and computational literacy provide a context for prolonged interest and engagement for young people who have been historically marginalized in computing careers? Can code become a socially and culturally relevant medium of expression for creating and sharing music?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Broadening participation of historically marginalized groups; Creativity; Inquiry learning (e.g., project/problem based learning); Design-based research (DBR)",,"Broadening participation of historically marginalized groups, Collaborative and/or participatory learning, Computational thinking, Modeling and simulation (including agent-based modeling), Creativity",Cultural competence/responsiveness,Equity and Social Justice,Outreach
Kilchan Choi,"development of advanced statistical methodologies including latent variable hierarchical models, Bayesian analysis, latent variable measurement models with hierarchical data and applications in large-scale assessment, multi-site evaluation, growth modeling, the effectiveness/accountability of schools, psychometric models and hierarchical models, assessment strategies, implementation of new approaches, innovation in evaluation methods",,University of California-Los Angeles,"Center for Research on Evaluation, Standards and Student Testing (CRESST)",,2119818,Identifying and Extracting Meaningful Indicators of Children's Moment-to-Moment Programming Processes in Scratch,"This project aims to serve the national interest in STEM and computational thinking by developing and validating indicators of students' programming processes. The proposed exploratory research will develop a data logging module for Scratch to collect students' moment-to-moment programming behavior. The project team will develop data processing rules or algorithms to derive indicators of programming processes (e.g., debugging). The project will advance the understanding of what programming processes students use, how these processes unfold over time, and how these processes relate to measures of programming and computational thinking. The data logging module and algorithms will be distributed to the Scratch community to allow the study of programming processes at scale. The research will also produce a systematic and replicable methodology to accelerate the development of algorithms and widespread dissemination of the tools, techniques, and methods used to study programming processes.<br/><br/>The research will observe novice fifth grade and undergraduate students learning to program in Scratch. Students' process data will be used to derive indicators of programming processes. The indicators will be compared between age groups, within each age group over time, and to existing external measures of programming concepts and skills. This research will generate insights about what, how, and potentially why students perform the way they do. The capability to derive indicators of programming processes will complement existing methods of scoring static Scratch code. Algorithm development will focus on theoretically-driven, rule-based indicators of programming processes that are directly interpretable and on methods that systematize and accelerate the algorithm development process. The algorithm development methodology will apply to other block-based environments and applications involving process data such as games, simulations, and innovative item types in educational assessment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Telemetry-based indicators,,"Cyber-enhanced/Computer-assisted assessments, Computational thinking, Learning analytics","Learning analytics,Machine learning,Evaluation,Modeling and simulation (including agent-based modeling)","Analytics,Capacity Building,Other Disciplinary Areas,AI Approaches and Technologies","Evaluation,Testing"
Anirban Roy,"Computer Vision, Machine Learning, Deep Learning, Neural Networks",,SRI International,Learning Sciences,,2139219,EAGER: Technology to Review Online Videos for Education (TROVE),"Online videos are becoming increasingly popular with young children. This presents a challenge for parents and educators who want them to watch educational videos but may lack the ability or time to distinguish educational from non-educational content within the rapidly growing universe of online video. To our knowledge, there are currently no machine learning methods for classifying educational video content; current methods rely on humans to identify video content. But human content reviews cannot keep pace when, on average, approximately 500 hours of content are uploaded to YouTube every minute. The goal of this project is to develop Technology to Review Online Videos for Education (TROVE), a machine learning-based tool to identify early childhood mathematics content in a high volume of videos. This capability will enable new approaches to increase young children‚Äôs exposure to developmentally appropriate mathematics content in videos, which has been shown to improve mathematics learning outcomes. TROVE will lay the groundwork to identify a range of subjects in videos, including literacy, science, and social-emotional content. Further, the technological advances developed under this project will have applications in other fields, including adaptive learning, social media analytics, propaganda detection, and video summarization. <br/><br/>Our multidisciplinary team of education and machine learning researchers will develop a content classification engine to identify mathematics content in online videos. We will define developmentally appropriate mathematics content at the toddler, preschool, and kindergarten levels based on the Head Start Early Learning Outcomes Framework and Common Core State Standards. To train the content classification engine, researchers who have demonstrated reliability in identifying the target mathematics content will annotate the mathematics content in 100 hours of online videos. The project‚Äôs central research question asks, how accurately can the content classification engine identify early childhood mathematics content in videos, as compared to humans? To answer this, we will compare the mathematics content identified by TROVE to that identified by researchers in a set of videos that were not used to train the classification engine. We will share our findings with education technology researchers and developers, educators, and policymakers via a peer-reviewed journal article and blog post. TROVE has transformative potential to support young children‚Äôs learning through exposure to high-quality, developmentally appropriate educational videos. Further, this technology may enable large-scale research on the impacts of children‚Äôs exposure to educational and non-educational video content.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Computer vision technologies; Machine learning; Multimodal data analysis; Media use,,Machine learning,"Machine learning,Computer vision technologies","Other Disciplinary Areas,AI Approaches and Technologies",Learning Sciences
Jennifer Chiu,"Teacher Education, Curriculum & Instruction, Instructional Technology, Science Education","University of California, Berkley",University of Virginia,School of Education and Human Development,,2136724,EAGER: Adaptive Digital Twinning: An Immersive Visualization Framework for Structural Cyber-Physical Systems,"Infrastructure systems in the United States include a diverse series of assets, systems, and networks that are vital to the nation‚Äôs economy, security, and integrity. Members of every community, ranging from individual families to global corporations, rely on these infrastructure systems to thrive and maintain a high quality of life. This infrastructure is complex, interdependent, interconnected, and diverse, encompassing the water that we drink, the power that we use, the transportation services that move us, and the communication systems that connect us. Many of these infrastructure systems that serve society today were built during the second industrial age, and in many cases are in a state of disrepair with decreasing resources to preserve them. While we have continued to improve design approaches and implement more sustainable preservation strategies, modern infrastructure systems still follow many of the historical approaches used in their early development and have not been modernized. As societal dependence on technology continues to grow, the underlying physical infrastructure systems must be preserved, but also modernized to ensure that these systems are equipped to serve as the smart and agile cyber-physical systems (CPS) the future demands. This project will explore a high-risk/high reward approach to modernizing infrastructure systems using artificial intelligence-informed digital twins. The digital twinning of an infrastructure system will form a collaborative feedback loop between the measurable data of the physical world and simulated processes in the virtual world, providing a domain-specific adaptation of the broader CPS framework necessary to inform decision-making.<br/><br/>Applied to the domain of large-scale structural systems, this project will test the hypothesis that immersive engagement using a digital twin representation of these structural systems will enable participants to observe, interact, and contextualize the complex behavior mechanisms associated with these systems in their operational environment. To test the hypothesis, the research design will explore a series of technology innovations including the formulation of artificial intelligence models to emulate both simulation-based results and experiment-based measurements. Leveraging these technology innovations, we will be able to 1) understand to what extent can artificial intelligence formulated models effectively emulate the complex mechanical behaviors of simulation and experimentation of large-scale structural system; 2) evaluate to what extent does the development of artificial intelligence formulated models enable the real-time, bi-directional interaction between simulation and experimentation required of a digital twin; and 3) characterize how the deployment of artificial intelligence formulated models within an immersive environment allow end users to observe and characterize operational states of an in-service structural system. Success of this work will be realized through the fusion of experimental and numerical descriptions of these complex cyber physical systems and the creation of novel processes necessary to overcome the knowledge gap that exists between the theoretical descriptions of behavior and real-life structural response, forming a foundation for real-time decision-making for structural systems in their operational environments. Results from this project will be disseminated to the broader research community through refereed journals, conference proceedings, and student dissertations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Data visualization,representations and dashboards, AI","Science education,Instructional Design,Educator professional learning","Capacity Building,Disciplinary Areas","Education, Psychology"
Bradford Campbell,"Internet of Things, Smart Buildings/Cities, Embedded Systems‚Äã‚Äã",,University of Virginia,Computer Science; Electrical and Computer Engineering,,2136724,EAGER: Adaptive Digital Twinning: An Immersive Visualization Framework for Structural Cyber-Physical Systems,"Infrastructure systems in the United States include a diverse series of assets, systems, and networks that are vital to the nation‚Äôs economy, security, and integrity. Members of every community, ranging from individual families to global corporations, rely on these infrastructure systems to thrive and maintain a high quality of life. This infrastructure is complex, interdependent, interconnected, and diverse, encompassing the water that we drink, the power that we use, the transportation services that move us, and the communication systems that connect us. Many of these infrastructure systems that serve society today were built during the second industrial age, and in many cases are in a state of disrepair with decreasing resources to preserve them. While we have continued to improve design approaches and implement more sustainable preservation strategies, modern infrastructure systems still follow many of the historical approaches used in their early development and have not been modernized. As societal dependence on technology continues to grow, the underlying physical infrastructure systems must be preserved, but also modernized to ensure that these systems are equipped to serve as the smart and agile cyber-physical systems (CPS) the future demands. This project will explore a high-risk/high reward approach to modernizing infrastructure systems using artificial intelligence-informed digital twins. The digital twinning of an infrastructure system will form a collaborative feedback loop between the measurable data of the physical world and simulated processes in the virtual world, providing a domain-specific adaptation of the broader CPS framework necessary to inform decision-making.<br/><br/>Applied to the domain of large-scale structural systems, this project will test the hypothesis that immersive engagement using a digital twin representation of these structural systems will enable participants to observe, interact, and contextualize the complex behavior mechanisms associated with these systems in their operational environment. To test the hypothesis, the research design will explore a series of technology innovations including the formulation of artificial intelligence models to emulate both simulation-based results and experiment-based measurements. Leveraging these technology innovations, we will be able to 1) understand to what extent can artificial intelligence formulated models effectively emulate the complex mechanical behaviors of simulation and experimentation of large-scale structural system; 2) evaluate to what extent does the development of artificial intelligence formulated models enable the real-time, bi-directional interaction between simulation and experimentation required of a digital twin; and 3) characterize how the deployment of artificial intelligence formulated models within an immersive environment allow end users to observe and characterize operational states of an in-service structural system. Success of this work will be realized through the fusion of experimental and numerical descriptions of these complex cyber physical systems and the creation of novel processes necessary to overcome the knowledge gap that exists between the theoretical descriptions of behavior and real-life structural response, forming a foundation for real-time decision-making for structural systems in their operational environments. Results from this project will be disseminated to the broader research community through refereed journals, conference proceedings, and student dissertations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Data visualization,representations and dashboards, AI","Wearable / physiological technology,Smart & connected communities for learning",Learning Environments and Platforms,"Computer Science, Electrical Engineering, Computer Engineering"
Panagiotis Apostolellis,"HCI, Audience Interaction, Informal Learning with Technology, 3D User Interfaces, User, Experience Design, Computer Science education, Computational Thinking",,University of Virginia,Computer Science,,2136724,EAGER: Adaptive Digital Twinning: An Immersive Visualization Framework for Structural Cyber-Physical Systems,"Infrastructure systems in the United States include a diverse series of assets, systems, and networks that are vital to the nation‚Äôs economy, security, and integrity. Members of every community, ranging from individual families to global corporations, rely on these infrastructure systems to thrive and maintain a high quality of life. This infrastructure is complex, interdependent, interconnected, and diverse, encompassing the water that we drink, the power that we use, the transportation services that move us, and the communication systems that connect us. Many of these infrastructure systems that serve society today were built during the second industrial age, and in many cases are in a state of disrepair with decreasing resources to preserve them. While we have continued to improve design approaches and implement more sustainable preservation strategies, modern infrastructure systems still follow many of the historical approaches used in their early development and have not been modernized. As societal dependence on technology continues to grow, the underlying physical infrastructure systems must be preserved, but also modernized to ensure that these systems are equipped to serve as the smart and agile cyber-physical systems (CPS) the future demands. This project will explore a high-risk/high reward approach to modernizing infrastructure systems using artificial intelligence-informed digital twins. The digital twinning of an infrastructure system will form a collaborative feedback loop between the measurable data of the physical world and simulated processes in the virtual world, providing a domain-specific adaptation of the broader CPS framework necessary to inform decision-making.<br/><br/>Applied to the domain of large-scale structural systems, this project will test the hypothesis that immersive engagement using a digital twin representation of these structural systems will enable participants to observe, interact, and contextualize the complex behavior mechanisms associated with these systems in their operational environment. To test the hypothesis, the research design will explore a series of technology innovations including the formulation of artificial intelligence models to emulate both simulation-based results and experiment-based measurements. Leveraging these technology innovations, we will be able to 1) understand to what extent can artificial intelligence formulated models effectively emulate the complex mechanical behaviors of simulation and experimentation of large-scale structural system; 2) evaluate to what extent does the development of artificial intelligence formulated models enable the real-time, bi-directional interaction between simulation and experimentation required of a digital twin; and 3) characterize how the deployment of artificial intelligence formulated models within an immersive environment allow end users to observe and characterize operational states of an in-service structural system. Success of this work will be realized through the fusion of experimental and numerical descriptions of these complex cyber physical systems and the creation of novel processes necessary to overcome the knowledge gap that exists between the theoretical descriptions of behavior and real-life structural response, forming a foundation for real-time decision-making for structural systems in their operational environments. Results from this project will be disseminated to the broader research community through refereed journals, conference proceedings, and student dissertations.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Data visualization,representations and dashboards, AI","Informal settings,Computer science education,HCI,Computational thinking,Design Research,Interactive Displays","Research Methods,Disciplinary Areas,Learning Environments and Platforms",Computer Science
Andrea Hillsamer,Outreach,,McGaw YMCA MetaMedia,School Age Programs,,2119701,Supporting Computational Literacy by Designing a Collaborative Platform at the Intersection of Music and Code,"This project will design and build technology that empowers ensemble musical performances with code while advancing the field of collaborative learning. It addresses two critical challenges for science and technology learning in the 21st century. First, how do we develop broad-based computational literacy skills for the next generation of learners? Second, how do we do that in a way that is inclusive‚Äîengaging diverse learners who have been historically marginalized in computational fields? The challenge of developing computational literacy is important across scientific, creative, artistic, and trade professions because computing is rapidly transforming all fields. As a result, skills such as computer programming are becoming foundational for everyone. To support motivation, learning, creative expression, and broadening participation, this research will investigate the intersection of music (as an integral component of contemporary culture) and computer programming in the design of a new collaborative technology platform. The platform takes inspiration from community-centered discourse and participation structures, such as drum circles, improvisational performance, and jam sessions. Participants will collaborate in online compositions by simultaneously writing computer code to play virtual musical instruments. Through a close partnership with the YMCA of Evanston, Illinois, the project will directly impact thousands of young learners in and around Chicago, and beyond, with a focus on students of color. The platform and learning materials (including audio and video tutorials hosted on YouTube) will be made freely available via a website to facilitate widespread adoption. These interconnections have the potential to serve as a foundation for prolonged interest, learning, creative expression, and lead to positive attitudes towards computing from a more representative, computationally empowered population.<br/><br/>This research builds on conceptual connections between music and computer science to contribute to computational literacy, informal learning in STEM and the arts, and creative and embodied approaches to computing. The project designs and studies a collaborative music+coding platform designed to give students freedom to tinker creatively, learn from their peers, and playfully confront culturally ingrained expectations about who can and should be a ""computer person"". The project will investigate the following thematic pairs of research questions: (1) Technology Innovation: How can we design technology that empowers ensemble musical performances with code? What are the foundational affordances of this technology to facilitate both co-located (multiple learners on the same physical stage) and distributed (multiple learners performing on a virtual livestream) musical performances? (2) New Models for Learning with Technology: How do we best design collaborative music+coding environments? What are the affordances of such environments for distributed collaboration, creativity, and computational literacy? (3) Broadening Participation: How can the intersection of music and computational literacy provide a context for prolonged interest and engagement for young people who have been historically marginalized in computing careers? Can code become a socially and culturally relevant medium of expression for creating and sharing music?<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Broadening participation of historically marginalized groups; Creativity; Inquiry learning (e.g., project/problem based learning); Design-based research (DBR)",,"Broadening participation of historically marginalized groups, Collaborative and/or participatory learning, Computational thinking, Modeling and simulation (including agent-based modeling), Creativity",Cultural competence/responsiveness,Equity and Social Justice,Outreach
Alison Bailey,"Children's first and second language acquisition, Early literacy development, Academic language pedagogy, Language and cognitive development, Bilingualism, Atypical language development, Narrative analysis",,University of California-Los Angeles,Education; Human Development and Psychology,,2202585,Collaborative Research: Improving speech technology for better learning outcomes: the case of AAE child speakers,"The lack of reading proficiency seen in children of underserved school districts has lasting impacts on students‚Äô performances in various subjects. Low literacy is an especially pressing issue for African American students.  Interactive spoken language systems offer the possibility of a powerful tool for assisting in early childhood education, freeing up teachers‚Äô time, and engaging students in repeated opportunities for learning. These systems involve both Automatic Speech Recognition and Text-to-Speech Systems. The goal of this research is to improve the performance of such systems for young speakers of African American English (AAE) such that automated oral literacy assessment can be developed. The research has important societal and technological impacts. It will enhance the usability of speech technology in early education for AAE speaking children, providing a model for better supporting students with diverse dialects. Many under-resourced children do not have access to adequate reading and language assessments, and the proposed work will address these issues by creating methods for adapting spoken language technology to AAE children, increasing fairness in speech technology on a broader scale. The work has strong outreach and dissemination programs and will train undergraduate and graduate students in interdisciplinary research in Electrical and Computer Engineering, Linguistics, Education, and Psychology.<br/><br/> <br/>Challenges facing children‚Äôs Automatic Speech Recognition (ASR) are due to (1) lack of child speech data and, hence, current models used for recognition are trained using data collected from adult speakers, and (2) children display a wider range of intra- and inter- speaker variability than adults.  ASR performance is especially poor for children who are non-native English speakers or those who at times transition into dialects such as AAE that are different from what ASR systems are typically trained on.  In addition, most dialog systems built on text-to-speech (TTS) technology are designed using General American English (GAE) voices, which minority children may not identify with. In the high-stakes area of education, these considerations impact the effectiveness of technology for different groups. The work will utilize a new and continuously developing database of AAE children's speech to research the impact of spoken language systems on children‚Äôs learning outcomes. On the learning side, the research will highlight the impact of dialect on literacy assessment. On the technology side, the work will yield novel machine learning algorithms for low-resource tasks.  Specifically, this project will develop data augmentation techniques that can increase the amount of training data available for low-resource tasks, and data normalization techniques so that ASR performance is improved for AAE child speakers. The work on TTS will explore new methods of disentangling speaker and dialect impacts on spectral realization of phrases that model dialect density (rather than treating dialect as a categorical variable) and separately accounting for pronunciation and prosodic factors.  Methods found to be effective for TTS will be leveraged in the data augmentation work for ASR and explored as a diagnostic in literacy assessment.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Natural language processing and speech technologies, Machine learning, Literacy (e.g.,reading/reading comprehension,writing,language learning), Broadening participation of historically marginalized groups","Broadening participation of historically marginalized groups,Educator professional learning,Cognitive psychology / Cognitive science,Spoken language,Critical theory and identity,ELA education,Qualitative Methods","Capacity Building,Other Disciplinary Areas,Research Methods,Learning Processes and Theories,Equity and Social Justice,Disciplinary Areas","Education, Psychology"
Richard Correnti,"Automated Writing Evaluation, Education Reform, Improvement Science, Intelligent Tutoring Systems, Interventions, Mathematics Coaching, Professional Learning, Research/Practice Partnerships, Improvement Research in Education, Learning Technology, educational policy reform, teacher practice with technology",,University of Pittsburgh,School of Education,,2202347,Collaborative Research: Development of Natural Language Processing Techniques to Improve Students' Revision of Evidence Use in Argument Writing,"Writing is foundational to learning in multiple disciplines. It is a critical process by which students make sense of ideas ‚Äì particularly from source texts ‚Äì and bring them to bear to demonstrate their emerging understanding of concepts and to make sound arguments. Recognizing the importance of argumentative writing, multiple educational technologies driven by natural language processing (NLP) have been developed to support students and teachers in these processes. However, evidence is modest that such systems improve writing skills, and this is especially the case for younger students. One reason is that NLP technologies have only recently matured to the point that it is possible to provide feedback keyed to the content of students‚Äô writing. A second reason is that many students lack the strategic knowledge and skills needed to revise their essays even after receiving writing feedback. An educational technology that assesses students‚Äô skill at revising their writing and that provides feedback on their revision attempts would support the development of this critical skill, while placing no additional burden on teachers. Such a technology has the potential to prepare a new generation of students for productively writing and revising argumentative essays, a skill they will need in order to be prepared for the educational and workplace settings of the future.<br/><br/>To address the limitations of existing educational technologies for writing, the research team will develop a system that leverages NLP to provide students with formative feedback on the quality of their revisions. The team will 1) develop and establish the reliability and validity of new measures of revision quality in response to formative feedback on evidence use, 2) use NLP to automate the scoring of revisions using these measures, 3) provide formative feedback to students based on the automated revision scoring, and 4) evaluate the utility of this feedback in improving student writing and revision in classroom settings. The team hypothesizes that such a system will improve students‚Äô implementation of feedback messages on text-based argument writing, leading toward more successful revision and ultimately more successful writing. For learning researchers and educators, the revision quality measures will provide detailed information about how students implement formative feedback. Few summative or formative assessments currently exist that provide this type of information. For technology researchers, the automated revision scoring will extend prior writing analysis research in novel ways, e.g., by assessing the quality of revisions between essay drafts and by incorporating alignment with prior formative feedback into the assessment. Multiple types of NLP models will be developed to examine tradeoffs between model type and differing evaluation dimensions such as reliability, transparency, and fairness.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Cyber-enhanced/Computer-assisted assessments; Formative assessment; Argumentation,,"Formative assessment, Cyber-enhanced/Computer-assisted assessments, Literacy (e.g.,reading/reading comprehension,writing,language learning), Natural language processing and speech technologies","Learning analytics,Policy,Math education,Educator professional learning,Research Partnerships,Design Research,Adaptive/Personalized learning and intelligent tutors","Analytics,Capacity Building,Research Methods,Disciplinary Areas,AI Approaches and Technologies",Education
Lindsay Clare Matsumura,"Classroom discourse, Text-based argument writing, Learning technology (automated writing evaluation), Professional learning, Literacy coaching (online and ‚Äòin-person‚Äô)",,University of Pittsburgh,School of Education,,2202347,Collaborative Research: Development of Natural Language Processing Techniques to Improve Students' Revision of Evidence Use in Argument Writing,"Writing is foundational to learning in multiple disciplines. It is a critical process by which students make sense of ideas ‚Äì particularly from source texts ‚Äì and bring them to bear to demonstrate their emerging understanding of concepts and to make sound arguments. Recognizing the importance of argumentative writing, multiple educational technologies driven by natural language processing (NLP) have been developed to support students and teachers in these processes. However, evidence is modest that such systems improve writing skills, and this is especially the case for younger students. One reason is that NLP technologies have only recently matured to the point that it is possible to provide feedback keyed to the content of students‚Äô writing. A second reason is that many students lack the strategic knowledge and skills needed to revise their essays even after receiving writing feedback. An educational technology that assesses students‚Äô skill at revising their writing and that provides feedback on their revision attempts would support the development of this critical skill, while placing no additional burden on teachers. Such a technology has the potential to prepare a new generation of students for productively writing and revising argumentative essays, a skill they will need in order to be prepared for the educational and workplace settings of the future.<br/><br/>To address the limitations of existing educational technologies for writing, the research team will develop a system that leverages NLP to provide students with formative feedback on the quality of their revisions. The team will 1) develop and establish the reliability and validity of new measures of revision quality in response to formative feedback on evidence use, 2) use NLP to automate the scoring of revisions using these measures, 3) provide formative feedback to students based on the automated revision scoring, and 4) evaluate the utility of this feedback in improving student writing and revision in classroom settings. The team hypothesizes that such a system will improve students‚Äô implementation of feedback messages on text-based argument writing, leading toward more successful revision and ultimately more successful writing. For learning researchers and educators, the revision quality measures will provide detailed information about how students implement formative feedback. Few summative or formative assessments currently exist that provide this type of information. For technology researchers, the automated revision scoring will extend prior writing analysis research in novel ways, e.g., by assessing the quality of revisions between essay drafts and by incorporating alignment with prior formative feedback into the assessment. Multiple types of NLP models will be developed to examine tradeoffs between model type and differing evaluation dimensions such as reliability, transparency, and fairness.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Cyber-enhanced/Computer-assisted assessments; Formative assessment; Argumentation,,"Formative assessment, Cyber-enhanced/Computer-assisted assessments, Literacy (e.g.,reading/reading comprehension,writing,language learning), Natural language processing and speech technologies","Machine learning,Cyber-enhanced/Computer-assisted assessments,Qualitative Methods,Formal classroom settings,Educator professional learning","Learning Environments and Platforms,Capacity Building,Other Disciplinary Areas,Instruments Assessment and Measures,Research Methods,AI Approaches and Technologies",Education
Steven Coxon,"robotics, spatial ability, creativity, gifted",,Maryville University,Education,,2119174,Integrating Artificial Intelligence with Smart Engineering and English Language Arts in Upper Elementary Education,"This project will develop upper elementary school students‚Äô abilities to work with Artificial intelligence (AI) in future careers. AI will be a critical tool for influencing and increasing productivity in the future of work. As such, it is increasingly important to introduce K-12 students to basic AI knowledge and skills, build familiarity with AI technologies, and train students to be competitive in the workforce. Through this project, a team of robotics and education researchers at Tufts University in Massachusetts and Maryville University in St. Louis, MO will work with over 50 teachers in St. Louis County to develop a research-informed educational ecosystem bringing AI concepts to upper elementary school students. This ecosystem will include a novel, low-cost, AI-enabled hardware toolset, including components such as sensors, actuators, and a microcontroller, for students to build smart systems, as well as support for teacher professional development. Through after-school and summer programs, the project will engage over 1000 St. Louis County students in constructing functional AI-enabled solutions to problems presented in fictional stories that the students read in English language arts and summer reading programs. The goal of the approach is to encourage transdisciplinary learning at the intersection of AI, engineering, and literacy. The education program testing will include 12 teachers and 500 students from the upper elementary target audience, with other participants in pilot testing across the K-12 grade band. The project aims to generate a new model for introducing vital AI concepts to elementary students that reduces barriers to integrating computational thinking into school curricula and provides tangible, trainable representations of AI for students to explore.<br/><br/>Researchers will investigate three primary research questions: 1) How does the introduction of tangible artificial intelligence elements lead to changes in upper elementary students‚Äô understanding of artificial intelligence concepts and attitudes towards artificial intelligence? 2) How do different levels of complexity and variety of tangible artificial intelligence learning tools impact students' engagement and the diversity of their solutions and designs? 3) What are the potential benefits and challenges of introducing tangible artificial intelligence elements in integrated engineering and literacy activities? The project team will apply a design-based research (DBR) approach to jointly generate interdisciplinary education and learning sciences theory alongside iteratively designing and developing the toolset, professional development, and activities. The research will include interviews and surveys with AI professionals to develop and validate grade-appropriate measures of students‚Äô understanding of AI concepts and attitudes. The team will evaluate the research questions with a mixed-methods analytic approach, triangulating qualitative data from teacher interviews, lesson and professional development observations, student-made artifact analysis, and artifact-based student interviews with quantitative data from teacher and student surveys. The project‚Äôs contribution will shift the artificial intelligence education paradigm towards a convergent curriculum and away from the status quo of coding and computing requiring separate instruction. The project findings will help inform the field about challenges specific to AI education in upper elementary grades. The deliverables from this project will include the AI Animated Inventions (AI2) hardware toolset, a teacher professional development model, a gallery of example activities and student work, and measures of the program‚Äôs effectiveness, as well as the usability and utility of the tangible artificial intelligence elements for learning AI concepts.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Design-based research (DBR), Modeling and simulation (including agent-based modeling), AI","Inclusive/universal design,Robots,Creativity","Learning Processes and Theories,Equity and Social Justice,AI Approaches and Technologies",Education
Christos Mousas,"virtual reality, virtual humans, computer animation, human-computer interaction",,Purdue University,Computer Graphics Technology,,2201019,Collaborative Research: Using Artificial Intelligence to Transform Online Video Lectures into Effective and Inclusive Agent-Based Presentations,"Students in introductory STEM courses frequently encounter video lectures that include an instructor standing next to a progression of slides. A challenge with these video lectures is that students may lose interest in science when they see the instructors as unhelpful (e.g., when they portray negative emotions while teaching) or unwelcoming (e.g., when they do not reflect the gender, ethnic, and racial diversity of the audience). This project aims to develop, validate, study, and make publicly available an artificial-intelligence (AI)-based framework that takes existing online instructional video lectures on introductory STEM topics created by human instructors and transforms them into instructionally effective and inclusive agent-based presentations. This work is intended to help improve science instruction and attract students from under-represented groups.<br/><br/>The research team will apply artificial intelligence methods to extract gesture and voice from instructional videos with human instructors and transform them into instruction delivered by a diverse set of emotionally and socially sensitive onscreen animated embodied agents. Experimental research studies will investigate: 1) whether students learn better from an AI-transformed version of a video lecture than the original instructor-made video lecture; and 2) which features of onscreen agents in AI-transformed video lectures produce improved learning outcomes and processes, comparing delivery from an onscreen agent who does or does not match the student's gender, ethnicity, or race. Overall, results from the project will impact access to high-quality inclusive STEM learning experiences.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"AI, Adaptive/Personalized learning and intelligent tutors","Pedagogical agents,Augmented/virtual/mixed reality,HCI","Research Methods,AI Approaches and Technologies,Learning Environments and Platforms","Computer Science, Human-Computer Interaction"
Eliana Colunga,"Cognitive and language development, combining computational modeling and cross-linguistic studies with children and adults.
",,University of Colorado at Boulder,College of Arts and Sciences,,2223917,EAGER: Automatic Story Generation in Support of Early Vocabulary Learning,"In child development, small early differences can compound into big long-term effects. One example of this is the relationship between early vocabulary size, literacy, and later academic achievement. With this relationship in mind, many vocabulary enrichment programs based on shared reading with a caregiver have been developed, with mixed success. Evidence suggests that individualizing target-vocabulary selection can improve learning, but manually generating stories that include personalized target words for every child is infeasible. Automatic story generation using natural language processing techniques has the potential to solve this problem. Although there has been some progress in automatic story generation for adults, this is an unsolved and particularly challenging problem when stories are targeted for preschoolers, because both content and complexity need to be tailored to the age group. Thus, the researchers explore multiple innovative machine learning methods to generate engaging, high-quality child-directed stories that contain specific words that will enrich a child‚Äôs vocabulary. Furthermore, preschoolers and their caregivers participate in story-sharing activities to investigate if the automatically generated stories are effective tools for teaching words to children. This research is particularly critical for low-income families and dual language learners, who are more likely to exhibit vocabulary delays while, at the same time, being less likely to receive intervention support.<br/><br/>This EArly Grant for Exploratory Research makes novel and potentially transformative contributions to the area of automatic story generation by taking necessary exploratory steps towards flexible, adaptive technology that can automatically generate personalized, engaging, and effective stories for toddlers and their caregivers to share at home as a vehicle for early vocabulary enrichment. Specifically, the first part of this project consists of the following: 1) an investigation of multiple computational models with regards to their suitability for preschooler-directed story generation; 2) a study of strategies to avoid the generation of content that is not suitable for children by machine learning-based story generation models; and 3) an exploration of how to automatically incorporate a set of predefined target words into generated stories. Furthermore, the team of researchers investigates the quality of story generation models and the stories' effectiveness for word learning via the following: 4) obtaining feedback from families in the local community as to whether the automatically generated stories are appropriate and engaging for preschoolers and 5) conducting a laboratory study in which stories will be shared by caregivers and their children in a setting that resembles a natural home environment and subsequently comparing the children‚Äôs knowledge of target words against control words.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Modeling and simulation (including agent-based modeling), Natural language processing and speech technologies, Machine learning, Literacy (e.g.,reading/reading comprehension,writing,language learning)","ELA education,Cognitive psychology / Cognitive science,Modeling and simulation (including agent-based modeling),HCI","Research Methods,Learning Processes and Theories,AI Approaches and Technologies,Disciplinary Areas",Arts and Sciences
Ibrahim Dahlstrom-Hakki,"Effective methods of teaching STEM to students with disabilities, Implicit measures of learning, Using neurocognitive tools in authentic learning settings, Game-based learning (GBL) and game-based learning assessments (GBLA), Cognitive loads differentially impacting students with disabilities",,TERC Inc,TERC Inc,,2202291,Using Augmented Reality to Enhance Attention in STEM Learning for Students with Executive Function Disabilities,"Using Augmented Reality to Enhance Attention in Science, Technology, Engineering and Mathematics Learning for Students with Executive Function Disabilities<br/><br/>Executive functioning represents a broad skill set that is central to STEM learning and academic success, including skills related to attention, persistence, emotion regulation, and inhibition control. For students with executive function difficulties, focusing during homework and other independent learning tasks is a challenge. Many existing assistive technologies supplementing a student‚Äôs organizational capabilities are expensive and exclusionary and rely on students‚Äô ability to organize or initiate their own task monitoring. This project provides an innovative, scalable intervention that enables individuals who struggle with executive functioning to persist and thrive in academic and workplace settings by using Augmented Reality technology to support an individual‚Äôs ability to self-monitor their attention and re-engage with the content when they are off task. In the long term, the system has the potential to become a widely used learning technology that improves outcomes for students with and without executive functioning difficulties. The project will serve the public interest by increasing the participation of a population that is currently underrepresented in STEM education and the STEM workforce.<br/><br/>This project will make a novel contribution to both the computer sciences and the learning sciences, achieved through two overarching project goals. First, using a temporal analysis of head position, head orientation, and gaze orientation, the project team will develop an open-source tool based on deep learning algorithms that can detect off-task behavior as undergraduate students work on math homework problems. Second, the team will use augmented reality to provide appropriate feedback to students in the form of redirection or breaks related to their own level of focus and distractibility. Development of this system will involve an iterative prototyping and testing process, and will conclude with an early efficacy study. To explore the most effective prompts, students with executive functioning issues will participate as co-designers of the system. The deep learning algorithm for the detection of off-task behavior is a novel contribution to the computer science field that has potential applications for other subject areas and other types of learning difficulties. Furthermore, the resultant self-monitoring and redirection prompts are a contribution to the learning sciences that can benefit most learners. Thus, this research will be a significant development in the application of augmented reality to learning as it explores the most productive means of student interaction with educational technology in a complex problem space.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Accessibility and technology; Augmented/virtual/mixed reality; Attention; Argumentation,,"Formative assessment, Augmented/virtual/mixed reality, Accessibility and technology","Learning analytics,Inclusive/universal design,Instructional design,Neuroscience,Accessibility and technology,Cognitive psychology / Cognitive science,Games and game making","Learning Processes and Theories,Analytics,Equity and Social Justice,Learning Environments and Platforms",Learning Technology
Jodi Asbell-Clarke,"Game-based learning, Neurodiversity, Computational Thinking, Assessment",,TERC Inc,TERC Inc,,2202291,Using Augmented Reality to Enhance Attention in STEM Learning for Students with Executive Function Disabilities,"Using Augmented Reality to Enhance Attention in Science, Technology, Engineering and Mathematics Learning for Students with Executive Function Disabilities<br/><br/>Executive functioning represents a broad skill set that is central to STEM learning and academic success, including skills related to attention, persistence, emotion regulation, and inhibition control. For students with executive function difficulties, focusing during homework and other independent learning tasks is a challenge. Many existing assistive technologies supplementing a student‚Äôs organizational capabilities are expensive and exclusionary and rely on students‚Äô ability to organize or initiate their own task monitoring. This project provides an innovative, scalable intervention that enables individuals who struggle with executive functioning to persist and thrive in academic and workplace settings by using Augmented Reality technology to support an individual‚Äôs ability to self-monitor their attention and re-engage with the content when they are off task. In the long term, the system has the potential to become a widely used learning technology that improves outcomes for students with and without executive functioning difficulties. The project will serve the public interest by increasing the participation of a population that is currently underrepresented in STEM education and the STEM workforce.<br/><br/>This project will make a novel contribution to both the computer sciences and the learning sciences, achieved through two overarching project goals. First, using a temporal analysis of head position, head orientation, and gaze orientation, the project team will develop an open-source tool based on deep learning algorithms that can detect off-task behavior as undergraduate students work on math homework problems. Second, the team will use augmented reality to provide appropriate feedback to students in the form of redirection or breaks related to their own level of focus and distractibility. Development of this system will involve an iterative prototyping and testing process, and will conclude with an early efficacy study. To explore the most effective prompts, students with executive functioning issues will participate as co-designers of the system. The deep learning algorithm for the detection of off-task behavior is a novel contribution to the computer science field that has potential applications for other subject areas and other types of learning difficulties. Furthermore, the resultant self-monitoring and redirection prompts are a contribution to the learning sciences that can benefit most learners. Thus, this research will be a significant development in the application of augmented reality to learning as it explores the most productive means of student interaction with educational technology in a complex problem space.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Accessibility and technology; Augmented/virtual/mixed reality; Attention; Argumentation,,"Formative assessment, Augmented/virtual/mixed reality, Accessibility and technology","Cyber-enhanced/Computer-assisted assessments,Computational thinking,Inclusive/universal design,Games and game making","Instruments Assessment and Measures,Disciplinary Areas,Equity and Social Justice,Learning Environments and Platforms",Learning Technology
Richard Gerkin,"Neuroinformatics, Olfaction, Synaptic Physiology",,Arizona State University,School of life sciences; School of Mathematical and Statistical Sciences,,2202630,Multi-modal Learning for Enhanced Engagement and Presence,"The sense of smell plays a central role in how people navigate many common workplace situations. Despite this, contemporary educational approaches have only recently begun to explore using olfaction to improve education, and research on multimedia learning has almost completely overlooked it. As researchers, policy makers, and educators continue to expand digital platforms for teaching and learning, the failure to understand the role played by situational cues such as smell threatens the effectiveness of implementing STEM learning in digital environments. This integrative transdisciplinary project draws together insights from engineering, computational neurosciences, neurobiology, teaching and learning sciences, and the social sciences to advance understanding of the role that olfaction plays in learning in virtual learning environments.<br/><br/>To investigate the role of olfaction into virtual learning environments, the project team will design software platforms that integrate control of hardware that delivers a physical olfactory stimulus into real-time 3D virtual environments. This project will advance learning and teaching technologies by: (i) developing portable hardware and software systems to reliably synthesize virtual odors through miniaturized physical apparatuses, (ii) designing principles of easy-to-use development tools for virtual odor space design, and (iii) developing cloud-powered systems to model complex odor propagation. This project aims to advance understanding of the role that explicit olfactory training plays in improving a learner‚Äôs ability to identify, localize, and describe odors. By exploring how incorporating odor affects cognitive and procedural learning and its impact on learning transfer for tasks related to olfactory identification, this research will expand understanding of multimedia learning theory. Insights from this research will be used to develop pedagogical teaching approaches for domains where olfaction is important and aligns with vocational skills. By infusing olfaction into virtual reality education spaces, this project aims to create broadly accessible education opportunities around overlooked sensory cues.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Augmented/virtual/mixed reality,"Neuroscience and analytics,Neuroscience,Physiological sciences","Learning Processes and Theories,Other Disciplinary Areas","Mathematics, Life Sciences"
Ruth Wylie,"Learning Sciences, Interdisciplinary Collaboration, Educational Technology",,Arizona State University,Center for Science and the imagination; Teachers College,,2202630,Multi-modal Learning for Enhanced Engagement and Presence,"The sense of smell plays a central role in how people navigate many common workplace situations. Despite this, contemporary educational approaches have only recently begun to explore using olfaction to improve education, and research on multimedia learning has almost completely overlooked it. As researchers, policy makers, and educators continue to expand digital platforms for teaching and learning, the failure to understand the role played by situational cues such as smell threatens the effectiveness of implementing STEM learning in digital environments. This integrative transdisciplinary project draws together insights from engineering, computational neurosciences, neurobiology, teaching and learning sciences, and the social sciences to advance understanding of the role that olfaction plays in learning in virtual learning environments.<br/><br/>To investigate the role of olfaction into virtual learning environments, the project team will design software platforms that integrate control of hardware that delivers a physical olfactory stimulus into real-time 3D virtual environments. This project will advance learning and teaching technologies by: (i) developing portable hardware and software systems to reliably synthesize virtual odors through miniaturized physical apparatuses, (ii) designing principles of easy-to-use development tools for virtual odor space design, and (iii) developing cloud-powered systems to model complex odor propagation. This project aims to advance understanding of the role that explicit olfactory training plays in improving a learner‚Äôs ability to identify, localize, and describe odors. By exploring how incorporating odor affects cognitive and procedural learning and its impact on learning transfer for tasks related to olfactory identification, this research will expand understanding of multimedia learning theory. Insights from this research will be used to develop pedagogical teaching approaches for domains where olfaction is important and aligns with vocational skills. By infusing olfaction into virtual reality education spaces, this project aims to create broadly accessible education opportunities around overlooked sensory cues.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Augmented/virtual/mixed reality,,,Learning Sciences
Dustin Thoman,"Social identity, Social interactions, motivational experiences, self-regulation of motivation, participation and diversity in science education",,San Diego State University,Psychology,,2202413,Seeing Virtually: Toward a Vision of Teaching Physics in 3-D Space,"One reason that students struggle in introductory physics classes, which are often key entry points for science, technology, engineering, and math majors, is that certain topics are difficult to mentally visualize and manipulate. For example, vectors and fields are challenging in their own right, and even more so when presented using static two-dimensional imagery. Conversely, in virtual reality where students are able to be present in a tactile environment and use familiar gestures to interact with objects, the potential for deeper learning is enhanced. The scope of this project involves developing virtual reality-based physics learning spaces in which students can explore models from multiple angles, manipulate the components, and interact with an instructor who is also engaged within the environment. A critical component of the design is inclusive access, as the platform does not require expensive or complicated equipment. All students will be able to participate from anywhere with nothing more than a smartphone and a desire to learn.<br/><br/>The goal of this project is to develop spatial computing environments that are specialized for undergraduate physics education. By leveraging expertise in educational research and state-of-the-art technologies, the team will prototype, iteratively develop, and optimize collaborative educational spaces where students can interact with three-dimensional renderings of physics phenomena and engage with each other and instructors in real time. The scope of this project involves (1) constructing three fundamental learning spaces: electric fields, magnetic fields, and electromagnetic waves, and (2) developing research-based theory regarding how virtual reality experiences can improve students‚Äô learning gains. The spaces will include dynamic graphical elements relevant to the physics phenomenon, interaction tools to modify those phenomena, a live instructor who can assume a student‚Äôs perspective to see exactly what the student is viewing, and learning assessment measures. The students‚Äô actions in these virtual environments and their learning gains will be studied in order to optimize the design and implementation of this novel approach. Access to the environment will be inclusive because it is platform-agnostic: while the instructor may use sophisticated tools, students can join with a tablet or smartphone.  This will foster successful learning opportunities for all students, and particularly for underrepresented minorities and at-risk students. Findings will advance knowledge on embodied cognition in spatial computing learning environments by investigating the ways in which various composition elements and tasks engage students in deeper levels of visualization and conceptual understanding.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Accessibility and technology; Augmented/virtual/mixed reality; Embodied learning and cognition; Inquiry learning (e.g., project/problem based learning)",,"Augmented/virtual/mixed reality, Science education","Collaborative and/or participatory learning,Identity,Social welfare development and responsibility,Community partnerships,Self-regulation reflection and metacognition","Learning Processes and Theories,Equity and Social Justice",Psychology
Bruce McLaren,"Learning Sciences, educational technology, digital learning games, intelligent tutoring systems, collaborative learning,  e-learning principles.",University of Pittsburgh,Carnegie Mellon University,Human Computer Interaction Institute,,2225091,Support for U.S. Doctoral Students to Participate in the Annual Artificial Intelligence in Education (AIED) and co-located Educational Data Mining (EDM) Conferences,"The United States has historically been the global leader in the field of artificial intelligence in education (AIED), or ways to use computerized artificial intelligence to enhance teaching and learning in contexts ranging from children learning math in school, to soldiers learning highly technical jobs in the US military. The preeminent conference in this field is the AIED conference; at this conference the latest research is presented and practitioners learn the state of the art techniques that allow creation of these important educational technologies. A related conference that is equally significant is the Educational Data Mining (EDM) conference, which focuses on research on big data and analytics for education. <br/><br/>This proposal would provide partial travel support for 10 Ph.D. students from the United States, selected through a competitive process, to attend the AIED conference and/or EDM conference, present their work, and receive additional mentoring outside of their dissertation committees as part of a doctoral consortium. The intellectual merit of the work rests on the studies the graduate students submit to be considered for participation in the early career track of the conference; this work is then enhanced by guidance from world-class mentors who meet with the students in a structured format to improve their research. The broader impact includes the career impact on the twenty selected students, especially since promising graduate students whose advisors may not have funding to send them to the conference can still be included, and their work can be showcased and improved. Possible long-term broader impacts include building the field of artificial intelligence in education and data analytics researchers and thus eventually, improving the quality of education.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Workforce development,"Adaptive/Personalized learning and intelligent tutors,Games and game making","AI Approaches and Technologies,Learning Environments and Platforms","Computer Science, Human-Computer Interaction"
Janet Bowers,"Learning, Teaching and Learning, Mathematics Education, Instructional Design, Didactics, Pedagogy, Mathematical Concepts, Pedagogy and Education",,San Diego State University,College of Education; Center for research in Mathematics and Science Education,,2202413,Seeing Virtually: Toward a Vision of Teaching Physics in 3-D Space,"One reason that students struggle in introductory physics classes, which are often key entry points for science, technology, engineering, and math majors, is that certain topics are difficult to mentally visualize and manipulate. For example, vectors and fields are challenging in their own right, and even more so when presented using static two-dimensional imagery. Conversely, in virtual reality where students are able to be present in a tactile environment and use familiar gestures to interact with objects, the potential for deeper learning is enhanced. The scope of this project involves developing virtual reality-based physics learning spaces in which students can explore models from multiple angles, manipulate the components, and interact with an instructor who is also engaged within the environment. A critical component of the design is inclusive access, as the platform does not require expensive or complicated equipment. All students will be able to participate from anywhere with nothing more than a smartphone and a desire to learn.<br/><br/>The goal of this project is to develop spatial computing environments that are specialized for undergraduate physics education. By leveraging expertise in educational research and state-of-the-art technologies, the team will prototype, iteratively develop, and optimize collaborative educational spaces where students can interact with three-dimensional renderings of physics phenomena and engage with each other and instructors in real time. The scope of this project involves (1) constructing three fundamental learning spaces: electric fields, magnetic fields, and electromagnetic waves, and (2) developing research-based theory regarding how virtual reality experiences can improve students‚Äô learning gains. The spaces will include dynamic graphical elements relevant to the physics phenomenon, interaction tools to modify those phenomena, a live instructor who can assume a student‚Äôs perspective to see exactly what the student is viewing, and learning assessment measures. The students‚Äô actions in these virtual environments and their learning gains will be studied in order to optimize the design and implementation of this novel approach. Access to the environment will be inclusive because it is platform-agnostic: while the instructor may use sophisticated tools, students can join with a tablet or smartphone.  This will foster successful learning opportunities for all students, and particularly for underrepresented minorities and at-risk students. Findings will advance knowledge on embodied cognition in spatial computing learning environments by investigating the ways in which various composition elements and tasks engage students in deeper levels of visualization and conceptual understanding.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Accessibility and technology; Augmented/virtual/mixed reality; Embodied learning and cognition; Inquiry learning (e.g., project/problem based learning)",,"Augmented/virtual/mixed reality, Science education","Inquiry learning (e.g. project/problem based learning),Math education,Instructional Design,Pedagogy","Learning Processes and Theories,Capacity Building,Other Disciplinary Areas,Disciplinary Areas",Education
Raffaella Borasi,"Mathematics education, teacher education, innovation and entrepreneurship in education",,University of Rochester,School of Education,,2225227,EAGER: Cultivating Scientific Mindsets in the Machine Learning Era,"Artificial Intelligence (AI) is woven into the fabric of everyday life. There is currently an enormous skills gap in AI for the future workforce. Limited AI learning opportunities among K-12 students and professional development opportunities for teachers may lead to AI inequity in the workforce and education. This project addresses these challenges by introducing Machine Learning (ML) as a discovery tool for data-driven scientific inquiry in K-12 STEM classroom. The project focuses on creating and studying a novel programming-free and visual-based ML-powered learning environment. It aims to enable high school students and teachers with limited mathematical, programming and data skills to discover complex scientific phenomena and ask big questions from thought-provoking patterns hidden in real-world data. Researchers will include high school students from marginalized backgrounds in STEM throughout the research activities and engage in outreach in collaboration with the David T. Kearns Center for Diversity and Leadership at the University of Rochester. This project will contribute to NSF‚Äôs missions on promoting inclusion in next-generation STEM education, and advance K-12 AI literacy as a driving force of national prosperity. <br/><br/>     Researchers will carry out three synergistic research activities: (1) creating a ML-powered visual learning environment that utilizes a combination of novel glyph-based data visualization and analogical learning process to mitigate the steep learning curve of ML and multi-dimensional pattern discovery for high school learners; (2) adopting a co-design approach to include K-12 STEM teachers and data science experts in creating ML-powered scientific inquiry activities; and (3) iteratively evaluating the effectiveness of the new learning environment in supporting three key learning goals for high school students: multi-dimensional pattern discovery, ML concepts and methods around clustering and classification, and pattern-inspired scientific inquiry through question asking, hypothesis generation, explanation and argument. Findings of this project will advance our knowledge on the design and pedagogical guidelines of ML-powered visual learning environments that minimize cognitive load for novice K-12 AI learners. The resulting novel learning environment, and ML-powered scientific inquiry activities will be made publicly available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Machine learning; Data visualization, representations, and dashboards; Online learning; Inquiry learning (e.g., project/problem based learning)",,"Data visualization,representations and dashboards, Machine learning, Data science education","Workforce development,Math education,Educator professional learning","Capacity Building,Disciplinary Areas",Education
Yiran Yang,"Sustainable additive manufacturing, Waste recycling towards circular economy and closed-loop material flow, Process modeling and optimization, Additive manufacturing supply chain design and optimization, Hybrid additive-subtractive manufacturing",,University of Texas at Arlington,"Industrial, Manufacturing, and Systems Engineering",,2202598,"Enhancing Active Learning in Additive Manufacturing Using a Bilingual, Assisted Virtual-Reality Platform","Technology is integrated into every aspect of today‚Äôs world; therefore, the education system needs to train students in the use of technology. Virtual reality is one method that can be incorporated as a part of the curriculum, as an instructional delivery system, an instrument to enhance the learning process, and a tool for evaluation. This project focuses on additive manufacturing and will leverage emerging technologies by using virtual reality to develop a bilingual (English/Spanish) immersive learning environment for engineering students. All students, including students with disabilities, will be given access to the cutting-edge learning modules within virtual environments. Additive manufacturing technologies play a critical role in future manufacturing; however, they pose high-level safety-related threats to workers and environments. Hence, workers who need to directly or indirectly work with these technologies must be professionally trained with hands-on experience to gain the specific certified skills needed. The learning platform developed during this project will transform traditional approaches of learning and teaching, and improve engineering education in additive manufacturing.<br/><br/>The proposed project includes four distinct activities: (i) development of a virtual reality learning platform, (ii) design of course modules, (iii) development of software to track students‚Äô interactions, and (iv) deployment of the developed software in the target courses. The learning platform will be a virtual additive manufacturing lab equipped with different types of 3D printers, a computer workstation, a station for hand tools, and a station for personal protective equipment. Students will be assigned operational or safety training projects, based on the printer chosen, with instructions to complete tasks in sequence. After the development of the learning platform and course modules, a pilot study will be performed to collect data on student interactions with the course modules. Students‚Äô facial expressions and eye movements will be collected in real-time along with their interactions with the learning platform and course materials. Data from this study will enable us to develop a model to design assistive functionalities within the virtual platform. This model can create useful feedback and additional instructions or question students‚Äô selections, substitute instructors‚Äô supervision, and provide assistance. The outcomes of this project will be a novel bilingual learning and teaching platform with real-time assistance to significantly enhance student engagement and performance in active learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Computer vision technologies; Accessibility and technology; Virtual and remote laboratories / field trips; Attention,,"Augmented/virtual/mixed reality, Accessibility and technology, Engineering education, Learning analytics",,,"Industrial Engineering,Manufacturing Engineering, Systems Engineering"
Tamar Fuhrmann,"Cultural Making, Transformative Pedagogies- Science Education, Transformative Pedagogies- CS Education, Critiques of EdTech & Mis/Disinformation, Transformative Research Methodologies, Transformative Technological Tools, Incubated Research Communities",,Columbia University,Teachers College,,2202579,Collaborative Research: Seeing Science: Using Computer Vision to Explore the Scientific Principles Behind Everyday Objects,"Understanding science is critical for preparing students to make sense of the world around them, make informed decisions, and participate in civic society and in the workforce. However, for many youth, science is a mysterious body of knowledge that feels disconnected from their lives. This project aims to bring science into middle school students‚Äô homes, allowing them to see the science behind everyday objects and transforming lived environments into engaging learning spaces. Students will work on inquiry-based learning units on mobile phones that explore STEM phenomena topics like diffusion, electricity, and simple machines that are present in their kitchens, bedrooms, and local parks. They will be able to take photos and videos of their home and neighborhood, and computer vision algorithms will augment these images with diagrams, models, and simulations that illustrate the principles and mechanisms that explain the STEM phenomena. These overlays will allow students to observe, experiment with, and make predictions for phenomena such as tea diffusing in hot water or heat traveling through walls. The project will capitalize on existing technological devices, such as camera phones, to create ‚Äúlenses‚Äù which enable students to see the science that is all around them.<br/> <br/>By committing to such low-cost solutions, the project aims to make science education accessible to more students, and enable at-home learning while avoiding undue pressures on family resources. Operating in diverse, low-resource environments motivates fundamental advances in computer vision: First, algorithms must automatically build up a 3D and temporal representation of a scene of a given physical phenomenon. Second, the system must expose hooks for educators to decide which graphics should be overlaid at which time and in which place atop this scene. Further, the project will engage in human-centered design to bring cutting-edge technologies to youth in ways that are accessible, easy to use, and achieve educational goals. Investigators will conduct extensive interviews with parents, students, and teachers about the aspects of students‚Äô out-of-school lives that they would be willing to share with researchers, peers, and teachers. These data will enable the team to realize the benefits of equitable science education that builds on students‚Äô lives and cultures. This research will help foster the development of a more agentic, inclusive way of engaging in science inquiry at home, encouraging students to have a personal connection with science from a young age. This is particularly important for students most at risk to perceive science as disconnected from their lives, and whom can benefit most from seeing science at work in their lives and community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Computer vision technologies; Mobile learning; Inquiry learning (e.g., project/problem based learning); HCI",,"Computer vision technologies, Science education","Computer science education,Cultural competence/responsiveness,Community partnerships,Ethics","Equity and Social Justice,Disciplinary Areas",Learning Sciences
Carl Vondrick,"Computer Vision, Machine Learning",,Columbia University,Computer Science,,2202578,Collaborative Research: Seeing Science: Using Computer Vision to Explore the Scientific Principles Behind Everyday Objects,"Understanding science is critical for preparing students to make sense of the world around them, make informed decisions, and participate in civic society and in the workforce. However, for many youth, science is a mysterious body of knowledge that feels disconnected from their lives. This project aims to bring science into middle school students‚Äô homes, allowing them to see the science behind everyday objects and transforming lived environments into engaging learning spaces. Students will work on inquiry-based learning units on mobile phones that explore STEM phenomena topics like diffusion, electricity, and simple machines that are present in their kitchens, bedrooms, and local parks. They will be able to take photos and videos of their home and neighborhood, and computer vision algorithms will augment these images with diagrams, models, and simulations that illustrate the principles and mechanisms that explain the STEM phenomena. These overlays will allow students to observe, experiment with, and make predictions for phenomena such as tea diffusing in hot water or heat traveling through walls. The project will capitalize on existing technological devices, such as camera phones, to create ‚Äúlenses‚Äù which enable students to see the science that is all around them.<br/> <br/>By committing to such low-cost solutions, the project aims to make science education accessible to more students, and enable at-home learning while avoiding undue pressures on family resources. Operating in diverse, low-resource environments motivates fundamental advances in computer vision: First, algorithms must automatically build up a 3D and temporal representation of a scene of a given physical phenomenon. Second, the system must expose hooks for educators to decide which graphics should be overlaid at which time and in which place atop this scene. Further, the project will engage in human-centered design to bring cutting-edge technologies to youth in ways that are accessible, easy to use, and achieve educational goals. Investigators will conduct extensive interviews with parents, students, and teachers about the aspects of students‚Äô out-of-school lives that they would be willing to share with researchers, peers, and teachers. These data will enable the team to realize the benefits of equitable science education that builds on students‚Äô lives and cultures. This research will help foster the development of a more agentic, inclusive way of engaging in science inquiry at home, encouraging students to have a personal connection with science from a young age. This is particularly important for students most at risk to perceive science as disconnected from their lives, and whom can benefit most from seeing science at work in their lives and community.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Computer vision technologies, Science education","Machine learning,Computer vision technologies","Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Nigel Bosch,"Learning analytics, user modeling, fairness and transparency in machine learning.",,University of Illinois at Urbana-Champaign,Educational Psychology; National Center for Supercomputing Applications (NCSA),,2202481,FairFL-MC: A Metacognitive Calibration Intervention Powered by Fair and Private Machine Learning,"Students often have difficulty estimating their own level of knowledge. The goal of this project is to research ways to improve students' ability to estimate their knowledge, using a student support system consisting of short training exercises that will be personalized with artificial intelligence (AI) methods. While there is abundant research on AI methods in educational contexts, such projects rarely consider some of the key social and human factors, such as privacy and fairness, that are needed for widespread adoption of personalized educational software. This project addresses these issues with a novel decentralized AI framework that is specifically for education contexts. The project framework will enable researchers to create AI systems that provide feedback to students as part of their training exercises, all without directly accessing their data and while also training the AI system to reduce biases related to key aspects of students' identity, such as their demographics. The training exercises will include educational activities where students estimate their test scores, receive feedback from the AI system, and reflect on their knowledge. The privacy and fairness capabilities of the project framework will transform postsecondary online learning, which is poised to benefit from emerging AI-driven learning technologies but has yet to fully realize these benefits. The project will directly benefit students participating in the research as they will improve their knowledge estimation skills, prepare more effectively for tests in class, and learn about potential privacy violations and AI biases. Given the fairness focus of the project, the team of researchers will pay special attention to benefits for students from groups traditionally underrepresented in STEM (Science, Technology, Engineering, and Mathematics), ensuring that the AI-powered framework is equally helpful for them and that their perspectives on privacy and fairness receive special attention.<br/><br/>This project will advance AI research by incorporating, both, a strict privacy guarantee for student data and fairness considerations across multiple student demographic groups. Additionally, it will advance education research by determining how effective preemptive feedback is for improving knowledge estimation skills, and will examine the mechanism by which preemptively improving knowledge estimation influences academic outcomes. In particular, the project will achieve four research objectives through interdisciplinary innovations in both learning sciences and technology. First, the team will determine how much students' metacognitive calibration can be improved via AI-powered preemptive feedback, which may be perceived differently by students than post hoc feedback. Second, the project will expand theoretical understanding of metacognitive calibration and calibration interventions by studying the mechanism by which the intervention in the project works. Third, the team will address the fundamental tradeoff between the fairness and accuracy of AI models via an innovative federated learning model. Fourth, the team will evaluate the AI framework on real-world education datasets and compare its performance with the state-of-the-art baselines in terms of protecting privacy and mitigating bias. The project team will disseminate results of the project through workshops, publications, and interactive activities, and will train undergraduate and graduate students from diverse backgrounds throughout the project.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Machine learning, AI, Self-regulation,reflection and metacognition","Learning analytics,Bias and equity in AI,HCI","Research Methods,Analytics,AI Approaches and Technologies","Psychology, Computer Science"
Leslie Neely,"Autism, Applied behavior analysis, training challenging behavior",,University of Texas at San Antonio,Educational Psychology,,2202632,"Enhancing Programming and Machine Learning Education for Students with Visual Impairments through the Use of Compilers, AI and Cloud Technologies","Attractive high-paying and highly flexible Computer Science careers should be more readily accessible for people with blindness or visual impairments (BVI). Unfortunately, teaching the required computer programming and data science skills to students with BVI is extremely challenging due to two major difficulties. The first difficulty comes from the limited capability of current screen readers to properly read computer codes that are a mix of English letters, digits, and punctuation marks. The specialized set of keystrokes used in programming is also not conveniently read by screen readers (e.g., spaces and tabs). The second difficulty comes from time-consuming and frustrating code navigation, whereby students with BVI must repeatedly use screen readers to read every line to locate the desired line for editing. Partnering with San Antonio Lighthouse for the Blind and Vision Impaired, the project will develop new accessibility tools, including a program syntax- and semantics-aware screen reader and a voice-command-based code navigation framework to address the above two difficulties. These accessibility tools will be offered through cloud-based web interfaces to provide nationwide access to students and educators. The success of this project will improve the effectiveness of teaching computer programming and data science to students with BVI, which in turn will increase accessibility for more individuals with BVI to participate in Computing Science with high-paying career opportunities and could lead to a more-diverse Computer Science workforce. <br/> <br/>These accessibility tools will use compilers, Artificial Intelligence (AI), and cloud technologies to read computer code statements based on their meanings, rather than only reading one character at a time. The screen reader will articulate the necessary information that beginning coders need and help them more easily understand the lexicon and semantics used in computer programming and data science. The voice-command-based code navigation will employ speech recognition and natural language processing so that students will be able to use their voice to easily locate a specific statement (e.g., a variable declaration) within their code. These accessibility tools will be integrated into Jupyter notebook and offered through the cloud which will give nationwide access to students and educators. This cloud-based solution will also allow sophisticated AI models to be employed without requiring the students to have powerful and expensive computers to run these accessibility tools. The project will conduct a systematic evaluation of these accessibility tools using single-case research design to deepen the understanding of how technologies, including compilers, AI, and cloud computing, can be applied to teaching Computer Science skills to students with BVI. The evaluation will also provide feedback on the effectiveness of different speech styles and provide additional feedback for future improvements of these accessibility tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Workforce development; Accessibility and technology; Single-case Research Design,,"Natural language processing and speech technologies, Accessibility and technology, Machine learning, AI","Multimodal data analysis,Workforce development,Inclusive/universal design","Analytics,Equity and Social Justice,Capacity Building",Psychology
Sergiu Dascalu,"Software development techniques and tools for scientific research, Software requirements, Software design, Simulation environments, Human-computer interaction, User interaction design, Data visualization, Brain-computer interaction, Virtual reality, Data science, Computer-aided education",,"University of Nevada, Reno",Computer Science & Engineering,,2202640,Impact of Utilizing Immersive Virtual Reality and Dynamic Assessment on Mining Engineering Education from the Community of Inquiry Perspective,"A qualified workforce for domestic mining production of critical minerals is essential to a clean energy transition. However, current U.S. mining engineering education programs are not adequately producing mining graduates with the desired qualifications. A lack of in-depth understanding of the scientific principles involved in mining engineering is one the primary factors prohibiting mining engineers from excelling in their duties. To improve the situation, innovations are needed to transform traditional mining engineering education. This project will study the application of immersive virtual reality (IVR) technology as an innovative tool to improve mining engineering education, with froth flotation as a test topic. Froth flotation is a complex three-phase mineral separation process that relies on interactions between physics, chemistry, and the flotation machine to recover valuable minerals. The project takes an interdisciplinary approach, with experts in mining engineering, computer science and engineering, cognitive psychology, learning analytics, and chemistry, working alongside multi-national mining companies to develop an IVR based platform for froth flotation education. Although the primary focus is on froth flotation, the IVR platform can be applied to a broad range of learning domains by substituting new content. The project also collaborates with the University Libraries @Reality Virtual + Augmented Reality Lab at the University of Nevada, Reno to promote learning with emerging technologies for a wide range of visitors, including university students and educators, Northern Nevada residents with their young children, and local K-12 students. <br/><br/>The project will be conducted with the community of inquiry (CoI) as the pedagogical framework and a dynamic assessment approach as a measurement tool. Three objectives will be achieved: 1) determining the implications of the CoI framework in an IVR environment in the context of froth flotation education, 2) developing dynamic assessment models to predict students‚Äô learning outcomes using the CoI indicators measured in the IVR environment, and 3) demonstrating to what extent the application of IVR observed within the CoI framework and augmented by dynamic assessment can enhance froth flotation education. The research outcomes can potentially advance the current state-of-the-art in three areas: 1) improving froth flotation education by adopting an innovative teaching and learning platform, 2) adding new knowledge to the science of education by understanding how the integration of the CoI framework and dynamic assessment can impact the efficacy of the IVR application, and 3) advancing IVR software engineering in terms of software specification, design and implementation, usability, and testing and evaluation. This project is a critical first step in addressing gaps in the preparation of a U.S. workforce for domestic mining of critical minerals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Cyber-enhanced/Computer-assisted assessments, Augmented/virtual/mixed reality, Engineering education, Learning analytics","Software engineering ,Narrative and simulated environments,Neuroscience,HCI,Data mining,Augmented/virtual/mixed reality,Data visualization representations and dashboards,Software engineering","Analytics,Learning Environments and Platforms,Other Disciplinary Areas,Research Methods,Learning Processes and Theories","Computer Science, Engineering"
Danielle Oprean,"Virtual reality and game development, Evaluation of user experience with immersive technology, Investigating spatial learning through technology mediation",,University of Missouri-Columbia,College of Education & Human Development,,2202108,Research on the Use of Real-Time Tracking and Eye-Tracking Technology for Integrating Metacognition and Augmented Reality into Undergraduate Engineering Laboratories,"This project aims to innovate Augmented Reality (AR) learning platforms in an undergraduate engineering laboratory. Recently, due to the COVID-19 pandemic, in-person engineering laboratories faced significant challenges in providing hands-on exercise. AR technology might be a solution to the current challenge. Unlike virtual reality, AR does not cover a physical world but mixes 3D virtual objects into physical objects to improve students‚Äô laboratory experiences and spatial awareness. However, students faced difficulties navigating the AR device and have experienced a mismatch between computer-generated 3D images and physical objects while learning in an AR environment. To transform AR learning from a static and isolated experience into a dynamic self-study, this project includes research on using a real-time tracking sensor with a 3D full-body motion capture system to improve AR usability and detect student‚Äôs premature termination of learning using metacognitive monitoring feedback and eye-tracking technology.  <br/><br/>The primary goal of this project is to integrate real-time 3D motion and location tracking systems to meet a series of objectives to gain insight into scientific development and technological innovation in a location-based AR environment. The first objective is to create the next generation of an AR learning platform by integrating state-of-the-art indoor real-time location technology and a 3D full-body motion capture system. The second objective is to detect the early termination of learning by using metacognitive monitoring feedback and eye movement data. The researchers will apply advanced gaze behavior metrics, such as fractal analysis of pupil dilation and eye inter-fixation duration, to identify significant eye gaze behavior representing student‚Äôs premature termination of learning. The last objective is to implement the research findings to promote instructional improvement in an engineering laboratory on the impact of receiving metacognitive feedback on learning performance. The current project will address integrated research and education activities to enhance our knowledge of effective undergraduate engineering laboratory education using real-time 3D motion and location tracking capabilities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Formative assessment, Augmented/virtual/mixed reality, Biometrics (e.g.,eye-tracking,EEG), Self-regulation,reflection and metacognition","Science education,Data mining,Augmented/virtual/mixed reality,Games and game making","Analytics,Disciplinary Areas,Learning Environments and Platforms","Education, Psychology"
Xiaojin Zhu,"machine learning methods for optimal teaching, topological data analysis, semi-supervised learning, active learning, human behaviors, analyze social media for social good",,University of Wisconsin-Madison,Computer Science,,2202457,Digitally Inoculating Viewers Against Visual Misinformation With a Perceptual Training,"Misinformation impedes people‚Äôs ability to make informed decisions in many areas, for example politics, health care, purchasing, or investing. Misinformation can be created by accident or intentionally. Misleading graphs are a particularly dangerous form of misinformation because they can make false information more believable and reach viewers faster. To combat misinformation in graphs, one needs to consider two aspects of graph comprehension: conceptual reasoning and perception. Prior research has focused on conceptual reasoning about graphs. Yet, because perception is automatic it is especially prone to false information in misleading graphs. This project focuses on perception. The investigators will develop a perceptual training method that helps viewers to extract correct information from misleading graphs. The perceptual training method will be provided as a web browser plugin. It will provide feedback as viewers see misleading graphs on the web. The investigators will use machine learning algorithms to design the perceptual training method. The project will advance scientific understanding of perception in graph comprehension. It will also develop machine learning algorithms for educational purposes. The project will provide new tools for addressing issues of misinformation. <br/><br/>Misinformation poses a severe risk to society. Misleading graphs are a type of visual misinformation that can quickly convey false information to viewers. While existing interventions for visual misinformation target conceptual processes, perceptual processes also play an important role. Perceptual processes are automatic and prone to biases. Visual misinformation often targets perceptual over conceptual processing. Therefore, this project directly targets perceptual processes. Investigators will develop a perceptual training method that will teach viewers to extract correct information from misleading graphs so that they become ‚Äúimmune‚Äù against visual misinformation. The perceptual training method will be delivered as a web browser plugin and will have two components. First, upon installing the browser plugin, viewers will receive a 2-minute massed training that will serve as the initial ‚Äúvaccine‚Äù against misleading graphs. Second, the browser plugin will deliver a spaced training by giving feedback when viewers encounter misleading graphs on the web, which serves as a ‚Äúbooster‚Äù for their immunity. The investigators will use machine learning algorithms to decide which type of feedback the perceptual training should offer and how often such feedback should be provided. Two randomized experiments will evaluate components of the perceptual training method while participants browse the web. This project will advance scientific understanding of perceptual learning, educational applications of machine learning algorithms, and will develop novel approaches to combat misinformation.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Machine learning; Data visualization, representations, and dashboards; Misinformation; Cognitive psychology / Cognitive science",,"Machine learning, Data visualization,representations and dashboards","Learning analytics,Machine learning,Learning analytics,Social welfare development and responsibility,Behavior analysis","Analytics,Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Rebecca Vieyra,"Teacher education network, mobile sensors for education",,University of Colorado at Boulder,Global Initiatives of the PhET Interactive Simulations,,2114586,Combining Smartphone Light Detection and Ranging with Augmented Reality to Enhance Position-Based Teaching and Learning in STEM,"Understanding how to measure, display, and interpret motion is important for many STEM-related careers, particularly in the physical and data sciences. Educational researchers have advocated for numerous approaches to support sense-making with mathematical models of motion, but teachers often struggle to enact them due to limited resources. This project will make high-precision position sensing a reality for anyone who owns a smartphone by building on light-based mobile sensors (LiDAR) that are able to detect one‚Äôs distance from objects and location within a space. The educational research will measure the effect of using this new technology to improve student learning and engagement with regard to mathematical models with motion graphs, by producing a classroom-ready application and gamified lessons for teachers and students to use in traditional classrooms as well as the home. <br/><br/>Researchers and educational software developers will develop new data visualization technology based on iOS‚Äô scanning LiDAR and Android‚Äôs time-of-flight depth imaging. The proposed technological innovation will make use of the novel back-facing infrared beam array to significantly increase precision in position measurements and the placement of augmented reality (AR) visualizations based on users‚Äô movements and environmental data. This project will determine the extent to which LiDAR-aided AR technology can enable high-precision, position-based, and real-time data visualization. It will explore how the new technology can provide the kind of cognitive scaffolding and embodied experiences needed for advancing teaching about modeling motion with graphs and vectors. Research in the learning sciences will entail a collaboration with STEM educators to develop and test the effectiveness of scenarios for exploration in traditional and remote learning contexts. This proposal will assess full-body movement to make sense of motion graphs with a focus on embodied learning and practice with data visualization literacy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Data visualization, representations, and dashboards; Community partnerships; Augmented/virtual/mixed reality; Embodied learning and cognition",,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Science education, Data science education","Wearable / physiological technology,Educator professional learning","Capacity Building,Learning Environments and Platforms",Learning Technology
Chrystian Vieyra,Android and IOS app developer,,Vieryra Software,Software engineering,,2114586,Combining Smartphone Light Detection and Ranging with Augmented Reality to Enhance Position-Based Teaching and Learning in STEM,"Understanding how to measure, display, and interpret motion is important for many STEM-related careers, particularly in the physical and data sciences. Educational researchers have advocated for numerous approaches to support sense-making with mathematical models of motion, but teachers often struggle to enact them due to limited resources. This project will make high-precision position sensing a reality for anyone who owns a smartphone by building on light-based mobile sensors (LiDAR) that are able to detect one‚Äôs distance from objects and location within a space. The educational research will measure the effect of using this new technology to improve student learning and engagement with regard to mathematical models with motion graphs, by producing a classroom-ready application and gamified lessons for teachers and students to use in traditional classrooms as well as the home. <br/><br/>Researchers and educational software developers will develop new data visualization technology based on iOS‚Äô scanning LiDAR and Android‚Äôs time-of-flight depth imaging. The proposed technological innovation will make use of the novel back-facing infrared beam array to significantly increase precision in position measurements and the placement of augmented reality (AR) visualizations based on users‚Äô movements and environmental data. This project will determine the extent to which LiDAR-aided AR technology can enable high-precision, position-based, and real-time data visualization. It will explore how the new technology can provide the kind of cognitive scaffolding and embodied experiences needed for advancing teaching about modeling motion with graphs and vectors. Research in the learning sciences will entail a collaboration with STEM educators to develop and test the effectiveness of scenarios for exploration in traditional and remote learning contexts. This proposal will assess full-body movement to make sense of motion graphs with a focus on embodied learning and practice with data visualization literacy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Data visualization, representations, and dashboards; Community partnerships; Augmented/virtual/mixed reality; Embodied learning and cognition",,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Science education, Data science education",Software engineering,Other Disciplinary Areas,Computer Science
Daniel O'Brien,"Climate Modeling, Energy Policy, Biomedical Engineering, Physics Education",,Georgetown University,Department of Physics,,2114586,Combining Smartphone Light Detection and Ranging with Augmented Reality to Enhance Position-Based Teaching and Learning in STEM,"Understanding how to measure, display, and interpret motion is important for many STEM-related careers, particularly in the physical and data sciences. Educational researchers have advocated for numerous approaches to support sense-making with mathematical models of motion, but teachers often struggle to enact them due to limited resources. This project will make high-precision position sensing a reality for anyone who owns a smartphone by building on light-based mobile sensors (LiDAR) that are able to detect one‚Äôs distance from objects and location within a space. The educational research will measure the effect of using this new technology to improve student learning and engagement with regard to mathematical models with motion graphs, by producing a classroom-ready application and gamified lessons for teachers and students to use in traditional classrooms as well as the home. <br/><br/>Researchers and educational software developers will develop new data visualization technology based on iOS‚Äô scanning LiDAR and Android‚Äôs time-of-flight depth imaging. The proposed technological innovation will make use of the novel back-facing infrared beam array to significantly increase precision in position measurements and the placement of augmented reality (AR) visualizations based on users‚Äô movements and environmental data. This project will determine the extent to which LiDAR-aided AR technology can enable high-precision, position-based, and real-time data visualization. It will explore how the new technology can provide the kind of cognitive scaffolding and embodied experiences needed for advancing teaching about modeling motion with graphs and vectors. Research in the learning sciences will entail a collaboration with STEM educators to develop and test the effectiveness of scenarios for exploration in traditional and remote learning contexts. This proposal will assess full-body movement to make sense of motion graphs with a focus on embodied learning and practice with data visualization literacy.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Data visualization, representations, and dashboards; Community partnerships; Augmented/virtual/mixed reality; Embodied learning and cognition",,"Augmented/virtual/mixed reality, Data visualization,representations and dashboards, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Science education, Data science education","Environmental Science,Science education,Engineering education,Energy,Policy","Capacity Building,Other Disciplinary Areas,Disciplinary Areas",Physics
Kangwon Seo,"system health monitoring and failure prediction, data imbalance problems in machine learning and optimal experimental designs of reliability tests, teaching design and analysis of engineering experiments, applied statistical models, probability and statistics, multivariate data analysis",,University of Missouri-Columbia,"Industrial, Manufacturing, and Systems Engineering",,2202108,Research on the Use of Real-Time Tracking and Eye-Tracking Technology for Integrating Metacognition and Augmented Reality into Undergraduate Engineering Laboratories,"This project aims to innovate Augmented Reality (AR) learning platforms in an undergraduate engineering laboratory. Recently, due to the COVID-19 pandemic, in-person engineering laboratories faced significant challenges in providing hands-on exercise. AR technology might be a solution to the current challenge. Unlike virtual reality, AR does not cover a physical world but mixes 3D virtual objects into physical objects to improve students‚Äô laboratory experiences and spatial awareness. However, students faced difficulties navigating the AR device and have experienced a mismatch between computer-generated 3D images and physical objects while learning in an AR environment. To transform AR learning from a static and isolated experience into a dynamic self-study, this project includes research on using a real-time tracking sensor with a 3D full-body motion capture system to improve AR usability and detect student‚Äôs premature termination of learning using metacognitive monitoring feedback and eye-tracking technology.  <br/><br/>The primary goal of this project is to integrate real-time 3D motion and location tracking systems to meet a series of objectives to gain insight into scientific development and technological innovation in a location-based AR environment. The first objective is to create the next generation of an AR learning platform by integrating state-of-the-art indoor real-time location technology and a 3D full-body motion capture system. The second objective is to detect the early termination of learning by using metacognitive monitoring feedback and eye movement data. The researchers will apply advanced gaze behavior metrics, such as fractal analysis of pupil dilation and eye inter-fixation duration, to identify significant eye gaze behavior representing student‚Äôs premature termination of learning. The last objective is to implement the research findings to promote instructional improvement in an engineering laboratory on the impact of receiving metacognitive feedback on learning performance. The current project will address integrated research and education activities to enhance our knowledge of effective undergraduate engineering laboratory education using real-time 3D motion and location tracking capabilities.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Formative assessment, Augmented/virtual/mixed reality, Biometrics (e.g.,eye-tracking,EEG), Self-regulation,reflection and metacognition","Educator professional learning,Machine learning,Learning Analytics,Multimodal data analysis,Software engineering,Bias and equity in AI","Analytics,Capacity Building,Other Disciplinary Areas,AI Approaches and Technologies","Industrial Engineering,Manufacturing Engineering, Systems Engineering"
Leping Liu,"instructional technology, instructional design, information technology in education, statistics, research design, counseling technologies",,"University of Nevada, Reno",Instructional Technology & Educational Statistics,,2202640,Impact of Utilizing Immersive Virtual Reality and Dynamic Assessment on Mining Engineering Education from the Community of Inquiry Perspective,"A qualified workforce for domestic mining production of critical minerals is essential to a clean energy transition. However, current U.S. mining engineering education programs are not adequately producing mining graduates with the desired qualifications. A lack of in-depth understanding of the scientific principles involved in mining engineering is one the primary factors prohibiting mining engineers from excelling in their duties. To improve the situation, innovations are needed to transform traditional mining engineering education. This project will study the application of immersive virtual reality (IVR) technology as an innovative tool to improve mining engineering education, with froth flotation as a test topic. Froth flotation is a complex three-phase mineral separation process that relies on interactions between physics, chemistry, and the flotation machine to recover valuable minerals. The project takes an interdisciplinary approach, with experts in mining engineering, computer science and engineering, cognitive psychology, learning analytics, and chemistry, working alongside multi-national mining companies to develop an IVR based platform for froth flotation education. Although the primary focus is on froth flotation, the IVR platform can be applied to a broad range of learning domains by substituting new content. The project also collaborates with the University Libraries @Reality Virtual + Augmented Reality Lab at the University of Nevada, Reno to promote learning with emerging technologies for a wide range of visitors, including university students and educators, Northern Nevada residents with their young children, and local K-12 students. <br/><br/>The project will be conducted with the community of inquiry (CoI) as the pedagogical framework and a dynamic assessment approach as a measurement tool. Three objectives will be achieved: 1) determining the implications of the CoI framework in an IVR environment in the context of froth flotation education, 2) developing dynamic assessment models to predict students‚Äô learning outcomes using the CoI indicators measured in the IVR environment, and 3) demonstrating to what extent the application of IVR observed within the CoI framework and augmented by dynamic assessment can enhance froth flotation education. The research outcomes can potentially advance the current state-of-the-art in three areas: 1) improving froth flotation education by adopting an innovative teaching and learning platform, 2) adding new knowledge to the science of education by understanding how the integration of the CoI framework and dynamic assessment can impact the efficacy of the IVR application, and 3) advancing IVR software engineering in terms of software specification, design and implementation, usability, and testing and evaluation. This project is a critical first step in addressing gaps in the preparation of a U.S. workforce for domestic mining of critical minerals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Cyber-enhanced/Computer-assisted assessments, Augmented/virtual/mixed reality, Engineering education, Learning analytics","Learning Analytics,Mental health,Instructional Design","Equity and Social Justice,Capacity Building","Curriculum and Instruction, Education"
Li-Ting Chen,"Research Methods, Educational Statistics, Online Teaching and Learning, Assessment, Health",,"University of Nevada, Reno",Educational Studies,,2202640,Impact of Utilizing Immersive Virtual Reality and Dynamic Assessment on Mining Engineering Education from the Community of Inquiry Perspective,"A qualified workforce for domestic mining production of critical minerals is essential to a clean energy transition. However, current U.S. mining engineering education programs are not adequately producing mining graduates with the desired qualifications. A lack of in-depth understanding of the scientific principles involved in mining engineering is one the primary factors prohibiting mining engineers from excelling in their duties. To improve the situation, innovations are needed to transform traditional mining engineering education. This project will study the application of immersive virtual reality (IVR) technology as an innovative tool to improve mining engineering education, with froth flotation as a test topic. Froth flotation is a complex three-phase mineral separation process that relies on interactions between physics, chemistry, and the flotation machine to recover valuable minerals. The project takes an interdisciplinary approach, with experts in mining engineering, computer science and engineering, cognitive psychology, learning analytics, and chemistry, working alongside multi-national mining companies to develop an IVR based platform for froth flotation education. Although the primary focus is on froth flotation, the IVR platform can be applied to a broad range of learning domains by substituting new content. The project also collaborates with the University Libraries @Reality Virtual + Augmented Reality Lab at the University of Nevada, Reno to promote learning with emerging technologies for a wide range of visitors, including university students and educators, Northern Nevada residents with their young children, and local K-12 students. <br/><br/>The project will be conducted with the community of inquiry (CoI) as the pedagogical framework and a dynamic assessment approach as a measurement tool. Three objectives will be achieved: 1) determining the implications of the CoI framework in an IVR environment in the context of froth flotation education, 2) developing dynamic assessment models to predict students‚Äô learning outcomes using the CoI indicators measured in the IVR environment, and 3) demonstrating to what extent the application of IVR observed within the CoI framework and augmented by dynamic assessment can enhance froth flotation education. The research outcomes can potentially advance the current state-of-the-art in three areas: 1) improving froth flotation education by adopting an innovative teaching and learning platform, 2) adding new knowledge to the science of education by understanding how the integration of the CoI framework and dynamic assessment can impact the efficacy of the IVR application, and 3) advancing IVR software engineering in terms of software specification, design and implementation, usability, and testing and evaluation. This project is a critical first step in addressing gaps in the preparation of a U.S. workforce for domestic mining of critical minerals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Cyber-enhanced/Computer-assisted assessments, Augmented/virtual/mixed reality, Engineering education, Learning analytics","Learning analytics,Cyber-enhanced/Computer-assisted assessments,Online learning,Health","Instruments Assessment and Measures,Analytics,Other Disciplinary Areas,Learning Environments and Platforms",Learning Sciences
Ying Yang,Polymer materials,,"University of Nevada, Reno",Chemistry,,2202640,Impact of Utilizing Immersive Virtual Reality and Dynamic Assessment on Mining Engineering Education from the Community of Inquiry Perspective,"A qualified workforce for domestic mining production of critical minerals is essential to a clean energy transition. However, current U.S. mining engineering education programs are not adequately producing mining graduates with the desired qualifications. A lack of in-depth understanding of the scientific principles involved in mining engineering is one the primary factors prohibiting mining engineers from excelling in their duties. To improve the situation, innovations are needed to transform traditional mining engineering education. This project will study the application of immersive virtual reality (IVR) technology as an innovative tool to improve mining engineering education, with froth flotation as a test topic. Froth flotation is a complex three-phase mineral separation process that relies on interactions between physics, chemistry, and the flotation machine to recover valuable minerals. The project takes an interdisciplinary approach, with experts in mining engineering, computer science and engineering, cognitive psychology, learning analytics, and chemistry, working alongside multi-national mining companies to develop an IVR based platform for froth flotation education. Although the primary focus is on froth flotation, the IVR platform can be applied to a broad range of learning domains by substituting new content. The project also collaborates with the University Libraries @Reality Virtual + Augmented Reality Lab at the University of Nevada, Reno to promote learning with emerging technologies for a wide range of visitors, including university students and educators, Northern Nevada residents with their young children, and local K-12 students. <br/><br/>The project will be conducted with the community of inquiry (CoI) as the pedagogical framework and a dynamic assessment approach as a measurement tool. Three objectives will be achieved: 1) determining the implications of the CoI framework in an IVR environment in the context of froth flotation education, 2) developing dynamic assessment models to predict students‚Äô learning outcomes using the CoI indicators measured in the IVR environment, and 3) demonstrating to what extent the application of IVR observed within the CoI framework and augmented by dynamic assessment can enhance froth flotation education. The research outcomes can potentially advance the current state-of-the-art in three areas: 1) improving froth flotation education by adopting an innovative teaching and learning platform, 2) adding new knowledge to the science of education by understanding how the integration of the CoI framework and dynamic assessment can impact the efficacy of the IVR application, and 3) advancing IVR software engineering in terms of software specification, design and implementation, usability, and testing and evaluation. This project is a critical first step in addressing gaps in the preparation of a U.S. workforce for domestic mining of critical minerals.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Cyber-enhanced/Computer-assisted assessments, Augmented/virtual/mixed reality, Engineering education, Learning analytics",Engineering education,Disciplinary Areas,Chemistry
Kathy Ewoldt,"Learning Disabilities, Writing, Cultural & Linguistically Diverse, Learners, Assessment, Assistive Technology",,"University of Texas, San Antonio",Interdisciplinary Learning &Teaching (ILT),,2202632,"Enhancing Programming and Machine Learning Education for Students with Visual Impairments through the Use of Compilers, AI and Cloud Technologies","Attractive high-paying and highly flexible Computer Science careers should be more readily accessible for people with blindness or visual impairments (BVI). Unfortunately, teaching the required computer programming and data science skills to students with BVI is extremely challenging due to two major difficulties. The first difficulty comes from the limited capability of current screen readers to properly read computer codes that are a mix of English letters, digits, and punctuation marks. The specialized set of keystrokes used in programming is also not conveniently read by screen readers (e.g., spaces and tabs). The second difficulty comes from time-consuming and frustrating code navigation, whereby students with BVI must repeatedly use screen readers to read every line to locate the desired line for editing. Partnering with San Antonio Lighthouse for the Blind and Vision Impaired, the project will develop new accessibility tools, including a program syntax- and semantics-aware screen reader and a voice-command-based code navigation framework to address the above two difficulties. These accessibility tools will be offered through cloud-based web interfaces to provide nationwide access to students and educators. The success of this project will improve the effectiveness of teaching computer programming and data science to students with BVI, which in turn will increase accessibility for more individuals with BVI to participate in Computing Science with high-paying career opportunities and could lead to a more-diverse Computer Science workforce. <br/> <br/>These accessibility tools will use compilers, Artificial Intelligence (AI), and cloud technologies to read computer code statements based on their meanings, rather than only reading one character at a time. The screen reader will articulate the necessary information that beginning coders need and help them more easily understand the lexicon and semantics used in computer programming and data science. The voice-command-based code navigation will employ speech recognition and natural language processing so that students will be able to use their voice to easily locate a specific statement (e.g., a variable declaration) within their code. These accessibility tools will be integrated into Jupyter notebook and offered through the cloud which will give nationwide access to students and educators. This cloud-based solution will also allow sophisticated AI models to be employed without requiring the students to have powerful and expensive computers to run these accessibility tools. The project will conduct a systematic evaluation of these accessibility tools using single-case research design to deepen the understanding of how technologies, including compilers, AI, and cloud computing, can be applied to teaching Computer Science skills to students with BVI. The evaluation will also provide feedback on the effectiveness of different speech styles and provide additional feedback for future improvements of these accessibility tools.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Natural language processing and speech technologies; Workforce development; Accessibility and technology; Single-case Research Design,,"Natural language processing and speech technologies, Accessibility and technology, Machine learning, AI","Cyber-enhanced/Computer-assisted assessments,Inclusive/universal design,ELA education,Accessibility and technology","Instruments Assessment and Measures,Equity and Social Justice,Disciplinary Areas","Curriculum and Instruction, Education"
Amanda Olsen,"Equity, School climate, program evaluation, Quantitative methods, quantitative methods, interdisciplinary collaborations",,University of Texas at Arlington,Curriculum and Instruction,,2202598,"Enhancing Active Learning in Additive Manufacturing Using a Bilingual, Assisted Virtual-Reality Platform","Technology is integrated into every aspect of today‚Äôs world; therefore, the education system needs to train students in the use of technology. Virtual reality is one method that can be incorporated as a part of the curriculum, as an instructional delivery system, an instrument to enhance the learning process, and a tool for evaluation. This project focuses on additive manufacturing and will leverage emerging technologies by using virtual reality to develop a bilingual (English/Spanish) immersive learning environment for engineering students. All students, including students with disabilities, will be given access to the cutting-edge learning modules within virtual environments. Additive manufacturing technologies play a critical role in future manufacturing; however, they pose high-level safety-related threats to workers and environments. Hence, workers who need to directly or indirectly work with these technologies must be professionally trained with hands-on experience to gain the specific certified skills needed. The learning platform developed during this project will transform traditional approaches of learning and teaching, and improve engineering education in additive manufacturing.<br/><br/>The proposed project includes four distinct activities: (i) development of a virtual reality learning platform, (ii) design of course modules, (iii) development of software to track students‚Äô interactions, and (iv) deployment of the developed software in the target courses. The learning platform will be a virtual additive manufacturing lab equipped with different types of 3D printers, a computer workstation, a station for hand tools, and a station for personal protective equipment. Students will be assigned operational or safety training projects, based on the printer chosen, with instructions to complete tasks in sequence. After the development of the learning platform and course modules, a pilot study will be performed to collect data on student interactions with the course modules. Students‚Äô facial expressions and eye movements will be collected in real-time along with their interactions with the learning platform and course materials. Data from this study will enable us to develop a model to design assistive functionalities within the virtual platform. This model can create useful feedback and additional instructions or question students‚Äô selections, substitute instructors‚Äô supervision, and provide assistance. The outcomes of this project will be a novel bilingual learning and teaching platform with real-time assistance to significantly enhance student engagement and performance in active learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Computer vision technologies; Accessibility and technology; Virtual and remote laboratories / field trips; Attention,,"Augmented/virtual/mixed reality, Accessibility and technology, Engineering education, Learning analytics",Quantitative Methods,Research Methods,Curriculum and Instruction
Jiebo Luo,"AI, multimedia, computational social science, computational medicine, big data analytics",,University of Rochester,Computer Science,,2225227,EAGER: Cultivating Scientific Mindsets in the Machine Learning Era,"Artificial Intelligence (AI) is woven into the fabric of everyday life. There is currently an enormous skills gap in AI for the future workforce. Limited AI learning opportunities among K-12 students and professional development opportunities for teachers may lead to AI inequity in the workforce and education. This project addresses these challenges by introducing Machine Learning (ML) as a discovery tool for data-driven scientific inquiry in K-12 STEM classroom. The project focuses on creating and studying a novel programming-free and visual-based ML-powered learning environment. It aims to enable high school students and teachers with limited mathematical, programming and data skills to discover complex scientific phenomena and ask big questions from thought-provoking patterns hidden in real-world data. Researchers will include high school students from marginalized backgrounds in STEM throughout the research activities and engage in outreach in collaboration with the David T. Kearns Center for Diversity and Leadership at the University of Rochester. This project will contribute to NSF‚Äôs missions on promoting inclusion in next-generation STEM education, and advance K-12 AI literacy as a driving force of national prosperity. <br/><br/>     Researchers will carry out three synergistic research activities: (1) creating a ML-powered visual learning environment that utilizes a combination of novel glyph-based data visualization and analogical learning process to mitigate the steep learning curve of ML and multi-dimensional pattern discovery for high school learners; (2) adopting a co-design approach to include K-12 STEM teachers and data science experts in creating ML-powered scientific inquiry activities; and (3) iteratively evaluating the effectiveness of the new learning environment in supporting three key learning goals for high school students: multi-dimensional pattern discovery, ML concepts and methods around clustering and classification, and pattern-inspired scientific inquiry through question asking, hypothesis generation, explanation and argument. Findings of this project will advance our knowledge on the design and pedagogical guidelines of ML-powered visual learning environments that minimize cognitive load for novice K-12 AI learners. The resulting novel learning environment, and ML-powered scientific inquiry activities will be made publicly available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Machine learning; Data visualization, representations, and dashboards; Online learning; Inquiry learning (e.g., project/problem based learning)",,"Data visualization,representations and dashboards, Machine learning, Data science education","Learning analytics,Machine learning,AI,Data mining,Media use","Learning Processes and Theories,Analytics,Other Disciplinary Areas,AI Approaches and Technologies",Computer Science
Michael Daley,STEM Education,,University of Rochester,School of Education; Center for Professional Development & Education Reform,,2225227,EAGER: Cultivating Scientific Mindsets in the Machine Learning Era,"Artificial Intelligence (AI) is woven into the fabric of everyday life. There is currently an enormous skills gap in AI for the future workforce. Limited AI learning opportunities among K-12 students and professional development opportunities for teachers may lead to AI inequity in the workforce and education. This project addresses these challenges by introducing Machine Learning (ML) as a discovery tool for data-driven scientific inquiry in K-12 STEM classroom. The project focuses on creating and studying a novel programming-free and visual-based ML-powered learning environment. It aims to enable high school students and teachers with limited mathematical, programming and data skills to discover complex scientific phenomena and ask big questions from thought-provoking patterns hidden in real-world data. Researchers will include high school students from marginalized backgrounds in STEM throughout the research activities and engage in outreach in collaboration with the David T. Kearns Center for Diversity and Leadership at the University of Rochester. This project will contribute to NSF‚Äôs missions on promoting inclusion in next-generation STEM education, and advance K-12 AI literacy as a driving force of national prosperity. <br/><br/>     Researchers will carry out three synergistic research activities: (1) creating a ML-powered visual learning environment that utilizes a combination of novel glyph-based data visualization and analogical learning process to mitigate the steep learning curve of ML and multi-dimensional pattern discovery for high school learners; (2) adopting a co-design approach to include K-12 STEM teachers and data science experts in creating ML-powered scientific inquiry activities; and (3) iteratively evaluating the effectiveness of the new learning environment in supporting three key learning goals for high school students: multi-dimensional pattern discovery, ML concepts and methods around clustering and classification, and pattern-inspired scientific inquiry through question asking, hypothesis generation, explanation and argument. Findings of this project will advance our knowledge on the design and pedagogical guidelines of ML-powered visual learning environments that minimize cognitive load for novice K-12 AI learners. The resulting novel learning environment, and ML-powered scientific inquiry activities will be made publicly available.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.","Machine learning; Data visualization, representations, and dashboards; Online learning; Inquiry learning (e.g., project/problem based learning)",,"Data visualization,representations and dashboards, Machine learning, Data science education","Science education,Math education,Engineering education",Disciplinary Areas,"Education, Outreach"
Byron Lahey,"Human computer interaction, Embodied Cognition, Human Robot Interaction",,Arizona State University,School of Arts Media and Engineering,,2202630,Multi-modal Learning for Enhanced Engagement and Presence,"The sense of smell plays a central role in how people navigate many common workplace situations. Despite this, contemporary educational approaches have only recently begun to explore using olfaction to improve education, and research on multimedia learning has almost completely overlooked it. As researchers, policy makers, and educators continue to expand digital platforms for teaching and learning, the failure to understand the role played by situational cues such as smell threatens the effectiveness of implementing STEM learning in digital environments. This integrative transdisciplinary project draws together insights from engineering, computational neurosciences, neurobiology, teaching and learning sciences, and the social sciences to advance understanding of the role that olfaction plays in learning in virtual learning environments.<br/><br/>To investigate the role of olfaction into virtual learning environments, the project team will design software platforms that integrate control of hardware that delivers a physical olfactory stimulus into real-time 3D virtual environments. This project will advance learning and teaching technologies by: (i) developing portable hardware and software systems to reliably synthesize virtual odors through miniaturized physical apparatuses, (ii) designing principles of easy-to-use development tools for virtual odor space design, and (iii) developing cloud-powered systems to model complex odor propagation. This project aims to advance understanding of the role that explicit olfactory training plays in improving a learner‚Äôs ability to identify, localize, and describe odors. By exploring how incorporating odor affects cognitive and procedural learning and its impact on learning transfer for tasks related to olfactory identification, this research will expand understanding of multimedia learning theory. Insights from this research will be used to develop pedagogical teaching approaches for domains where olfaction is important and aligns with vocational skills. By infusing olfaction into virtual reality education spaces, this project aims to create broadly accessible education opportunities around overlooked sensory cues.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Augmented/virtual/mixed reality,"Human-AI Interaction,Embodied learning and cognition,HCI","Research Methods,Learning Processes and Theories,Learning Environments and Platforms","Arts and Sciences, Engineering"
Christy Spackman,"Studying the taste of water, how sensory science shapes people's interactions with the environment, creation of tastelessness, Desert transplant rooted in a multi-generation, messy, diasporic history of European settlement in North America.",,Arizona State University,"School for the Future of Innovation in Society, School of Arts, Media and Engineering",,2202630,Multi-modal Learning for Enhanced Engagement and Presence,"The sense of smell plays a central role in how people navigate many common workplace situations. Despite this, contemporary educational approaches have only recently begun to explore using olfaction to improve education, and research on multimedia learning has almost completely overlooked it. As researchers, policy makers, and educators continue to expand digital platforms for teaching and learning, the failure to understand the role played by situational cues such as smell threatens the effectiveness of implementing STEM learning in digital environments. This integrative transdisciplinary project draws together insights from engineering, computational neurosciences, neurobiology, teaching and learning sciences, and the social sciences to advance understanding of the role that olfaction plays in learning in virtual learning environments.<br/><br/>To investigate the role of olfaction into virtual learning environments, the project team will design software platforms that integrate control of hardware that delivers a physical olfactory stimulus into real-time 3D virtual environments. This project will advance learning and teaching technologies by: (i) developing portable hardware and software systems to reliably synthesize virtual odors through miniaturized physical apparatuses, (ii) designing principles of easy-to-use development tools for virtual odor space design, and (iii) developing cloud-powered systems to model complex odor propagation. This project aims to advance understanding of the role that explicit olfactory training plays in improving a learner‚Äôs ability to identify, localize, and describe odors. By exploring how incorporating odor affects cognitive and procedural learning and its impact on learning transfer for tasks related to olfactory identification, this research will expand understanding of multimedia learning theory. Insights from this research will be used to develop pedagogical teaching approaches for domains where olfaction is important and aligns with vocational skills. By infusing olfaction into virtual reality education spaces, this project aims to create broadly accessible education opportunities around overlooked sensory cues.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,Augmented/virtual/mixed reality,"Inquiry learning (e.g. project/problem based learning),Physiological sciences,Broadening participation of historically marginalized groups","Learning Processes and Theories,Equity and Social Justice,Other Disciplinary Areas",Social Sciences
Philip Yasskin,"General Relativity, Differential Geometry, Applications of Computer Algebra Systems, Technology in STEM Education, Enhancement of K-12 Education, Outreach to K-12 Education",,Texas A&M University,Mathematics,,2119549,Using Augmented Reality and Artificial Intelligence to Improve Teaching and Learning Spatial Transformations in STEM Disciplines,"The mathematics that are used to describe spatial transformations can be very difficult for undergraduate students.  While moving something in the physical world may be easy to understand, describing the same operation with math in the digital world can be daunting.  This project will develop new technology using Augmented Reality (AR) and Artificial Intelligence (AI) to improve the teaching and learning of these difficult concepts in STEM disciplines as well as creative endeavors.  The project will test the use of new AR/AI technology to enhance students‚Äô learning of the mathematics behind spatial transformations.  This will improve the use of AR/AI-powered precise motion tracking of objects that can collect high resolution in-situ motion and scene data to enhance learning analytics. The project will identify the AR capabilities that can help students conceive, connect, and compare mathematical representations of motion to overcome the well-documented difficulties students face when learning spatial transformations.  Strengthening this skill will support their continued development across many STEM disciplines.<br/><br/>An AR/AI-powered innovative learning environment will be developed and evaluated for its effects on teaching and learning major rotation and orientation representations in the Euclidean space.  Different levels of abstraction, including Axis-Angle, Euler Angles, Matrices, and Quaternions will be tested. In workshops participants will play with and transform 3D-printed geometry models to evaluate the effectiveness of the AR/AI technology. The project will assess student learning outcomes by comparing math skills in pre- and post-workshop tests compared to students working through the same tasks without the use of the AR/AI technology. The project will contribute to advancing knowledge across disciplines of spatial and mathematical pedagogies, by exploring: a) the role of novel AR interaction that allows the interplay between physical and virtual manipulatives to engage students in embodied learning; b) the capabilities of AR to make difficult invisible concepts visible for supporting an intuitive and formal understanding of spatial reasoning and mathematical formulation; c) the features of AR that help students see relationships between spatial manipulations and mathematical operations; and d) the potential impact of individual differences in spatial transformations when using AR-assisted mathematical learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality; Games and game making; Makers / making,,"Augmented/virtual/mixed reality, Self-regulation,reflection and metacognition, AI, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Learning analytics","Instructional Design,Cultural competence/responsiveness,Physics,Pedagogical agents,Science education,Math education,Engineering education,Mathematical sciences","Capacity Building,Other Disciplinary Areas,Equity and Social Justice,Disciplinary Areas,AI Approaches and Technologies",Mathematics
Dezhen Song,"Robot Perception, Networked Robots, Vision Systems, Stochastic Modeling",,Texas A&M University,Computer Science and Engineering,,2119549,Using Augmented Reality and Artificial Intelligence to Improve Teaching and Learning Spatial Transformations in STEM Disciplines,"The mathematics that are used to describe spatial transformations can be very difficult for undergraduate students.  While moving something in the physical world may be easy to understand, describing the same operation with math in the digital world can be daunting.  This project will develop new technology using Augmented Reality (AR) and Artificial Intelligence (AI) to improve the teaching and learning of these difficult concepts in STEM disciplines as well as creative endeavors.  The project will test the use of new AR/AI technology to enhance students‚Äô learning of the mathematics behind spatial transformations.  This will improve the use of AR/AI-powered precise motion tracking of objects that can collect high resolution in-situ motion and scene data to enhance learning analytics. The project will identify the AR capabilities that can help students conceive, connect, and compare mathematical representations of motion to overcome the well-documented difficulties students face when learning spatial transformations.  Strengthening this skill will support their continued development across many STEM disciplines.<br/><br/>An AR/AI-powered innovative learning environment will be developed and evaluated for its effects on teaching and learning major rotation and orientation representations in the Euclidean space.  Different levels of abstraction, including Axis-Angle, Euler Angles, Matrices, and Quaternions will be tested. In workshops participants will play with and transform 3D-printed geometry models to evaluate the effectiveness of the AR/AI technology. The project will assess student learning outcomes by comparing math skills in pre- and post-workshop tests compared to students working through the same tasks without the use of the AR/AI technology. The project will contribute to advancing knowledge across disciplines of spatial and mathematical pedagogies, by exploring: a) the role of novel AR interaction that allows the interplay between physical and virtual manipulatives to engage students in embodied learning; b) the capabilities of AR to make difficult invisible concepts visible for supporting an intuitive and formal understanding of spatial reasoning and mathematical formulation; c) the features of AR that help students see relationships between spatial manipulations and mathematical operations; and d) the potential impact of individual differences in spatial transformations when using AR-assisted mathematical learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality; Games and game making; Makers / making,,"Augmented/virtual/mixed reality, Self-regulation,reflection and metacognition, AI, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Learning analytics","Machine learning,Computer vision technologies,Robots","Other Disciplinary Areas,AI Approaches and Technologies","Computer Science, Engineering"
Heather Burte,"Spatial Cognition, Cognitive Psychology, Educational Psychology, STEM Learning",,Texas A&M University,College Arts and Sciences,,2119549,Using Augmented Reality and Artificial Intelligence to Improve Teaching and Learning Spatial Transformations in STEM Disciplines,"The mathematics that are used to describe spatial transformations can be very difficult for undergraduate students.  While moving something in the physical world may be easy to understand, describing the same operation with math in the digital world can be daunting.  This project will develop new technology using Augmented Reality (AR) and Artificial Intelligence (AI) to improve the teaching and learning of these difficult concepts in STEM disciplines as well as creative endeavors.  The project will test the use of new AR/AI technology to enhance students‚Äô learning of the mathematics behind spatial transformations.  This will improve the use of AR/AI-powered precise motion tracking of objects that can collect high resolution in-situ motion and scene data to enhance learning analytics. The project will identify the AR capabilities that can help students conceive, connect, and compare mathematical representations of motion to overcome the well-documented difficulties students face when learning spatial transformations.  Strengthening this skill will support their continued development across many STEM disciplines.<br/><br/>An AR/AI-powered innovative learning environment will be developed and evaluated for its effects on teaching and learning major rotation and orientation representations in the Euclidean space.  Different levels of abstraction, including Axis-Angle, Euler Angles, Matrices, and Quaternions will be tested. In workshops participants will play with and transform 3D-printed geometry models to evaluate the effectiveness of the AR/AI technology. The project will assess student learning outcomes by comparing math skills in pre- and post-workshop tests compared to students working through the same tasks without the use of the AR/AI technology. The project will contribute to advancing knowledge across disciplines of spatial and mathematical pedagogies, by exploring: a) the role of novel AR interaction that allows the interplay between physical and virtual manipulatives to engage students in embodied learning; b) the capabilities of AR to make difficult invisible concepts visible for supporting an intuitive and formal understanding of spatial reasoning and mathematical formulation; c) the features of AR that help students see relationships between spatial manipulations and mathematical operations; and d) the potential impact of individual differences in spatial transformations when using AR-assisted mathematical learning.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",Modeling and simulation (including agent-based modeling); Augmented/virtual/mixed reality; Games and game making; Makers / making,,"Augmented/virtual/mixed reality, Self-regulation,reflection and metacognition, AI, Embodied learning and cognition, Modeling and simulation (including agent-based modeling), Learning analytics","Cognitive psychology / Cognitive science,Science education,Science education,Math education,Engineering education","Learning Processes and Theories,Disciplinary Areas",Arts and Sciences
Chelsea Lyles,"preK-12 and higher education policy and finance, academic labor, graduate education, assessment of student learning",,Virginia Tech,"Institute for creativity, arts and technology, Center for Educational Networks and Impacts (CENI)",,2119011,"RETTL: Facilitating socially constructed learning through a shared, mobile-based virtual reality platform in informal learning settings","Virtual reality (VR) technologies have great potential in STEM education because they provide immersive learning experiences that one cannot have in the real world. However, interactivity using VR head-mounted displays is often a solitary experience, isolating learners from the social and learning context. This makes it challenging to learn through collaborations with peers and instructors. Furthermore, many learners are excluded from using virtual reality headsets, including children, those who wear glasses, and those vulnerable to health concerns such as motion sickness, nausea, and falling. The project will develop and deploy a mobile-device-based VR platform to enable social learning. The project partners with the Science Museum of Western Virginia and the Institute of Creativity, Arts, and Technology at Virginia Tech to support socially constructed, informal STEM learning for their wide range of visitors, including young children with family members, college students, and local K-12 school students. <br/><br/>The project's overarching objective is to design, develop, and deploy an inclusive, socially connected virtual reality platform and educational content. With the system, museum attendees can collectively interact with STEM topics in virtual reality. The system will use social virtual reality to allow multiple learners to engage with the learning material, the instructor, and one another via and beyond motion-tracked mobile devices. A shared physical space with the mobile-based virtual reality platform will grant a diverse range of learners access to immersive STEM learning content and their peers beyond the screen. The researchers will study how the shared display technology facilitates socially constructed learning and enables novel active learning techniques in informal learning settings. The results will advance understanding of integrating virtual reality into inclusive settings and promoting collaborative learning with VR to enhance learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Collaborative and/or participatory learning, Social emotional learning","Educator professional learning,Policy",Capacity Building,Arts
Phyllis Newbill,Informal learning,,Virginia Tech,"Institute for creativity, arts and technology, Educational Networks",,2119011,"RETTL: Facilitating socially constructed learning through a shared, mobile-based virtual reality platform in informal learning settings","Virtual reality (VR) technologies have great potential in STEM education because they provide immersive learning experiences that one cannot have in the real world. However, interactivity using VR head-mounted displays is often a solitary experience, isolating learners from the social and learning context. This makes it challenging to learn through collaborations with peers and instructors. Furthermore, many learners are excluded from using virtual reality headsets, including children, those who wear glasses, and those vulnerable to health concerns such as motion sickness, nausea, and falling. The project will develop and deploy a mobile-device-based VR platform to enable social learning. The project partners with the Science Museum of Western Virginia and the Institute of Creativity, Arts, and Technology at Virginia Tech to support socially constructed, informal STEM learning for their wide range of visitors, including young children with family members, college students, and local K-12 school students. <br/><br/>The project's overarching objective is to design, develop, and deploy an inclusive, socially connected virtual reality platform and educational content. With the system, museum attendees can collectively interact with STEM topics in virtual reality. The system will use social virtual reality to allow multiple learners to engage with the learning material, the instructor, and one another via and beyond motion-tracked mobile devices. A shared physical space with the mobile-based virtual reality platform will grant a diverse range of learners access to immersive STEM learning content and their peers beyond the screen. The researchers will study how the shared display technology facilitates socially constructed learning and enables novel active learning techniques in informal learning settings. The results will advance understanding of integrating virtual reality into inclusive settings and promoting collaborative learning with VR to enhance learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Collaborative and/or participatory learning, Social emotional learning",Informal settings,Learning Environments and Platforms,Arts
Myounghoon Jeon,"Human-Computer Interaction/ Human-Robot Interaction, Sound and Music, Computing, Affective Computing, Assistive Technologies, Automotive User, Interfaces, Aesthetic Computing",,Virginia Tech,Industrial and Systems Engineering,,2119011,"RETTL: Facilitating socially constructed learning through a shared, mobile-based virtual reality platform in informal learning settings","Virtual reality (VR) technologies have great potential in STEM education because they provide immersive learning experiences that one cannot have in the real world. However, interactivity using VR head-mounted displays is often a solitary experience, isolating learners from the social and learning context. This makes it challenging to learn through collaborations with peers and instructors. Furthermore, many learners are excluded from using virtual reality headsets, including children, those who wear glasses, and those vulnerable to health concerns such as motion sickness, nausea, and falling. The project will develop and deploy a mobile-device-based VR platform to enable social learning. The project partners with the Science Museum of Western Virginia and the Institute of Creativity, Arts, and Technology at Virginia Tech to support socially constructed, informal STEM learning for their wide range of visitors, including young children with family members, college students, and local K-12 school students. <br/><br/>The project's overarching objective is to design, develop, and deploy an inclusive, socially connected virtual reality platform and educational content. With the system, museum attendees can collectively interact with STEM topics in virtual reality. The system will use social virtual reality to allow multiple learners to engage with the learning material, the instructor, and one another via and beyond motion-tracked mobile devices. A shared physical space with the mobile-based virtual reality platform will grant a diverse range of learners access to immersive STEM learning content and their peers beyond the screen. The researchers will study how the shared display technology facilitates socially constructed learning and enables novel active learning techniques in informal learning settings. The results will advance understanding of integrating virtual reality into inclusive settings and promoting collaborative learning with VR to enhance learning outcomes.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Augmented/virtual/mixed reality, Collaborative and/or participatory learning, Social emotional learning","Autonomous technology,Accessibility and technology,Multimodal data analysis,Creativity,Physiological sciences,Human-AI Interaction,Interactive Displays","Analytics,Learning Environments and Platforms,Other Disciplinary Areas,Learning Processes and Theories,Equity and Social Justice","Industrial Engineering, Systems Engineering"
Jeff Rosen,"social and emotional learning, survey measures of social and emotional skills, research related to at-risk student populations",,RTI International,Center for Evaluation and the Study of Educational Equity,,2119135,Exploring Artificial Intelligence-enhanced Electronic Design Process Logs: Empowering High School Engineering Teachers,"The Engineering Design Process (EDP) is a general theoretical framework often used for teaching engineering, STEM, invention, and even science, particularly in K-12 education. While most EDPs used in education are depicted as linear or circular, true design processes are highly creative, non-linear, and often involve ill-posed problem statements and solution criteria.  These traits make it particularly difficult for high school engineering teachers, who tend to skip over key elements of human-centered design, where an engineer takes time to understand the problem through research, interviews, prior literature searches, market analysis, and brainstorming‚Äîthe steps where diversity of thought and experience are of the most value. In addition, it can be hard to provide students with real-time feedback due to the asynchronous nature of group work and large class sizes, and students may not feel comfortable asking for feedback on incomplete work. This project will develop and pilot an artificial intelligence (AI) enhanced Engineering Design Process Log to help students navigate the design process, provide real-time feedback, and encourage meaningful documentation of each step of the process.  This project does not propose to replace teachers with AI; rather, the project will explore a novel approach in which AI systems assist teachers in the creation of instructional modules that adhere to EDP best practices. This project is a collaboration between researchers at Georgia Tech‚Äôs College of Computing (GT CoC) and researchers at Georgia Tech‚Äôs Center for Education Integrating Science, Mathematics and Computing (CEISMC).  <br/> <br/>This project is a teaching-focused technological innovation, representing an early exploration into AI-enhanced design pedagogy. Specifically, the project will: 1) Improve upon an existing web-based Engineering Design Process Log (EDPL) by engaging in teacher user studies, 2) Design, pilot, and implement an AI-based authoring and tutoring system for teachers to customize feedback for students and for specific projects with domain expertise, 3) Design and provide professional development opportunities for alpha and beta testing teachers, and 4) Assess the impact of an AI-based EDP Log (AI-EDPL) on engineering design pedagogy and classroom practice. The AI-EDPL software system will use concepts initially pioneered for intelligent tutoring systems, but applied to scaffolding the creation of custom, teacher-made instructional materials that adhere to best practices in design process pedagogy assessment. Unlike many other educational domains, engineering design problems vary widely in scope and solution pathways, which means there will not be a one-size-fits-all tutoring system that can provide feedback to students. This project will examine (a) whether artificial intelligence can support and scaffold teachers in the creation of the necessary models and knowledge structures needed to scaffold and support learners, and, (b) what professional development teachers need to be successful in developing these models. A multi-phased approach will be used, using value-sensitive design processes from the field of human computer interaction to develop minimalist functional systems that can be tested with teachers in classrooms. In order for AI to help teachers, who do not have a lot of time to tinker with software, they must be able to express their intentions in natural language, which must be automatically converted into functional approximations of the task models that can be easily edited. This project will build on best practices in design theory and pedagogy, design documentation, design instruction, design assessment, and AI tutoring to create a one-of-a-kind technology suitable for engineering design instruction at the high school level. It represents a first attempt at providing real-time feedback in a computational setting for an open-ended design challenge, and it does so without marginalizing or diminishing the role of the instructor in the engineering classroom.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; AI knowledge representation and reasoning,,"Other, User-centered design, Adaptive/Personalized learning and intelligent tutors, AI","Survey measures,Inclusive/universal design,Social emotional learning","Research Methods,Equity and Social Justice,Learning Processes and Theories","Evaluation, Equity"
Roxanne Moore,Computer Aided Engineering and Design,,Georgia Tech,Mechanical Engineering,,2119135,Exploring Artificial Intelligence-enhanced Electronic Design Process Logs: Empowering High School Engineering Teachers,"The Engineering Design Process (EDP) is a general theoretical framework often used for teaching engineering, STEM, invention, and even science, particularly in K-12 education. While most EDPs used in education are depicted as linear or circular, true design processes are highly creative, non-linear, and often involve ill-posed problem statements and solution criteria.  These traits make it particularly difficult for high school engineering teachers, who tend to skip over key elements of human-centered design, where an engineer takes time to understand the problem through research, interviews, prior literature searches, market analysis, and brainstorming‚Äîthe steps where diversity of thought and experience are of the most value. In addition, it can be hard to provide students with real-time feedback due to the asynchronous nature of group work and large class sizes, and students may not feel comfortable asking for feedback on incomplete work. This project will develop and pilot an artificial intelligence (AI) enhanced Engineering Design Process Log to help students navigate the design process, provide real-time feedback, and encourage meaningful documentation of each step of the process.  This project does not propose to replace teachers with AI; rather, the project will explore a novel approach in which AI systems assist teachers in the creation of instructional modules that adhere to EDP best practices. This project is a collaboration between researchers at Georgia Tech‚Äôs College of Computing (GT CoC) and researchers at Georgia Tech‚Äôs Center for Education Integrating Science, Mathematics and Computing (CEISMC).  <br/> <br/>This project is a teaching-focused technological innovation, representing an early exploration into AI-enhanced design pedagogy. Specifically, the project will: 1) Improve upon an existing web-based Engineering Design Process Log (EDPL) by engaging in teacher user studies, 2) Design, pilot, and implement an AI-based authoring and tutoring system for teachers to customize feedback for students and for specific projects with domain expertise, 3) Design and provide professional development opportunities for alpha and beta testing teachers, and 4) Assess the impact of an AI-based EDP Log (AI-EDPL) on engineering design pedagogy and classroom practice. The AI-EDPL software system will use concepts initially pioneered for intelligent tutoring systems, but applied to scaffolding the creation of custom, teacher-made instructional materials that adhere to best practices in design process pedagogy assessment. Unlike many other educational domains, engineering design problems vary widely in scope and solution pathways, which means there will not be a one-size-fits-all tutoring system that can provide feedback to students. This project will examine (a) whether artificial intelligence can support and scaffold teachers in the creation of the necessary models and knowledge structures needed to scaffold and support learners, and, (b) what professional development teachers need to be successful in developing these models. A multi-phased approach will be used, using value-sensitive design processes from the field of human computer interaction to develop minimalist functional systems that can be tested with teachers in classrooms. In order for AI to help teachers, who do not have a lot of time to tinker with software, they must be able to express their intentions in natural language, which must be automatically converted into functional approximations of the task models that can be easily edited. This project will build on best practices in design theory and pedagogy, design documentation, design instruction, design assessment, and AI tutoring to create a one-of-a-kind technology suitable for engineering design instruction at the high school level. It represents a first attempt at providing real-time feedback in a computational setting for an open-ended design challenge, and it does so without marginalizing or diminishing the role of the instructor in the engineering classroom.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",AI; AI knowledge representation and reasoning,,"Other, User-centered design, Adaptive/Personalized learning and intelligent tutors, AI",Graphics,Analytics,Mechanical Engineering
Ken Koedinger,"Intelligent Tutoring Systems, Educational Data Mining, Artificial Intelligence in Education, Learning Engineering, Learning Sciences",,Carnegie Mellon University,Human Computer Interaction Institute & Psychology,,2119007,Enhancing flexible STEM thinking by generating interactive diagrams at scale,"Math and science diagrams improve learning, both when diagrams are delivered with instruction, and when they are created for self-explanation. The resulting learning is often more flexible. For example, students that practice diagramming are better at transferring their learning from the problems they have explicitly practiced to more open-ended problems. Unfortunately, diagrams are too uncommon in instructional materials, especially practice problems. This is primarily because diagrams are much harder to produce than text and symbols. Teaching at scale adds further challenges. Ideally, e-learning platforms should deliver different problems to different students. These problems should be tailored to knowledge components, prevent cheating by copying, and be tuned the amount of practice to student needs. Problem templating systems aren‚Äôt built for diagrams and grading student-authored diagrams is hard to do even manually.  To address the challenge, this project aims to develop a new tool for generating diagrammatic instructional content. <br/><br/>This tool developed by the project will enable content authors to generate large problem sets by example. User will author one or two problems and the tool will synthesize a problem set from the examples. The project introduces efficient interaction techniques for viewing and editing these sets. The project will collect data from teachers and students to guide, refine, and evaluate the design of the tool. The project will conduct six studies, three will focus on the effectiveness of the tool in supporting authoring of educational content and three that focus on the impact of the resulting problems on student learning. These studies will enhance our understanding of when and how diagrams can be used to increase student understanding of science, technology, engineering and math (STEM) principles and lead to more flexible STEM thinking.<br/><br/>This award reflects NSF's statutory mission and has been deemed worthy of support through evaluation using the Foundation's intellectual merit and broader impacts review criteria.",,,"Other, AI, AI knowledge representation and reasoning","Data mining,AI,Adaptive/Personalized learning and intelligent tutors,Learning Engineering","Research Methods,Analytics,AI Approaches and Technologies","Human-Computer Interaction, Psychology"
